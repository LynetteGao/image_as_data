{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set-up of the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/lynette/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Basic packages\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import re\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "# Packages for data preparation\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Packages for modeling\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import regularizers\n",
    "\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import recall_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_WORDS = 10000  # Parameter indicating the number of words we'll put in the dictionary\n",
    "NB_START_EPOCHS = 30  # Number of epochs we usually start to train with\n",
    "BATCH_SIZE = 512  # Size of the batches used in the mini-batch gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set some parameters that will be used throughout the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We read in the csv with the tweets data and perform a random shuffle. It's a good practice to shuffle the data before splitting between a train and test set. We'll only keep the video decription column as input and the Relvancy column as the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'video_id', 'channel_title', 'channel_id',\n",
       "       'video_publish_date', 'video_title', 'video_description',\n",
       "       'video_category', 'video_view_count', 'video_comment_count',\n",
       "       'video_like_count', 'video_dislike_count', 'video_thumbnail',\n",
       "       'video_tags', 'collection_date', 'science.topic', 'Relevancy',\n",
       "       'attitude', 'Text/video', 'search.term', 'cld2', 'transcript',\n",
       "       'transcript_nchar', 'videoid', 'conspiracy', 'var_r', 'var_g', 'var_b',\n",
       "       'var_h', 'var_s', 'var_v', 'var_bright', 'var_bright_sd',\n",
       "       'var_contrast', 'var_colorful', 'median_r', 'median_g', 'median_b',\n",
       "       'median_h', 'median_s', 'median_v', 'median_bright', 'median_bright_sd',\n",
       "       'median_contrast', 'median_colorful', 'r_mean', 'g_mean', 'b_mean',\n",
       "       'h_mean', 's_mean', 'v_mean', 'bright_mean', 'lightning_mean',\n",
       "       'contrast_mean', 'colorful_mean', 'color_lag'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('handlabel_feature.csv')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['transcript']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>with coronavirus completely changing our way o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>you all know I'm a big fan of conspiracy theor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>how do you handle an epidemic in the age of fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CaptionUnavailable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>what's up guys Stephen here and welcome back t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>so the government work for us we don't work fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>but even if 5g has nothing to do with this cor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>um some people believe that 5g like like for c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>this is a podcast from the South China Morning...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>we're all catching the wires because of the fi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>407 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            transcript\n",
       "0    with coronavirus completely changing our way o...\n",
       "1    you all know I'm a big fan of conspiracy theor...\n",
       "2    how do you handle an epidemic in the age of fa...\n",
       "3                                   CaptionUnavailable\n",
       "4    what's up guys Stephen here and welcome back t...\n",
       "..                                                 ...\n",
       "402  so the government work for us we don't work fo...\n",
       "403  but even if 5g has nothing to do with this cor...\n",
       "404  um some people believe that 5g like like for c...\n",
       "405  this is a podcast from the South China Morning...\n",
       "406  we're all catching the wires because of the fi...\n",
       "\n",
       "[407 rows x 1 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X[(X[\"transcript\"] != 'CaptionUnavailable') & (X[\"transcript\"] != 'VideoUnavailable')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(313, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "df['attitude'] = le.fit_transform(df['attitude'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      0\n",
       "2      0\n",
       "4      0\n",
       "5      1\n",
       "      ..\n",
       "402    1\n",
       "403    0\n",
       "404    0\n",
       "405    0\n",
       "406    0\n",
       "Name: attitude, Length: 313, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df['attitude'][(df[\"transcript\"] != 'CaptionUnavailable') & (df[\"transcript\"] != 'VideoUnavailable')]\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing we'll do is removing stopwords. These words do not have any value for predicting the sentiment.Also, we remove the http link in the texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "visual = df[['var_r', 'var_g', 'var_b',\n",
    "       'var_h', 'var_s', 'var_v', 'var_bright', 'var_bright_sd',\n",
    "       'var_contrast', 'var_colorful', 'median_r', 'median_g', 'median_b',\n",
    "       'median_h', 'median_s', 'median_v', 'median_bright', 'median_bright_sd',\n",
    "       'median_contrast', 'median_colorful']][(df[\"transcript\"] != 'CaptionUnavailable') & (df[\"transcript\"] != 'VideoUnavailable')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_WORDS = 10000\n",
    "tk = Tokenizer(num_words=NB_WORDS,\n",
    "               filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
    "               lower=True,\n",
    "               split=\" \")\n",
    "tk.fit_on_texts(X.transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_seq = tk.texts_to_sequences(X.transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_seq(seqs, nb_features = NB_WORDS):\n",
    "    ohs = np.zeros((len(seqs), nb_features))\n",
    "    for i, s in enumerate(seqs):\n",
    "        ohs[i, s] = 1.\n",
    "    return ohs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_oh = one_hot_seq(x_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(313, 20)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visual.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(313, 10000)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_oh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "result = pd.DataFrame(pd.np.column_stack([visual, X_oh]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of            0            1            2           3            4      \\\n",
       "0     298.035544   256.526430   317.666638  176.226486   291.471955   \n",
       "1      14.562086    13.206167    14.473241   22.249816     3.087459   \n",
       "2    1397.200532  1812.288126  1125.290200  952.795220  3386.595470   \n",
       "3     800.175857   979.432379   765.202229  533.030459   899.264225   \n",
       "4     611.670255   710.533599   704.285521  565.782339   267.640542   \n",
       "..           ...          ...          ...         ...          ...   \n",
       "308   147.788425    83.104502   343.138525  287.133037   738.014925   \n",
       "309   499.048934   671.771055   464.885271  768.802809   362.948260   \n",
       "310    12.184924     9.988667     8.442325    7.628704     8.160141   \n",
       "311     3.100336    12.856796    13.246367    0.652040    23.776415   \n",
       "312    26.059390    20.160538    26.205856   37.262637     9.450165   \n",
       "\n",
       "          5            6           7            8           9      ...  10010  \\\n",
       "0    318.839186   249.684164   58.312728   273.094250  131.323126  ...    0.0   \n",
       "1     14.468497    13.461712    2.128646     6.360655    0.903765  ...    0.0   \n",
       "2    942.447595  1478.249667  160.366149  1102.429909  528.665700  ...    0.0   \n",
       "3    665.884765   850.382767  385.940453  2316.228370  115.950038  ...    0.0   \n",
       "4    616.471287   661.184079  185.405393    48.207604  226.281947  ...    0.0   \n",
       "..          ...          ...         ...          ...         ...  ...    ...   \n",
       "308  211.022546    73.414553  233.283992   762.744039  122.025988  ...    0.0   \n",
       "309  492.587090   554.760968   93.525503   564.382108   60.941841  ...    0.0   \n",
       "310   12.292979     9.858782    1.924338    13.182123    6.304640  ...    0.0   \n",
       "311    2.342890     9.398054    2.273838     0.001471    6.499906  ...    0.0   \n",
       "312   20.737421    21.035988   16.549036     6.226976    4.321690  ...    0.0   \n",
       "\n",
       "     10011  10012  10013  10014  10015  10016  10017  10018  10019  \n",
       "0      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "1      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "2      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "3      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "4      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "..     ...    ...    ...    ...    ...    ...    ...    ...    ...  \n",
       "308    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "309    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "310    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "311    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "312    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "\n",
       "[313 rows x 10020 columns]>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate K-fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train set: (281, 10020)\n",
      "Shape of y: (281, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "WARNING:tensorflow:From <ipython-input-35-34b29bc68726>:81: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "> Fold 1 - Precison: 0.5829248366013072 - Recall: 0.6470588235294118%\n",
      "Shape of train set: (281, 10020)\n",
      "Shape of y: (281, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "> Fold 2 - Precison: 0.6914335664335665 - Recall: 0.8181818181818182%\n",
      "Shape of train set: (281, 10020)\n",
      "Shape of y: (281, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "> Fold 3 - Precison: 0.71875 - Recall: 1.0%\n",
      "Shape of train set: (282, 10020)\n",
      "Shape of y: (282, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "> Fold 4 - Precison: 0.7407407407407407 - Recall: 1.0%\n",
      "Shape of train set: (282, 10020)\n",
      "Shape of y: (282, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f968ce164d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 5 - Precison: 0.8 - Recall: 1.0%\n",
      "Shape of train set: (282, 10020)\n",
      "Shape of y: (282, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 6 ...\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f969049f440> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 6 - Precison: 0.6525183927560838 - Recall: 0.7368421052631579%\n",
      "Shape of train set: (282, 10020)\n",
      "Shape of y: (282, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 7 ...\n",
      "WARNING:tensorflow:7 out of the last 7 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9689ec0710> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 7 - Precison: 0.6666666666666666 - Recall: 1.0%\n",
      "Shape of train set: (282, 10020)\n",
      "Shape of y: (282, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 8 ...\n",
      "WARNING:tensorflow:8 out of the last 8 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f96850c8440> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 8 - Precison: 0.7560483870967742 - Recall: 0.75%\n",
      "Shape of train set: (282, 10020)\n",
      "Shape of y: (282, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 9 ...\n",
      "WARNING:tensorflow:9 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9684d63560> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 9 - Precison: 0.7741935483870968 - Recall: 1.0%\n",
      "Shape of train set: (282, 10020)\n",
      "Shape of y: (282, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 10 ...\n",
      "WARNING:tensorflow:10 out of the last 10 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f96a7a8f830> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 10 - Precison: 0.775366568914956 - Recall: 0.7272727272727273%\n",
      "------------------------------------------------------------------------\n",
      "> Precison: 0.7158642707597193 (+- 0.06400502747723333)\n",
      "> Recall: 0.8679355474247116\n",
      "------------------------------------------------------------------------\n",
      "Shape of train set: (281, 10020)\n",
      "Shape of y: (281, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9686f73b00> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Fold 1 - Precison: 0.65625 - Recall: 1.0%\n",
      "Shape of train set: (281, 10020)\n",
      "Shape of y: (281, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f96859c2dd0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 2 - Precison: 0.6 - Recall: 1.0%\n",
      "Shape of train set: (281, 10020)\n",
      "Shape of y: (281, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f96a6d50320> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 3 - Precison: 0.71875 - Recall: 1.0%\n",
      "Shape of train set: (282, 10020)\n",
      "Shape of y: (282, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9689e3b5f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 4 - Precison: 0.8307834101382487 - Recall: 0.48%\n",
      "Shape of train set: (282, 10020)\n",
      "Shape of y: (282, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9684c708c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 5 - Precison: 0.6774193548387096 - Recall: 1.0%\n",
      "Shape of train set: (282, 10020)\n",
      "Shape of y: (282, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 6 ...\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f968cad7b90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 6 - Precison: 0.5837982051903954 - Recall: 0.15789473684210525%\n",
      "Shape of train set: (282, 10020)\n",
      "Shape of y: (282, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 7 ...\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f969003bf80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 7 - Precison: 0.8116461482520388 - Recall: 0.9565217391304348%\n",
      "Shape of train set: (282, 10020)\n",
      "Shape of y: (282, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 8 ...\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9684cead40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 8 - Precison: 0.6301898441117456 - Recall: 0.7368421052631579%\n",
      "Shape of train set: (282, 10020)\n",
      "Shape of y: (282, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 9 ...\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f96a6c5e710> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 9 - Precison: 0.8638884834330756 - Recall: 0.5769230769230769%\n",
      "Shape of train set: (282, 10020)\n",
      "Shape of y: (282, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 10 ...\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f968ce6b8c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Fold 10 - Precison: 0.710850439882698 - Recall: 0.8%\n",
      "------------------------------------------------------------------------\n",
      "> Precison: 0.7083575885846912 (+- 0.09327360960263813)\n",
      "> Recall: 0.7708181658158775\n",
      "------------------------------------------------------------------------\n",
      "Shape of train set: (281, 10020)\n",
      "Shape of y: (281, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9692dfeb90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 1 - Precison: 0.8387096774193549 - Recall: 1.0%\n",
      "Shape of train set: (281, 10020)\n",
      "Shape of y: (281, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f968cdc8f80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 2 - Precison: 0.782986111111111 - Recall: 0.7916666666666666%\n",
      "Shape of train set: (281, 10020)\n",
      "Shape of y: (281, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9675541dd0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 3 - Precison: 0.59375 - Recall: 1.0%\n",
      "Shape of train set: (282, 10020)\n",
      "Shape of y: (282, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9684dc1c20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 4 - Precison: 0.6961196820944366 - Recall: 0.6086956521739131%\n",
      "Shape of train set: (282, 10020)\n",
      "Shape of y: (282, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f96858de440> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 5 - Precison: 0.7638168283329574 - Recall: 0.9090909090909091%\n",
      "Shape of train set: (282, 10020)\n",
      "Shape of y: (282, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 6 ...\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9689e11560> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 6 - Precison: 0.6663594470046084 - Recall: 0.14285714285714285%\n",
      "Shape of train set: (282, 10020)\n",
      "Shape of y: (282, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 7 ...\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f96a7aa6830> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 7 - Precison: 0.6537634408602151 - Recall: 0.4%\n",
      "Shape of train set: (282, 10020)\n",
      "Shape of y: (282, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 8 ...\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f96976a1b00> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 8 - Precison: 0.6546718576195774 - Recall: 0.95%\n",
      "Shape of train set: (282, 10020)\n",
      "Shape of y: (282, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 9 ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f967610cdd0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 9 - Precison: 0.7419354838709677 - Recall: 1.0%\n",
      "Shape of train set: (282, 10020)\n",
      "Shape of y: (282, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 10 ...\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f968cd48f80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 10 - Precison: 0.5342188488298545 - Recall: 0.9411764705882353%\n",
      "------------------------------------------------------------------------\n",
      "> Precison: 0.6926331377143083 (+- 0.08690638134375597)\n",
      "> Recall: 0.7743486841376868\n",
      "------------------------------------------------------------------------\n",
      "Shape of train set: (281, 10020)\n",
      "Shape of y: (281, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f96a6d3b5f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 1 - Precison: 0.7685688405797102 - Recall: 0.43478260869565216%\n",
      "Shape of train set: (281, 10020)\n",
      "Shape of y: (281, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f968ce648c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 2 - Precison: 0.79325 - Recall: 0.64%\n",
      "Shape of train set: (281, 10020)\n",
      "Shape of y: (281, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f968ce02dd0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 3 - Precison: 0.625 - Recall: 1.0%\n",
      "Shape of train set: (282, 10020)\n",
      "Shape of y: (282, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9685959320> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 4 - Precison: 0.8138112305854242 - Recall: 0.88%\n",
      "Shape of train set: (282, 10020)\n",
      "Shape of y: (282, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f969042b440> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 5 - Precison: 0.6896551724137931 - Recall: 1.0%\n",
      "Shape of train set: (282, 10020)\n",
      "Shape of y: (282, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 6 ...\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f96a701bdd0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 6 - Precison: 0.7051544632189793 - Recall: 0.6190476190476191%\n",
      "Shape of train set: (282, 10020)\n",
      "Shape of y: (282, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 7 ...\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f96a6d3e3b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Fold 7 - Precison: 0.6177675371223759 - Recall: 0.2777777777777778%\n",
      "Shape of train set: (282, 10020)\n",
      "Shape of y: (282, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 8 ...\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f96a7885710> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 8 - Precison: 0.7425219941348975 - Recall: 0.36363636363636365%\n",
      "Shape of train set: (282, 10020)\n",
      "Shape of y: (282, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 9 ...\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f96976bd8c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 9 - Precison: 0.6451612903225806 - Recall: 1.0%\n",
      "Shape of train set: (282, 10020)\n",
      "Shape of y: (282, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 10 ...\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9674f04a70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 10 - Precison: 0.6615162193909822 - Recall: 0.5238095238095238%\n",
      "------------------------------------------------------------------------\n",
      "> Precison: 0.7062406747768744 (+- 0.06691632963869634)\n",
      "> Recall: 0.6739053892966936\n",
      "------------------------------------------------------------------------\n",
      "Shape of train set: (281, 10020)\n",
      "Shape of y: (281, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9676165440> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 1 - Precison: 0.8625 - Recall: 0.75%\n",
      "Shape of train set: (281, 10020)\n",
      "Shape of y: (281, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9686f8acb0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 2 - Precison: 0.8182142857142857 - Recall: 0.92%\n",
      "Shape of train set: (281, 10020)\n",
      "Shape of y: (281, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f96761763b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 3 - Precison: 0.6875 - Recall: 1.0%\n",
      "Shape of train set: (282, 10020)\n",
      "Shape of y: (282, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f968a7c2710> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 4 - Precison: 0.6516129032258063 - Recall: 0.3%\n",
      "Shape of train set: (282, 10020)\n",
      "Shape of y: (282, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9690411c20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 5 - Precison: 0.59926324173636 - Recall: 0.6111111111111112%\n",
      "Shape of train set: (282, 10020)\n",
      "Shape of y: (282, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 6 ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f96851e0320> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 6 - Precison: 0.6202798431005211 - Recall: 0.9473684210526315%\n",
      "Shape of train set: (282, 10020)\n",
      "Shape of y: (282, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 7 ...\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9690411320> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 7 - Precison: 0.5806451612903226 - Recall: 1.0%\n",
      "Shape of train set: (282, 10020)\n",
      "Shape of y: (282, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 8 ...\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9674d07560> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 8 - Precison: 0.7824333800841514 - Recall: 0.30434782608695654%\n",
      "Shape of train set: (282, 10020)\n",
      "Shape of y: (282, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 9 ...\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f968cd223b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 9 - Precison: 0.7666666666666667 - Recall: 1.0%\n",
      "Shape of train set: (282, 10020)\n",
      "Shape of y: (282, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 10 ...\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f96a7886440> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 10 - Precison: 0.7746610565684899 - Recall: 0.9130434782608695%\n",
      "------------------------------------------------------------------------\n",
      "> Precison: 0.7143776538386604 (+- 0.09400745425313571)\n",
      "> Recall: 0.7745870836511568\n",
      "------------------------------------------------------------------------\n",
      "Shape of train set: (281, 10020)\n",
      "Shape of y: (281, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9692cd9c20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 1 - Precison: 0.7115221088435374 - Recall: 0.9523809523809523%\n",
      "Shape of train set: (281, 10020)\n",
      "Shape of y: (281, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9684d1c320> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 2 - Precison: 0.7096774193548387 - Recall: 1.0%\n",
      "Shape of train set: (281, 10020)\n",
      "Shape of y: (281, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f96c28877a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 3 - Precison: 0.6854166666666667 - Recall: 0.6666666666666666%\n",
      "Shape of train set: (282, 10020)\n",
      "Shape of y: (282, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f96a6d04710> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Fold 4 - Precison: 0.5806451612903226 - Recall: 1.0%\n",
      "Shape of train set: (282, 10020)\n",
      "Shape of y: (282, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f96859e23b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 5 - Precison: 0.8035954301075269 - Recall: 0.2916666666666667%\n",
      "Shape of train set: (282, 10020)\n",
      "Shape of y: (282, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 6 ...\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f968cede3b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 6 - Precison: 0.6704704832334566 - Recall: 0.6818181818181818%\n",
      "Shape of train set: (282, 10020)\n",
      "Shape of y: (282, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 7 ...\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f96972ed560> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 7 - Precison: 0.6602150537634408 - Recall: 0.7%\n",
      "Shape of train set: (282, 10020)\n",
      "Shape of y: (282, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 8 ...\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9684dec710> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 8 - Precison: 0.6278689555429793 - Recall: 0.8947368421052632%\n",
      "Shape of train set: (282, 10020)\n",
      "Shape of y: (282, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 9 ...\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9664fdd8c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 9 - Precison: 0.7076073831292048 - Recall: 0.5454545454545454%\n",
      "Shape of train set: (282, 10020)\n",
      "Shape of y: (282, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 10 ...\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9690474170> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 10 - Precison: 0.8387096774193549 - Recall: 1.0%\n",
      "------------------------------------------------------------------------\n",
      "> Precison: 0.6995728339351329 (+- 0.07236768600184605)\n",
      "> Recall: 0.7732723855092276\n",
      "------------------------------------------------------------------------\n",
      "Shape of train set: (281, 10020)\n",
      "Shape of y: (281, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f96a6cd6cb0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 1 - Precison: 0.6321428571428571 - Recall: 0.42857142857142855%\n",
      "Shape of train set: (281, 10020)\n",
      "Shape of y: (281, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f968ce7a3b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 2 - Precison: 0.6661706349206349 - Recall: 0.9523809523809523%\n",
      "Shape of train set: (281, 10020)\n",
      "Shape of y: (281, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f96851d2710> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 3 - Precison: 0.5996710526315789 - Recall: 0.55%\n",
      "Shape of train set: (282, 10020)\n",
      "Shape of y: (282, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9692e07c20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 4 - Precison: 0.6449915110356537 - Recall: 0.3684210526315789%\n",
      "Shape of train set: (282, 10020)\n",
      "Shape of y: (282, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9675364320> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 5 - Precison: 0.7337073398784478 - Recall: 0.9565217391304348%\n",
      "Shape of train set: (282, 10020)\n",
      "Shape of y: (282, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 6 ...\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f96851d2170> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 6 - Precison: 0.6149928170301685 - Recall: 0.8421052631578947%\n",
      "Shape of train set: (282, 10020)\n",
      "Shape of y: (282, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 7 ...\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f96751ecd40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 7 - Precison: 0.8202304147465437 - Recall: 0.92%\n",
      "Shape of train set: (282, 10020)\n",
      "Shape of y: (282, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 8 ...\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9686f953b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 8 - Precison: 0.8111559139784946 - Recall: 0.625%\n",
      "Shape of train set: (282, 10020)\n",
      "Shape of y: (282, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 9 ...\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9684d50710> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 9 - Precison: 0.5492831541218639 - Recall: 0.3888888888888889%\n",
      "Shape of train set: (282, 10020)\n",
      "Shape of y: (282, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 10 ...\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f96a7aa0c20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 10 - Precison: 0.8202304147465437 - Recall: 0.92%\n",
      "------------------------------------------------------------------------\n",
      "> Precison: 0.6892576110232785 (+- 0.09488475964536117)\n",
      "> Recall: 0.6951889324761178\n",
      "------------------------------------------------------------------------\n",
      "Shape of train set: (281, 10020)\n",
      "Shape of y: (281, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f96752c3320> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Fold 1 - Precison: 0.625 - Recall: 1.0%\n",
      "Shape of train set: (281, 10020)\n",
      "Shape of y: (281, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f968ce135f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 2 - Precison: 0.6774193548387096 - Recall: 1.0%\n",
      "Shape of train set: (281, 10020)\n",
      "Shape of y: (281, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f96a6a5bcb0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 3 - Precison: 0.59375 - Recall: 1.0%\n",
      "Shape of train set: (282, 10020)\n",
      "Shape of y: (282, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f96a7b77f80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 4 - Precison: 0.7638168283329574 - Recall: 0.9090909090909091%\n",
      "Shape of train set: (282, 10020)\n",
      "Shape of y: (282, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9674fa5200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 5 - Precison: 0.7746823069403714 - Recall: 0.9545454545454546%\n",
      "Shape of train set: (282, 10020)\n",
      "Shape of y: (282, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 6 ...\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f96a79db3b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 6 - Precison: 0.7540655825113303 - Recall: 0.4090909090909091%\n",
      "Shape of train set: (282, 10020)\n",
      "Shape of y: (282, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 7 ...\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f968cdea3b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 7 - Precison: 0.7333333333333333 - Recall: 1.0%\n",
      "Shape of train set: (282, 10020)\n",
      "Shape of y: (282, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 8 ...\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f96a79db5f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 8 - Precison: 0.7923155357804968 - Recall: 0.9583333333333334%\n",
      "Shape of train set: (282, 10020)\n",
      "Shape of y: (282, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 9 ...\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f96a6d508c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 9 - Precison: 0.8012903225806453 - Recall: 0.8%\n",
      "Shape of train set: (282, 10020)\n",
      "Shape of y: (282, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 10 ...\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9674f973b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Fold 10 - Precison: 0.6 - Recall: 1.0%\n",
      "------------------------------------------------------------------------\n",
      "> Precison: 0.7115673264317844 (+- 0.07651930350888687)\n",
      "> Recall: 0.9031060606060606\n",
      "------------------------------------------------------------------------\n",
      "Shape of train set: (281, 10020)\n",
      "Shape of y: (281, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f968ce62710> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 1 - Precison: 0.58125 - Recall: 0.5%\n",
      "Shape of train set: (281, 10020)\n",
      "Shape of y: (281, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9675565c20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 2 - Precison: 0.7326992753623188 - Recall: 0.9565217391304348%\n",
      "Shape of train set: (281, 10020)\n",
      "Shape of y: (281, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9675477320> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 3 - Precison: 0.8205128205128205 - Recall: 0.38461538461538464%\n",
      "Shape of train set: (282, 10020)\n",
      "Shape of y: (282, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9686ff10e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 4 - Precison: 0.6202798431005211 - Recall: 0.9473684210526315%\n",
      "Shape of train set: (282, 10020)\n",
      "Shape of y: (282, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9676153dd0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 5 - Precison: 0.5999201038649755 - Recall: 0.5263157894736842%\n",
      "Shape of train set: (282, 10020)\n",
      "Shape of y: (282, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 6 ...\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f968cd283b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 6 - Precison: 0.8003199146894161 - Recall: 0.45454545454545453%\n",
      "Shape of train set: (282, 10020)\n",
      "Shape of y: (282, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 7 ...\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9686f95710> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 7 - Precison: 0.8267408231368187 - Recall: 0.96%\n",
      "Shape of train set: (282, 10020)\n",
      "Shape of y: (282, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 8 ...\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9689cc9c20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 8 - Precison: 0.7419354838709677 - Recall: 1.0%\n",
      "Shape of train set: (282, 10020)\n",
      "Shape of y: (282, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 9 ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9689c90320> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 9 - Precison: 0.7723502304147465 - Recall: 0.6%\n",
      "Shape of train set: (282, 10020)\n",
      "Shape of y: (282, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 10 ...\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9689c8bef0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 10 - Precison: 0.6684475806451613 - Recall: 0.55%\n",
      "------------------------------------------------------------------------\n",
      "> Precison: 0.7164456075597746 (+- 0.08802094711598057)\n",
      "> Recall: 0.6879366788817589\n",
      "------------------------------------------------------------------------\n",
      "Shape of train set: (281, 10020)\n",
      "Shape of y: (281, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f96a6d04e60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 1 - Precison: 0.6871565934065934 - Recall: 0.8571428571428571%\n",
      "Shape of train set: (281, 10020)\n",
      "Shape of y: (281, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9689e435f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 2 - Precison: 0.6774193548387096 - Recall: 1.0%\n",
      "Shape of train set: (281, 10020)\n",
      "Shape of y: (281, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f969732d7a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 3 - Precison: 0.9323994252873564 - Recall: 0.9655172413793104%\n",
      "Shape of train set: (282, 10020)\n",
      "Shape of y: (282, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f96904b3950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 4 - Precison: 0.6666666666666666 - Recall: 1.0%\n",
      "Shape of train set: (282, 10020)\n",
      "Shape of y: (282, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9692e01b00> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 5 - Precison: 0.7142857142857143 - Recall: 1.0%\n",
      "Shape of train set: (282, 10020)\n",
      "Shape of y: (282, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 6 ...\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9675457cb0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 6 - Precison: 0.8118279569892473 - Recall: 0.16666666666666666%\n",
      "Shape of train set: (282, 10020)\n",
      "Shape of y: (282, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 7 ...\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f96a6d04710> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Fold 7 - Precison: 0.769348463598113 - Recall: 0.8181818181818182%\n",
      "Shape of train set: (282, 10020)\n",
      "Shape of y: (282, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 8 ...\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9694c5dcb0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 8 - Precison: 0.5117210979763575 - Recall: 0.8571428571428571%\n",
      "Shape of train set: (282, 10020)\n",
      "Shape of y: (282, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 9 ...\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f96a7b4f3b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 9 - Precison: 0.6666666666666666 - Recall: 1.0%\n",
      "Shape of train set: (282, 10020)\n",
      "Shape of y: (282, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 10 ...\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f968ce42710> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 10 - Precison: 0.7949308755760368 - Recall: 0.25%\n",
      "------------------------------------------------------------------------\n",
      "> Precison: 0.7232422815291462 (+- 0.10652892391433452)\n",
      "> Recall: 0.7914651440513509\n",
      "------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "precision = []\n",
    "recall = []\n",
    "\n",
    "for i in range(10):\n",
    "    \n",
    "    num_folds = 10\n",
    "    # Define per-fold score containers <-- these are new\n",
    "    acc_per_fold = []\n",
    "    loss_per_fold = []\n",
    "\n",
    "    # Define the K-fold Cross Validator\n",
    "    kfold = KFold(n_splits=num_folds, shuffle=True)\n",
    "\n",
    "    inputs = result\n",
    "    targets = y\n",
    "\n",
    "#     print('# inputs data samples:', inputs.shape[0])\n",
    "#     print('# targets data samples:', targets.shape[0])\n",
    "\n",
    "    # K-fold Cross Validation model evaluation\n",
    "    fold_no = 1\n",
    "    for train, test in kfold.split(inputs, targets):\n",
    "\n",
    "    #     tk = Tokenizer(num_words=NB_WORDS,\n",
    "    #                filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
    "    #                lower=True,\n",
    "    #                split=\" \")\n",
    "    #     tk.fit_on_texts(inputs.iloc[train])\n",
    "\n",
    "    #     X_train_seq = tk.texts_to_sequences(inputs.iloc[train])\n",
    "    #     X_test_seq = tk.texts_to_sequences(inputs.iloc[test])\n",
    "\n",
    "\n",
    "        X_train_oh = inputs.iloc[train]\n",
    "        X_test_oh = inputs.iloc[test]\n",
    "\n",
    "        print('Shape of train set:',X_train_oh.shape)\n",
    "\n",
    "\n",
    "        y_train_le = targets.iloc[train]\n",
    "        y_train_oh = to_categorical(y_train_le)\n",
    "\n",
    "\n",
    "        y_test_le = targets.iloc[test]\n",
    "        y_test_oh = to_categorical(y_test_le)\n",
    "\n",
    "\n",
    "\n",
    "        print('Shape of y:',y_train_oh.shape)\n",
    "\n",
    "        # Define the model architecture\n",
    "        base_model = models.Sequential()\n",
    "        base_model.add(layers.Dense(128, activation='relu', input_shape=(10020,)))\n",
    "        base_model.add(layers.Dense(64, activation='relu'))\n",
    "        base_model.add(layers.Dense(2, activation='softmax'))\n",
    "\n",
    "        # Compile the model\n",
    "        base_model.compile(optimizer='rmsprop'\n",
    "                      , loss='categorical_crossentropy'\n",
    "                      , metrics=['accuracy',tf.keras.metrics.Precision(),tf.keras.metrics.Recall()])\n",
    "\n",
    "\n",
    "        # Generate a print\n",
    "        print('------------------------------------------------------------------------')\n",
    "        print(f'Training for fold {fold_no} ...')\n",
    "#         print('Shape of validation set:',X_test_oh.shape)\n",
    "\n",
    "        # Fit data to model\n",
    "        history = base_model.fit(X_train_oh\n",
    "                           ,y_train_oh\n",
    "                           , epochs=50\n",
    "                           , batch_size=BATCH_SIZE\n",
    "                           , verbose=0)\n",
    "#         print(history.history)\n",
    "\n",
    "\n",
    "        # Generate generalization metrics\n",
    "        from sklearn.metrics import classification_report\n",
    "        y_pred = base_model.predict_classes(X_test_oh)\n",
    "\n",
    "        average_recall = recall_score(y_test_le, y_pred)\n",
    "        average_precision = average_precision_score(y_test_le, y_pred)\n",
    "        print(f'> Fold {fold_no} - Precison: {average_precision} - Recall: {average_recall}%')\n",
    "\n",
    "        acc_per_fold.append(average_precision)\n",
    "        loss_per_fold.append(average_recall)\n",
    "\n",
    "        # Increase fold number\n",
    "        fold_no = fold_no + 1\n",
    "\n",
    "    # == Provide average scores ==\n",
    "    print('------------------------------------------------------------------------')\n",
    "\n",
    "    print(f'> Precison: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "    precision.append(np.mean(acc_per_fold))\n",
    "    print(f'> Recall: {np.mean(loss_per_fold)}')\n",
    "    print('------------------------------------------------------------------------')\n",
    "    recall.append(np.mean(loss_per_fold))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7158642707597193,\n",
       " 0.7083575885846912,\n",
       " 0.6926331377143083,\n",
       " 0.7062406747768744,\n",
       " 0.7143776538386604,\n",
       " 0.6995728339351329,\n",
       " 0.6892576110232785,\n",
       " 0.7115673264317844,\n",
       " 0.7164456075597746,\n",
       " 0.7232422815291462]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.010392133770934668"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.707755898615337"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6999196853333096, 0.7155921118973645)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy.stats as st\n",
    "\n",
    "st.t.interval(0.95, len(precision)-1, loc=np.mean(precision), scale=st.sem(precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8679355474247116,\n",
       " 0.7708181658158775,\n",
       " 0.7743486841376868,\n",
       " 0.6739053892966936,\n",
       " 0.7745870836511568,\n",
       " 0.7732723855092276,\n",
       " 0.6951889324761178,\n",
       " 0.9031060606060606,\n",
       " 0.6879366788817589,\n",
       " 0.7914651440513509]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0702638958740934"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7712564071850642"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7182737487405083, 0.82423906562962)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st.t.interval(0.95, len(recall)-1, loc=np.mean(recall), scale=st.sem(recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier, KerasRegressor\n",
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "\n",
    "base_model = models.Sequential()\n",
    "base_model.add(layers.Dense(128, activation='relu', input_shape=(10020,)))\n",
    "base_model.add(layers.Dense(64, activation='relu'))\n",
    "base_model.add(layers.Dense(2, activation='softmax'))\n",
    "\n",
    "X = result\n",
    "y = y\n",
    "\n",
    "my_model = KerasRegressor(build_fn=basemodel, **sk_params)    \n",
    "my_model.fit(X,y)\n",
    "\n",
    "perm = PermutationImportance(my_model, random_state=1).fit(X,y)\n",
    "eli5.show_weights(perm, feature_names = X.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shape mismatch: objects cannot be broadcast to a single shape",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-117-f54014f284ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Random Forest feature importance via permutation importance w. std. dev.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m plt.bar(range(X.shape[1]), imp_vals[indices],\n\u001b[0;32m---> 18\u001b[0;31m         yerr=std[indices])\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mbar\u001b[0;34m(x, height, width, bottom, align, data, **kwargs)\u001b[0m\n\u001b[1;32m   2455\u001b[0m     return gca().bar(\n\u001b[1;32m   2456\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbottom\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbottom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malign\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malign\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2457\u001b[0;31m         **({\"data\": data} if data is not None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1808\u001b[0m                         \u001b[0;34m\"the Matplotlib list!)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabel_namer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                         RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1810\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1812\u001b[0m         inner.__doc__ = _add_data_doc(inner.__doc__,\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mbar\u001b[0;34m(self, x, height, width, bottom, align, **kwargs)\u001b[0m\n\u001b[1;32m   2249\u001b[0m         x, height, width, y, linewidth = np.broadcast_arrays(\n\u001b[1;32m   2250\u001b[0m             \u001b[0;31m# Make args iterable too.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2251\u001b[0;31m             np.atleast_1d(x), height, width, y, linewidth)\n\u001b[0m\u001b[1;32m   2252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2253\u001b[0m         \u001b[0;31m# Now that units have been converted, set the tick locations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mbroadcast_arrays\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/numpy/lib/stride_tricks.py\u001b[0m in \u001b[0;36mbroadcast_arrays\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_m\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubok\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_m\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m     \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_broadcast_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/numpy/lib/stride_tricks.py\u001b[0m in \u001b[0;36m_broadcast_shape\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0;31m# use the old-iterator because np.nditer does not handle size 0 arrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m     \u001b[0;31m# consistently\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m     \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m     \u001b[0;31m# unfortunately, it cannot handle 32 or more arguments directly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mpos\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m31\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shape mismatch: objects cannot be broadcast to a single shape"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from mlxtend.evaluate import feature_importance_permutation\n",
    "from sklearn.metrics import f1_score\n",
    "imp_vals, imp_all = feature_importance_permutation(\n",
    "    predict_method= base_model.predict_classes, \n",
    "    X=X_test_oh.values,\n",
    "    y=y_test_le,\n",
    "    metric=f1_score,\n",
    "    num_rounds=10,\n",
    "    seed=1)\n",
    "\n",
    "\n",
    "std = np.std(imp_all, axis=1)\n",
    "indices = np.argsort(imp_vals)[::-1]\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Random Forest feature importance via permutation importance w. std. dev.\")\n",
    "plt.bar(range(X.shape[1]), imp_vals[indices],\n",
    "        yerr=std[indices])\n",
    "plt.xticks(range(X.shape[1]), indices)\n",
    "plt.xlim([-1, X.shape[1]])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
