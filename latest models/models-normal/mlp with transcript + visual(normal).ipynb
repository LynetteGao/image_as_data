{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set-up of the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading stopwords: <urlopen error [Errno 61]\n",
      "[nltk_data]     Connection refused>\n"
     ]
    }
   ],
   "source": [
    "# Basic packages\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import re\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "# Packages for data preparation\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Packages for modeling\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import regularizers\n",
    "\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import recall_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_WORDS = 10000  # Parameter indicating the number of words we'll put in the dictionary\n",
    "NB_START_EPOCHS = 30  # Number of epochs we usually start to train with\n",
    "BATCH_SIZE = 512  # Size of the batches used in the mini-batch gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set some parameters that will be used throughout the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We read in the csv with the tweets data and perform a random shuffle. It's a good practice to shuffle the data before splitting between a train and test set. We'll only keep the video decription column as input and the Relvancy column as the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('normal_handlabel_feature.csv')\n",
    "df.columns\n",
    "df = df[df['attitude'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>video_id</th>\n",
       "      <th>attitude</th>\n",
       "      <th>transcript</th>\n",
       "      <th>var_r</th>\n",
       "      <th>var_g</th>\n",
       "      <th>var_b</th>\n",
       "      <th>var_h</th>\n",
       "      <th>var_s</th>\n",
       "      <th>var_v</th>\n",
       "      <th>...</th>\n",
       "      <th>median_r</th>\n",
       "      <th>median_g</th>\n",
       "      <th>median_b</th>\n",
       "      <th>median_h</th>\n",
       "      <th>median_s</th>\n",
       "      <th>median_v</th>\n",
       "      <th>median_bright</th>\n",
       "      <th>median_bright_sd</th>\n",
       "      <th>median_contrast</th>\n",
       "      <th>median_colorful</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>8ocWUAwQMhY</td>\n",
       "      <td>1</td>\n",
       "      <td>hi guys Daniel Alexander cannon logic Authorit...</td>\n",
       "      <td>611.670255</td>\n",
       "      <td>710.533599</td>\n",
       "      <td>704.285521</td>\n",
       "      <td>565.782339</td>\n",
       "      <td>267.640542</td>\n",
       "      <td>616.471287</td>\n",
       "      <td>...</td>\n",
       "      <td>178.297660</td>\n",
       "      <td>182.070140</td>\n",
       "      <td>183.746428</td>\n",
       "      <td>67.315794</td>\n",
       "      <td>5.285804</td>\n",
       "      <td>184.217756</td>\n",
       "      <td>181.100160</td>\n",
       "      <td>92.073127</td>\n",
       "      <td>255.0</td>\n",
       "      <td>10.850100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>m63EyxOC7KM</td>\n",
       "      <td>1</td>\n",
       "      <td>New York new hot 97 app Ebro morning markets a...</td>\n",
       "      <td>452.356980</td>\n",
       "      <td>478.186275</td>\n",
       "      <td>419.175631</td>\n",
       "      <td>355.090668</td>\n",
       "      <td>468.120127</td>\n",
       "      <td>488.873792</td>\n",
       "      <td>...</td>\n",
       "      <td>58.932432</td>\n",
       "      <td>48.911764</td>\n",
       "      <td>50.621008</td>\n",
       "      <td>91.027888</td>\n",
       "      <td>61.974344</td>\n",
       "      <td>60.291964</td>\n",
       "      <td>52.098780</td>\n",
       "      <td>57.203108</td>\n",
       "      <td>223.0</td>\n",
       "      <td>22.048810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>lXnLwtAS6Fk</td>\n",
       "      <td>1</td>\n",
       "      <td>5g 5g Network that's taking people completely ...</td>\n",
       "      <td>255.602928</td>\n",
       "      <td>227.562307</td>\n",
       "      <td>115.534510</td>\n",
       "      <td>82.652435</td>\n",
       "      <td>56.376545</td>\n",
       "      <td>233.168950</td>\n",
       "      <td>...</td>\n",
       "      <td>162.885660</td>\n",
       "      <td>127.777572</td>\n",
       "      <td>135.631998</td>\n",
       "      <td>73.192558</td>\n",
       "      <td>136.100062</td>\n",
       "      <td>191.345718</td>\n",
       "      <td>139.447290</td>\n",
       "      <td>43.736392</td>\n",
       "      <td>183.0</td>\n",
       "      <td>102.317861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>3dGe2FXOQOw</td>\n",
       "      <td>1</td>\n",
       "      <td>hey guys welcome show today we're gonna discus...</td>\n",
       "      <td>346.926190</td>\n",
       "      <td>328.023541</td>\n",
       "      <td>306.858307</td>\n",
       "      <td>148.598571</td>\n",
       "      <td>82.680316</td>\n",
       "      <td>307.033028</td>\n",
       "      <td>...</td>\n",
       "      <td>199.799596</td>\n",
       "      <td>195.907756</td>\n",
       "      <td>194.418024</td>\n",
       "      <td>27.569884</td>\n",
       "      <td>9.146088</td>\n",
       "      <td>199.960340</td>\n",
       "      <td>196.905496</td>\n",
       "      <td>33.385873</td>\n",
       "      <td>135.0</td>\n",
       "      <td>12.993900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>3ajBR3R8doM</td>\n",
       "      <td>1</td>\n",
       "      <td>hey everyone I'm I'm Shawn oh we've got bit ey...</td>\n",
       "      <td>29.583790</td>\n",
       "      <td>22.456832</td>\n",
       "      <td>16.950847</td>\n",
       "      <td>20.298046</td>\n",
       "      <td>39.189503</td>\n",
       "      <td>29.754383</td>\n",
       "      <td>...</td>\n",
       "      <td>143.555642</td>\n",
       "      <td>127.917176</td>\n",
       "      <td>135.183554</td>\n",
       "      <td>54.865530</td>\n",
       "      <td>46.820690</td>\n",
       "      <td>151.462780</td>\n",
       "      <td>133.429320</td>\n",
       "      <td>69.593465</td>\n",
       "      <td>226.0</td>\n",
       "      <td>47.625559</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0     video_id  attitude  \\\n",
       "5            5  8ocWUAwQMhY         1   \n",
       "7            7  m63EyxOC7KM         1   \n",
       "10          10  lXnLwtAS6Fk         1   \n",
       "21          22  3dGe2FXOQOw         1   \n",
       "28          29  3ajBR3R8doM         1   \n",
       "\n",
       "                                           transcript       var_r       var_g  \\\n",
       "5   hi guys Daniel Alexander cannon logic Authorit...  611.670255  710.533599   \n",
       "7   New York new hot 97 app Ebro morning markets a...  452.356980  478.186275   \n",
       "10  5g 5g Network that's taking people completely ...  255.602928  227.562307   \n",
       "21  hey guys welcome show today we're gonna discus...  346.926190  328.023541   \n",
       "28  hey everyone I'm I'm Shawn oh we've got bit ey...   29.583790   22.456832   \n",
       "\n",
       "         var_b       var_h       var_s       var_v  ...    median_r  \\\n",
       "5   704.285521  565.782339  267.640542  616.471287  ...  178.297660   \n",
       "7   419.175631  355.090668  468.120127  488.873792  ...   58.932432   \n",
       "10  115.534510   82.652435   56.376545  233.168950  ...  162.885660   \n",
       "21  306.858307  148.598571   82.680316  307.033028  ...  199.799596   \n",
       "28   16.950847   20.298046   39.189503   29.754383  ...  143.555642   \n",
       "\n",
       "      median_g    median_b   median_h    median_s    median_v  median_bright  \\\n",
       "5   182.070140  183.746428  67.315794    5.285804  184.217756     181.100160   \n",
       "7    48.911764   50.621008  91.027888   61.974344   60.291964      52.098780   \n",
       "10  127.777572  135.631998  73.192558  136.100062  191.345718     139.447290   \n",
       "21  195.907756  194.418024  27.569884    9.146088  199.960340     196.905496   \n",
       "28  127.917176  135.183554  54.865530   46.820690  151.462780     133.429320   \n",
       "\n",
       "    median_bright_sd  median_contrast  median_colorful  \n",
       "5          92.073127            255.0        10.850100  \n",
       "7          57.203108            223.0        22.048810  \n",
       "10         43.736392            183.0       102.317861  \n",
       "21         33.385873            135.0        12.993900  \n",
       "28         69.593465            226.0        47.625559  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_stopwords(input_text):\n",
    "    stopwords_list = stopwords.words('english')\n",
    "    stopwords_list.append('The')\n",
    "    # Some words which might indicate a certain sentiment are kept via a whitelist\n",
    "    whitelist = [\"n't\", \"not\", \"no\"]\n",
    "    words = str(input_text).split() \n",
    "    clean_words = [word for word in words if (word not in stopwords_list or word in whitelist) and len(word) > 1] \n",
    "    return \" \".join(clean_words) \n",
    "    \n",
    "def remove_mentions(input_text):\n",
    "    return re.sub(r'@\\w+', '', input_text)\n",
    "\n",
    "\n",
    "       \n",
    "df.transcript = df.transcript.apply(remove_stopwords).apply(remove_mentions)\n",
    "df.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['transcript']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>hi guys Daniel Alexander cannon logic Authorit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>New York new hot 97 app Ebro morning markets a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5g 5g Network that's taking people completely ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>hey guys welcome show today we're gonna discus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>hey everyone I'm I'm Shawn oh we've got bit ey...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727</th>\n",
       "      <td>CaptionUnavailable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728</th>\n",
       "      <td>CaptionUnavailable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729</th>\n",
       "      <td>kovat 19 Diagnostics performing nasopharyngeal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>anyone anyone thinking taking chances take loo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>731</th>\n",
       "      <td>neurologists know kovat 19 novel coronavirus k...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>635 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            transcript\n",
       "5    hi guys Daniel Alexander cannon logic Authorit...\n",
       "7    New York new hot 97 app Ebro morning markets a...\n",
       "10   5g 5g Network that's taking people completely ...\n",
       "21   hey guys welcome show today we're gonna discus...\n",
       "28   hey everyone I'm I'm Shawn oh we've got bit ey...\n",
       "..                                                 ...\n",
       "727                                 CaptionUnavailable\n",
       "728                                 CaptionUnavailable\n",
       "729  kovat 19 Diagnostics performing nasopharyngeal...\n",
       "730  anyone anyone thinking taking chances take loo...\n",
       "731  neurologists know kovat 19 novel coronavirus k...\n",
       "\n",
       "[635 rows x 1 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X[(X[\"transcript\"] != 'CaptionUnavailable') & (X[\"transcript\"] != 'VideoUnavailable')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(460, 1)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>hi guys Daniel Alexander cannon logic Authorit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>New York new hot 97 app Ebro morning markets a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5g 5g Network that's taking people completely ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>hey guys welcome show today we're gonna discus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>hey everyone I'm I'm Shawn oh we've got bit ey...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>725</th>\n",
       "      <td>hey guys Trisha Trish advisor today gonna diff...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>726</th>\n",
       "      <td>personal protective equipment including masks ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729</th>\n",
       "      <td>kovat 19 Diagnostics performing nasopharyngeal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>anyone anyone thinking taking chances take loo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>731</th>\n",
       "      <td>neurologists know kovat 19 novel coronavirus k...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>460 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            transcript\n",
       "5    hi guys Daniel Alexander cannon logic Authorit...\n",
       "7    New York new hot 97 app Ebro morning markets a...\n",
       "10   5g 5g Network that's taking people completely ...\n",
       "21   hey guys welcome show today we're gonna discus...\n",
       "28   hey everyone I'm I'm Shawn oh we've got bit ey...\n",
       "..                                                 ...\n",
       "725  hey guys Trisha Trish advisor today gonna diff...\n",
       "726  personal protective equipment including masks ...\n",
       "729  kovat 19 Diagnostics performing nasopharyngeal...\n",
       "730  anyone anyone thinking taking chances take loo...\n",
       "731  neurologists know kovat 19 novel coronavirus k...\n",
       "\n",
       "[460 rows x 1 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "df['attitude'] = le.fit_transform(df['attitude'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5      0\n",
       "7      0\n",
       "10     0\n",
       "21     0\n",
       "28     0\n",
       "      ..\n",
       "725    1\n",
       "726    1\n",
       "729    1\n",
       "730    1\n",
       "731    1\n",
       "Name: attitude, Length: 460, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df['attitude'][(df[\"transcript\"] != 'CaptionUnavailable') & (df[\"transcript\"] != 'VideoUnavailable')]\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing we'll do is removing stopwords. These words do not have any value for predicting the sentiment.Also, we remove the http link in the texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "visual = df[['var_r', 'var_g', 'var_b',\n",
    "       'var_h', 'var_s', 'var_v', 'var_bright', 'var_bright_sd',\n",
    "       'var_contrast', 'var_colorful', 'median_r', 'median_g', 'median_b',\n",
    "       'median_h', 'median_s', 'median_v', 'median_bright', 'median_bright_sd',\n",
    "       'median_contrast', 'median_colorful']][(df[\"transcript\"] != 'CaptionUnavailable') & (df[\"transcript\"] != 'VideoUnavailable')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_WORDS = 10000\n",
    "tk = Tokenizer(num_words=NB_WORDS,\n",
    "               filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
    "               lower=True,\n",
    "               split=\" \")\n",
    "tk.fit_on_texts(X.transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_seq = tk.texts_to_sequences(X.transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_seq(seqs, nb_features = NB_WORDS):\n",
    "    ohs = np.zeros((len(seqs), nb_features))\n",
    "    for i, s in enumerate(seqs):\n",
    "        ohs[i, s] = 1.\n",
    "    return ohs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_oh = one_hot_seq(x_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(460, 20)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visual.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(460, 10000)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_oh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "result = pd.DataFrame(pd.np.column_stack([visual, X_oh]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of            0            1            2           3           4      \\\n",
       "0     611.670255   710.533599   704.285521  565.782339  267.640542   \n",
       "1     452.356980   478.186275   419.175631  355.090668  468.120127   \n",
       "2     255.602928   227.562307   115.534510   82.652435   56.376545   \n",
       "3     346.926190   328.023541   306.858307  148.598571   82.680316   \n",
       "4      29.583790    22.456832    16.950847   20.298046   39.189503   \n",
       "..           ...          ...          ...         ...         ...   \n",
       "455  2356.947868  2175.446373  2087.640234  413.396530  535.737994   \n",
       "456  2194.431494  2361.411495  2470.254090  399.127900  318.185826   \n",
       "457   820.036766  1169.309838  1175.549922  335.253698  132.699446   \n",
       "458   273.171022   421.142066   412.096403   58.687157  346.328848   \n",
       "459   106.808154   139.723951   134.030401  239.983373   74.746906   \n",
       "\n",
       "           5            6           7            8           9      ...  \\\n",
       "0     616.471287   661.184079  185.405393    48.207604  226.281947  ...   \n",
       "1     488.873792   444.666475   45.390127   783.693329   53.253433  ...   \n",
       "2     233.168950   201.218955   67.706699   411.482719   23.133398  ...   \n",
       "3     307.033028   328.973162  179.992448   851.291335   56.403953  ...   \n",
       "4      29.754383    20.640310    5.748194    48.051666   10.437365  ...   \n",
       "..           ...          ...         ...          ...         ...  ...   \n",
       "455  2313.298897  2198.912054   98.459260  1079.165688  183.170198  ...   \n",
       "456  2046.570149  2313.278504  433.935300  4425.830168  224.939034  ...   \n",
       "457   853.096095  1051.933567  421.973576  3692.410128   67.948962  ...   \n",
       "458   274.837309   329.884662   38.341451   633.204244  133.186585  ...   \n",
       "459    88.435287   123.775648  117.920362  1094.601656  206.854300  ...   \n",
       "\n",
       "     10010  10011  10012  10013  10014  10015  10016  10017  10018  10019  \n",
       "0      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "1      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "2      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "3      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "4      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "..     ...    ...    ...    ...    ...    ...    ...    ...    ...    ...  \n",
       "455    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "456    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "457    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "458    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "459    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "\n",
       "[460 rows x 10020 columns]>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate K-fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train set: (414, 10020)\n",
      "Shape of y: (414, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "WARNING:tensorflow:From <ipython-input-43-34b29bc68726>:81: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "> Fold 1 - Precison: 0.6811036789297659 - Recall: 0.34615384615384615%\n",
      "Shape of train set: (414, 10020)\n",
      "Shape of y: (414, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "> Fold 2 - Precison: 0.717948717948718 - Recall: 1.0%\n",
      "Shape of train set: (414, 10020)\n",
      "Shape of y: (414, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "> Fold 3 - Precison: 0.8005115089514065 - Recall: 0.23529411764705882%\n",
      "Shape of train set: (414, 10020)\n",
      "Shape of y: (414, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "> Fold 4 - Precison: 0.6567565520375701 - Recall: 0.9642857142857143%\n",
      "Shape of train set: (414, 10020)\n",
      "Shape of y: (414, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbc8672db90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 5 - Precison: 0.7494075542873725 - Recall: 0.8275862068965517%\n",
      "Shape of train set: (414, 10020)\n",
      "Shape of y: (414, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 6 ...\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbca940cf80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 6 - Precison: 0.6814814814814815 - Recall: 0.23333333333333334%\n",
      "Shape of train set: (414, 10020)\n",
      "Shape of y: (414, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 7 ...\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbc7b12d320> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 7 - Precison: 0.6880405950870718 - Recall: 0.9310344827586207%\n",
      "Shape of train set: (414, 10020)\n",
      "Shape of y: (414, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 8 ...\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbc84246440> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 8 - Precison: 0.846153846153846 - Recall: 0.8076923076923077%\n",
      "Shape of train set: (414, 10020)\n",
      "Shape of y: (414, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 9 ...\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbc7b150d40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 9 - Precison: 0.7019827998088868 - Recall: 0.39285714285714285%\n",
      "Shape of train set: (414, 10020)\n",
      "Shape of y: (414, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 10 ...\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbc8672d3b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 10 - Precison: 0.796576824709817 - Recall: 0.6153846153846154%\n",
      "------------------------------------------------------------------------\n",
      "> Precison: 0.7319963559395937 (+- 0.06002761809496949)\n",
      "> Recall: 0.6353621767009191\n",
      "------------------------------------------------------------------------\n",
      "Shape of train set: (414, 10020)\n",
      "Shape of y: (414, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbca7f98f80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Fold 1 - Precison: 0.6666666666666666 - Recall: 1.0%\n",
      "Shape of train set: (414, 10020)\n",
      "Shape of y: (414, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbc89362320> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 2 - Precison: 0.6811167586938239 - Recall: 0.9655172413793104%\n",
      "Shape of train set: (414, 10020)\n",
      "Shape of y: (414, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbc77bc8440> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 3 - Precison: 0.7766616691654173 - Recall: 0.4827586206896552%\n",
      "Shape of train set: (414, 10020)\n",
      "Shape of y: (414, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbc76e373b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 4 - Precison: 0.75 - Recall: 1.0%\n",
      "Shape of train set: (414, 10020)\n",
      "Shape of y: (414, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbcc30beb90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 5 - Precison: 0.5741800152555301 - Recall: 0.9166666666666666%\n",
      "Shape of train set: (414, 10020)\n",
      "Shape of y: (414, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 6 ...\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbc8a554830> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 6 - Precison: 0.8008495752123939 - Recall: 0.8888888888888888%\n",
      "Shape of train set: (414, 10020)\n",
      "Shape of y: (414, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 7 ...\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbc8935fb00> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 7 - Precison: 0.7845410628019324 - Recall: 0.1111111111111111%\n",
      "Shape of train set: (414, 10020)\n",
      "Shape of y: (414, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 8 ...\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbc8a645dd0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 8 - Precison: 0.7643998513563731 - Recall: 0.6153846153846154%\n",
      "Shape of train set: (414, 10020)\n",
      "Shape of y: (414, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 9 ...\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbca946b290> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 9 - Precison: 0.6818181818181818 - Recall: 1.0%\n",
      "Shape of train set: (414, 10020)\n",
      "Shape of y: (414, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 10 ...\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbc82fb63b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Fold 10 - Precison: 0.6097560975609756 - Recall: 1.0%\n",
      "------------------------------------------------------------------------\n",
      "> Precison: 0.7089989878531294 (+- 0.07403057448419645)\n",
      "> Recall: 0.7980327144120247\n",
      "------------------------------------------------------------------------\n",
      "Shape of train set: (414, 10020)\n",
      "Shape of y: (414, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbca938ab90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 1 - Precison: 0.6469979296066253 - Recall: 0.2222222222222222%\n",
      "Shape of train set: (414, 10020)\n",
      "Shape of y: (414, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbca9079b90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 2 - Precison: 0.825 - Recall: 1.0%\n",
      "Shape of train set: (414, 10020)\n",
      "Shape of y: (414, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbca7fbff80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 3 - Precison: 0.7996376811594202 - Recall: 0.4375%\n",
      "Shape of train set: (414, 10020)\n",
      "Shape of y: (414, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbc765d0320> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 4 - Precison: 0.7409420289855073 - Recall: 0.8260869565217391%\n",
      "Shape of train set: (414, 10020)\n",
      "Shape of y: (414, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbc8a580440> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 5 - Precison: 0.5620298355221217 - Recall: 0.8181818181818182%\n",
      "Shape of train set: (414, 10020)\n",
      "Shape of y: (414, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 6 ...\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbc8a62c950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 6 - Precison: 0.641304347826087 - Recall: 0.3333333333333333%\n",
      "Shape of train set: (414, 10020)\n",
      "Shape of y: (414, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 7 ...\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbca9079950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 7 - Precison: 0.8247282608695652 - Recall: 0.9375%\n",
      "Shape of train set: (414, 10020)\n",
      "Shape of y: (414, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 8 ...\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbc66b49f80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 8 - Precison: 0.7804372224662078 - Recall: 0.9629629629629629%\n",
      "Shape of train set: (414, 10020)\n",
      "Shape of y: (414, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 9 ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbc7b147320> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 9 - Precison: 0.7589664763577807 - Recall: 0.24242424242424243%\n",
      "Shape of train set: (414, 10020)\n",
      "Shape of y: (414, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 10 ...\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbc82fe7440> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 10 - Precison: 0.7290372670807455 - Recall: 0.5357142857142857%\n",
      "------------------------------------------------------------------------\n",
      "> Precison: 0.7309081049874061 (+- 0.0832547098202288)\n",
      "> Recall: 0.6315925821360604\n",
      "------------------------------------------------------------------------\n",
      "Shape of train set: (414, 10020)\n",
      "Shape of y: (414, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbc66819710> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 1 - Precison: 0.8422159887798036 - Recall: 0.5161290322580645%\n",
      "Shape of train set: (414, 10020)\n",
      "Shape of y: (414, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbca7b620e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 2 - Precison: 0.715797526456713 - Recall: 0.2903225806451613%\n",
      "Shape of train set: (414, 10020)\n",
      "Shape of y: (414, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbca935b3b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 3 - Precison: 0.5581395348837209 - Recall: 1.0%\n",
      "Shape of train set: (414, 10020)\n",
      "Shape of y: (414, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbc76e259e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 4 - Precison: 0.6859008767221328 - Recall: 0.5185185185185185%\n",
      "Shape of train set: (414, 10020)\n",
      "Shape of y: (414, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbc892eab90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 5 - Precison: 0.631578947368421 - Recall: 1.0%\n",
      "Shape of train set: (414, 10020)\n",
      "Shape of y: (414, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 6 ...\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbc766a4290> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 6 - Precison: 0.7785757897104663 - Recall: 0.9696969696969697%\n",
      "Shape of train set: (414, 10020)\n",
      "Shape of y: (414, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 7 ...\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbc75d025f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Fold 7 - Precison: 0.7859025032938076 - Recall: 0.24242424242424243%\n",
      "Shape of train set: (414, 10020)\n",
      "Shape of y: (414, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 8 ...\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbc760aac20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 8 - Precison: 0.8571428571428571 - Recall: 1.0%\n",
      "Shape of train set: (414, 10020)\n",
      "Shape of y: (414, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 9 ...\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbca7b62200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 9 - Precison: 0.7714604236343368 - Recall: 0.7692307692307693%\n",
      "Shape of train set: (414, 10020)\n",
      "Shape of y: (414, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 10 ...\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbc760ad7a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 10 - Precison: 0.6097560975609756 - Recall: 1.0%\n",
      "------------------------------------------------------------------------\n",
      "> Precison: 0.7236470545553234 (+- 0.09559579547447557)\n",
      "> Recall: 0.7306322112773725\n",
      "------------------------------------------------------------------------\n",
      "Shape of train set: (414, 10020)\n",
      "Shape of y: (414, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbc84155cb0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 1 - Precison: 0.6567565520375701 - Recall: 0.9642857142857143%\n",
      "Shape of train set: (414, 10020)\n",
      "Shape of y: (414, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbca93a43b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 2 - Precison: 0.666608695652174 - Recall: 0.48%\n",
      "Shape of train set: (414, 10020)\n",
      "Shape of y: (414, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbc892f4680> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 3 - Precison: 0.6744186046511628 - Recall: 1.0%\n",
      "Shape of train set: (414, 10020)\n",
      "Shape of y: (414, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbca8301e60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 4 - Precison: 0.7586399108138239 - Recall: 0.7777777777777778%\n",
      "Shape of train set: (414, 10020)\n",
      "Shape of y: (414, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbca94db7a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 5 - Precison: 0.8 - Recall: 1.0%\n",
      "Shape of train set: (414, 10020)\n",
      "Shape of y: (414, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 6 ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbc77bbacb0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 6 - Precison: 0.7015810276679841 - Recall: 0.7391304347826086%\n",
      "Shape of train set: (414, 10020)\n",
      "Shape of y: (414, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 7 ...\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbc8670a3b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 7 - Precison: 0.6590909090909091 - Recall: 1.0%\n",
      "Shape of train set: (414, 10020)\n",
      "Shape of y: (414, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 8 ...\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbc6707f710> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 8 - Precison: 0.8095238095238095 - Recall: 1.0%\n",
      "Shape of train set: (414, 10020)\n",
      "Shape of y: (414, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 9 ...\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbc6682f680> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 9 - Precison: 0.7624223602484472 - Recall: 0.39285714285714285%\n",
      "Shape of train set: (414, 10020)\n",
      "Shape of y: (414, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 10 ...\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbca7d005f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 10 - Precison: 0.725685618729097 - Recall: 0.48%\n",
      "------------------------------------------------------------------------\n",
      "> Precison: 0.7214727488414978 (+- 0.05540311614562957)\n",
      "> Recall: 0.7834051069703243\n",
      "------------------------------------------------------------------------\n",
      "Shape of train set: (414, 10020)\n",
      "Shape of y: (414, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbca941b290> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 1 - Precison: 0.6086956521739131 - Recall: 1.0%\n",
      "Shape of train set: (414, 10020)\n",
      "Shape of y: (414, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbc892e9440> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 2 - Precison: 0.6526400542418849 - Recall: 0.9259259259259259%\n",
      "Shape of train set: (414, 10020)\n",
      "Shape of y: (414, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbc668ae7a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 3 - Precison: 0.7345995423340961 - Recall: 0.64%\n",
      "Shape of train set: (414, 10020)\n",
      "Shape of y: (414, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbc8938acb0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Fold 4 - Precison: 0.6666666666666666 - Recall: 1.0%\n",
      "Shape of train set: (414, 10020)\n",
      "Shape of y: (414, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbca7fbecb0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 5 - Precison: 0.7384575569358178 - Recall: 0.8214285714285714%\n",
      "Shape of train set: (414, 10020)\n",
      "Shape of y: (414, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 6 ...\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbc8a654440> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 6 - Precison: 0.7363318340829585 - Recall: 0.4482758620689655%\n",
      "Shape of train set: (414, 10020)\n",
      "Shape of y: (414, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 7 ...\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbc76e447a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 7 - Precison: 0.813953488372093 - Recall: 1.0%\n",
      "Shape of train set: (414, 10020)\n",
      "Shape of y: (414, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 8 ...\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbca7d80cb0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 8 - Precison: 0.6291771469637082 - Recall: 0.9545454545454546%\n",
      "Shape of train set: (414, 10020)\n",
      "Shape of y: (414, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 9 ...\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbc55cb23b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 9 - Precison: 0.8618925831202046 - Recall: 0.47058823529411764%\n",
      "Shape of train set: (414, 10020)\n",
      "Shape of y: (414, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 10 ...\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbca7b628c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 10 - Precison: 0.8349218248018847 - Recall: 0.8928571428571429%\n",
      "------------------------------------------------------------------------\n",
      "> Precison: 0.7277336349693229 (+- 0.08391037474815455)\n",
      "> Recall: 0.8153621192120178\n",
      "------------------------------------------------------------------------\n",
      "Shape of train set: (414, 10020)\n",
      "Shape of y: (414, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbca84f0170> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 1 - Precison: 0.6735785953177258 - Recall: 0.46153846153846156%\n",
      "Shape of train set: (414, 10020)\n",
      "Shape of y: (414, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbc867e87a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 2 - Precison: 0.8408584169453734 - Recall: 0.9166666666666666%\n",
      "Shape of train set: (414, 10020)\n",
      "Shape of y: (414, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbca7ea8cb0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 3 - Precison: 0.7453416149068324 - Recall: 0.7142857142857143%\n",
      "Shape of train set: (414, 10020)\n",
      "Shape of y: (414, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbc760543b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 4 - Precison: 0.7208196976780427 - Recall: 0.45161290322580644%\n",
      "Shape of train set: (414, 10020)\n",
      "Shape of y: (414, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbc55c40710> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 5 - Precison: 0.6842105263157895 - Recall: 1.0%\n",
      "Shape of train set: (414, 10020)\n",
      "Shape of y: (414, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 6 ...\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbc566577a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 6 - Precison: 0.7833816425120773 - Recall: 0.4666666666666667%\n",
      "Shape of train set: (414, 10020)\n",
      "Shape of y: (414, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 7 ...\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbca935b5f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 7 - Precison: 0.6511627906976745 - Recall: 1.0%\n",
      "Shape of train set: (414, 10020)\n",
      "Shape of y: (414, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 8 ...\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbca84b4b90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 8 - Precison: 0.7816571512223687 - Recall: 0.7037037037037037%\n",
      "Shape of train set: (414, 10020)\n",
      "Shape of y: (414, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 9 ...\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbc55d12d40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 9 - Precison: 0.764726507713885 - Recall: 0.45161290322580644%\n",
      "Shape of train set: (414, 10020)\n",
      "Shape of y: (414, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 10 ...\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbc765fee60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 10 - Precison: 0.7104209799861974 - Recall: 0.6190476190476191%\n",
      "------------------------------------------------------------------------\n",
      "> Precison: 0.7356157923295965 (+- 0.055584661770125665)\n",
      "> Recall: 0.6785134638360445\n",
      "------------------------------------------------------------------------\n",
      "Shape of train set: (414, 10020)\n",
      "Shape of y: (414, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbc841ef290> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Fold 1 - Precison: 0.711304347826087 - Recall: 0.4%\n",
      "Shape of train set: (414, 10020)\n",
      "Shape of y: (414, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbca7d00dd0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 2 - Precison: 0.8001402524544179 - Recall: 0.3870967741935484%\n",
      "Shape of train set: (414, 10020)\n",
      "Shape of y: (414, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbc668ae4d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 3 - Precison: 0.6428571428571429 - Recall: 1.0%\n",
      "Shape of train set: (414, 10020)\n",
      "Shape of y: (414, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbc7a6b87a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 4 - Precison: 0.7896213183730716 - Recall: 0.3548387096774194%\n",
      "Shape of train set: (414, 10020)\n",
      "Shape of y: (414, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbca90a4cb0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 5 - Precison: 0.8383260522848623 - Recall: 0.9696969696969697%\n",
      "Shape of train set: (414, 10020)\n",
      "Shape of y: (414, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 6 ...\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbc566863b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 6 - Precison: 0.7451274362818592 - Recall: 0.3103448275862069%\n",
      "Shape of train set: (414, 10020)\n",
      "Shape of y: (414, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 7 ...\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbc66a48710> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 7 - Precison: 0.7637163561076604 - Recall: 0.9166666666666666%\n",
      "Shape of train set: (414, 10020)\n",
      "Shape of y: (414, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 8 ...\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbca8316440> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 8 - Precison: 0.6352657004830917 - Recall: 0.34782608695652173%\n",
      "Shape of train set: (414, 10020)\n",
      "Shape of y: (414, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 9 ...\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbc865f3f80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 9 - Precison: 0.6426086956521739 - Recall: 0.48%\n",
      "Shape of train set: (414, 10020)\n",
      "Shape of y: (414, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 10 ...\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbca7a177a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Fold 10 - Precison: 0.7293906810035842 - Recall: 0.25806451612903225%\n",
      "------------------------------------------------------------------------\n",
      "> Precison: 0.7298357983323951 (+- 0.06791896378018483)\n",
      "> Recall: 0.5424534550906366\n",
      "------------------------------------------------------------------------\n",
      "Shape of train set: (414, 10020)\n",
      "Shape of y: (414, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbc7a6becb0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 1 - Precison: 0.6428571428571429 - Recall: 1.0%\n",
      "Shape of train set: (414, 10020)\n",
      "Shape of y: (414, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbc765fb3b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 2 - Precison: 0.7197868008144688 - Recall: 0.24242424242424243%\n",
      "Shape of train set: (414, 10020)\n",
      "Shape of y: (414, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbc866a3710> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 3 - Precison: 0.7807052694850731 - Recall: 0.41935483870967744%\n",
      "Shape of train set: (414, 10020)\n",
      "Shape of y: (414, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbca7fc39e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 4 - Precison: 0.6455716586151369 - Recall: 0.5185185185185185%\n",
      "Shape of train set: (414, 10020)\n",
      "Shape of y: (414, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbca9bad290> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 5 - Precison: 0.6319875776397516 - Recall: 0.5%\n",
      "Shape of train set: (414, 10020)\n",
      "Shape of y: (414, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 6 ...\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbc766af7a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 6 - Precison: 0.8218355539971949 - Recall: 0.8709677419354839%\n",
      "Shape of train set: (414, 10020)\n",
      "Shape of y: (414, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 7 ...\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbc8a5a1950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 7 - Precison: 0.7451207729468599 - Recall: 0.43333333333333335%\n",
      "Shape of train set: (414, 10020)\n",
      "Shape of y: (414, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 8 ...\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbc65e16b00> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 8 - Precison: 0.725 - Recall: 1.0%\n",
      "Shape of train set: (414, 10020)\n",
      "Shape of y: (414, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 9 ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbc55dd8cb0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 9 - Precison: 0.5836903499469777 - Recall: 0.96%\n",
      "Shape of train set: (414, 10020)\n",
      "Shape of y: (414, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 10 ...\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbc4692ef80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 10 - Precison: 0.7127269698484091 - Recall: 0.896551724137931%\n",
      "------------------------------------------------------------------------\n",
      "> Precison: 0.7009282096151015 (+- 0.06996025955355181)\n",
      "> Recall: 0.6841150399059186\n",
      "------------------------------------------------------------------------\n",
      "Shape of train set: (414, 10020)\n",
      "Shape of y: (414, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbca935b680> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 1 - Precison: 0.8145094119606863 - Recall: 0.5862068965517241%\n",
      "Shape of train set: (414, 10020)\n",
      "Shape of y: (414, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbc766c6440> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 2 - Precison: 0.7560975609756098 - Recall: 1.0%\n",
      "Shape of train set: (414, 10020)\n",
      "Shape of y: (414, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbc7a6a14d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 3 - Precison: 0.7157190635451505 - Recall: 0.6923076923076923%\n",
      "Shape of train set: (414, 10020)\n",
      "Shape of y: (414, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbca9b90cb0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 4 - Precison: 0.7489072923855532 - Recall: 0.8148148148148148%\n",
      "Shape of train set: (414, 10020)\n",
      "Shape of y: (414, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbc770cd3b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 5 - Precison: 0.6862557732122949 - Recall: 0.6153846153846154%\n",
      "Shape of train set: (414, 10020)\n",
      "Shape of y: (414, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 6 ...\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbc66a5b710> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 6 - Precison: 0.6136363636363636 - Recall: 1.0%\n",
      "Shape of train set: (414, 10020)\n",
      "Shape of y: (414, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 7 ...\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbc89834440> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Fold 7 - Precison: 0.7384575569358178 - Recall: 0.8214285714285714%\n",
      "Shape of train set: (414, 10020)\n",
      "Shape of y: (414, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 8 ...\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbca7d00710> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 8 - Precison: 0.6976744186046512 - Recall: 1.0%\n",
      "Shape of train set: (414, 10020)\n",
      "Shape of y: (414, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 9 ...\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbc7a6a77a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 9 - Precison: 0.8098259482698842 - Recall: 0.9393939393939394%\n",
      "Shape of train set: (414, 10020)\n",
      "Shape of y: (414, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 10 ...\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbc8a54fcb0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 10 - Precison: 0.5997657736788171 - Recall: 0.25925925925925924%\n",
      "------------------------------------------------------------------------\n",
      "> Precison: 0.7180849163204828 (+- 0.06846044442512329)\n",
      "> Recall: 0.7728795789140618\n",
      "------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "precision = []\n",
    "recall = []\n",
    "\n",
    "for i in range(10):\n",
    "    \n",
    "    num_folds = 10\n",
    "    # Define per-fold score containers <-- these are new\n",
    "    acc_per_fold = []\n",
    "    loss_per_fold = []\n",
    "\n",
    "    # Define the K-fold Cross Validator\n",
    "    kfold = KFold(n_splits=num_folds, shuffle=True)\n",
    "\n",
    "    inputs = result\n",
    "    targets = y\n",
    "\n",
    "#     print('# inputs data samples:', inputs.shape[0])\n",
    "#     print('# targets data samples:', targets.shape[0])\n",
    "\n",
    "    # K-fold Cross Validation model evaluation\n",
    "    fold_no = 1\n",
    "    for train, test in kfold.split(inputs, targets):\n",
    "\n",
    "    #     tk = Tokenizer(num_words=NB_WORDS,\n",
    "    #                filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
    "    #                lower=True,\n",
    "    #                split=\" \")\n",
    "    #     tk.fit_on_texts(inputs.iloc[train])\n",
    "\n",
    "    #     X_train_seq = tk.texts_to_sequences(inputs.iloc[train])\n",
    "    #     X_test_seq = tk.texts_to_sequences(inputs.iloc[test])\n",
    "\n",
    "\n",
    "        X_train_oh = inputs.iloc[train]\n",
    "        X_test_oh = inputs.iloc[test]\n",
    "\n",
    "        print('Shape of train set:',X_train_oh.shape)\n",
    "\n",
    "\n",
    "        y_train_le = targets.iloc[train]\n",
    "        y_train_oh = to_categorical(y_train_le)\n",
    "\n",
    "\n",
    "        y_test_le = targets.iloc[test]\n",
    "        y_test_oh = to_categorical(y_test_le)\n",
    "\n",
    "\n",
    "\n",
    "        print('Shape of y:',y_train_oh.shape)\n",
    "\n",
    "        # Define the model architecture\n",
    "        base_model = models.Sequential()\n",
    "        base_model.add(layers.Dense(128, activation='relu', input_shape=(10020,)))\n",
    "        base_model.add(layers.Dense(64, activation='relu'))\n",
    "        base_model.add(layers.Dense(2, activation='softmax'))\n",
    "\n",
    "        # Compile the model\n",
    "        base_model.compile(optimizer='rmsprop'\n",
    "                      , loss='categorical_crossentropy'\n",
    "                      , metrics=['accuracy',tf.keras.metrics.Precision(),tf.keras.metrics.Recall()])\n",
    "\n",
    "\n",
    "        # Generate a print\n",
    "        print('------------------------------------------------------------------------')\n",
    "        print(f'Training for fold {fold_no} ...')\n",
    "#         print('Shape of validation set:',X_test_oh.shape)\n",
    "\n",
    "        # Fit data to model\n",
    "        history = base_model.fit(X_train_oh\n",
    "                           ,y_train_oh\n",
    "                           , epochs=50\n",
    "                           , batch_size=BATCH_SIZE\n",
    "                           , verbose=0)\n",
    "#         print(history.history)\n",
    "\n",
    "\n",
    "        # Generate generalization metrics\n",
    "        from sklearn.metrics import classification_report\n",
    "        y_pred = base_model.predict_classes(X_test_oh)\n",
    "\n",
    "        average_recall = recall_score(y_test_le, y_pred)\n",
    "        average_precision = average_precision_score(y_test_le, y_pred)\n",
    "        print(f'> Fold {fold_no} - Precison: {average_precision} - Recall: {average_recall}%')\n",
    "\n",
    "        acc_per_fold.append(average_precision)\n",
    "        loss_per_fold.append(average_recall)\n",
    "\n",
    "        # Increase fold number\n",
    "        fold_no = fold_no + 1\n",
    "\n",
    "    # == Provide average scores ==\n",
    "    print('------------------------------------------------------------------------')\n",
    "\n",
    "    print(f'> Precison: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "    precision.append(np.mean(acc_per_fold))\n",
    "    print(f'> Recall: {np.mean(loss_per_fold)}')\n",
    "    print('------------------------------------------------------------------------')\n",
    "    recall.append(np.mean(loss_per_fold))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7319963559395937,\n",
       " 0.7089989878531294,\n",
       " 0.7309081049874061,\n",
       " 0.7236470545553234,\n",
       " 0.7214727488414978,\n",
       " 0.7277336349693229,\n",
       " 0.7356157923295965,\n",
       " 0.7298357983323951,\n",
       " 0.7009282096151015,\n",
       " 0.7180849163204828]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.010400995648422806"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.722922160374385"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7150792647724791, 0.7307650559762908)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy.stats as st\n",
    "\n",
    "st.t.interval(0.95, len(precision)-1, loc=np.mean(precision), scale=st.sem(precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6353621767009191,\n",
       " 0.7980327144120247,\n",
       " 0.6315925821360604,\n",
       " 0.7306322112773725,\n",
       " 0.7834051069703243,\n",
       " 0.8153621192120178,\n",
       " 0.6785134638360445,\n",
       " 0.5424534550906366,\n",
       " 0.6841150399059186,\n",
       " 0.7728795789140618]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08366248808749328"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7072348448455381"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6441489459522528, 0.7703207437388234)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st.t.interval(0.95, len(recall)-1, loc=np.mean(recall), scale=st.sem(recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.save(\"mlp with visual and visual(normal).h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier, KerasRegressor\n",
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "\n",
    "base_model = models.Sequential()\n",
    "base_model.add(layers.Dense(128, activation='relu', input_shape=(10020,)))\n",
    "base_model.add(layers.Dense(64, activation='relu'))\n",
    "base_model.add(layers.Dense(2, activation='softmax'))\n",
    "\n",
    "X = result\n",
    "y = y\n",
    "\n",
    "my_model = KerasRegressor(build_fn=basemodel, **sk_params)    \n",
    "my_model.fit(X,y)\n",
    "\n",
    "perm = PermutationImportance(my_model, random_state=1).fit(X,y)\n",
    "eli5.show_weights(perm, feature_names = X.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shape mismatch: objects cannot be broadcast to a single shape",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-117-f54014f284ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Random Forest feature importance via permutation importance w. std. dev.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m plt.bar(range(X.shape[1]), imp_vals[indices],\n\u001b[0;32m---> 18\u001b[0;31m         yerr=std[indices])\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mbar\u001b[0;34m(x, height, width, bottom, align, data, **kwargs)\u001b[0m\n\u001b[1;32m   2455\u001b[0m     return gca().bar(\n\u001b[1;32m   2456\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbottom\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbottom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malign\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malign\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2457\u001b[0;31m         **({\"data\": data} if data is not None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1808\u001b[0m                         \u001b[0;34m\"the Matplotlib list!)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabel_namer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                         RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1810\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1812\u001b[0m         inner.__doc__ = _add_data_doc(inner.__doc__,\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mbar\u001b[0;34m(self, x, height, width, bottom, align, **kwargs)\u001b[0m\n\u001b[1;32m   2249\u001b[0m         x, height, width, y, linewidth = np.broadcast_arrays(\n\u001b[1;32m   2250\u001b[0m             \u001b[0;31m# Make args iterable too.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2251\u001b[0;31m             np.atleast_1d(x), height, width, y, linewidth)\n\u001b[0m\u001b[1;32m   2252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2253\u001b[0m         \u001b[0;31m# Now that units have been converted, set the tick locations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mbroadcast_arrays\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/numpy/lib/stride_tricks.py\u001b[0m in \u001b[0;36mbroadcast_arrays\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_m\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubok\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_m\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m     \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_broadcast_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/numpy/lib/stride_tricks.py\u001b[0m in \u001b[0;36m_broadcast_shape\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0;31m# use the old-iterator because np.nditer does not handle size 0 arrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m     \u001b[0;31m# consistently\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m     \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m     \u001b[0;31m# unfortunately, it cannot handle 32 or more arguments directly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mpos\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m31\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shape mismatch: objects cannot be broadcast to a single shape"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from mlxtend.evaluate import feature_importance_permutation\n",
    "from sklearn.metrics import f1_score\n",
    "imp_vals, imp_all = feature_importance_permutation(\n",
    "    predict_method= base_model.predict_classes, \n",
    "    X=X_test_oh.values,\n",
    "    y=y_test_le,\n",
    "    metric=f1_score,\n",
    "    num_rounds=10,\n",
    "    seed=1)\n",
    "\n",
    "\n",
    "std = np.std(imp_all, axis=1)\n",
    "indices = np.argsort(imp_vals)[::-1]\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Random Forest feature importance via permutation importance w. std. dev.\")\n",
    "plt.bar(range(X.shape[1]), imp_vals[indices],\n",
    "        yerr=std[indices])\n",
    "plt.xticks(range(X.shape[1]), indices)\n",
    "plt.xlim([-1, X.shape[1]])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
