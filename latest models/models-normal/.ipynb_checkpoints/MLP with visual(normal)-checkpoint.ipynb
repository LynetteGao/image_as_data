{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set-up of the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading stopwords: <urlopen error [Errno 61]\n",
      "[nltk_data]     Connection refused>\n"
     ]
    }
   ],
   "source": [
    "# Basic packages\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import re\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "# Packages for data preparation\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Packages for modeling\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import regularizers\n",
    "\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import recall_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set some parameters that will be used throughout the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_WORDS = 10000  # Parameter indicating the number of words we'll put in the dictionary\n",
    "NB_START_EPOCHS = 20  # Number of epochs we usually start to train with\n",
    "BATCH_SIZE = 512  # Size of the batches used in the mini-batch gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We read in the csv with the tweets data and perform a random shuffle. It's a good practice to shuffle the data before splitting between a train and test set. We'll only keep the video decription column as input and the Relvancy column as the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'video_id', 'attitude', 'transcript', 'var_r', 'var_g',\n",
       "       'var_b', 'var_h', 'var_s', 'var_v', 'var_bright', 'var_bright_sd',\n",
       "       'var_contrast', 'var_colorful', 'median_r', 'median_g', 'median_b',\n",
       "       'median_h', 'median_s', 'median_v', 'median_bright', 'median_bright_sd',\n",
       "       'median_contrast', 'median_colorful'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('normal_handlabel_feature.csv')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['attitude'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = X[(X[\"transcript\"] != 'CaptionUnavailable') & (X[\"transcript\"] != 'VideoUnavailable')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['var_r', 'var_g', 'var_b',\n",
    "       'var_h', 'var_s', 'var_v', 'var_bright', 'var_bright_sd',\n",
    "       'var_contrast', 'var_colorful', 'median_r', 'median_g', 'median_b',\n",
    "       'median_h', 'median_s', 'median_v', 'median_bright', 'median_bright_sd',\n",
    "       'median_contrast', 'median_colorful']][(df[\"transcript\"] != 'CaptionUnavailable') & (df[\"transcript\"] != 'VideoUnavailable')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = df[['var_r', 'var_g', 'var_b',\n",
    "#        'var_h', 'var_s', 'var_v', 'var_bright', 'var_bright_sd',\n",
    "#        'var_contrast', 'var_colorful', 'median_r', 'median_g', 'median_b',\n",
    "#        'median_h', 'median_s', 'median_v', 'median_bright', 'median_bright_sd',\n",
    "#        'median_contrast', 'median_colorful']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(635, 20)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "df['attitude'] = le.fit_transform(df['attitude'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5      0\n",
       "7      0\n",
       "10     0\n",
       "21     0\n",
       "28     0\n",
       "      ..\n",
       "725    1\n",
       "726    1\n",
       "729    1\n",
       "730    1\n",
       "731    1\n",
       "Name: attitude, Length: 460, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df['attitude'][(df[\"transcript\"] != 'CaptionUnavailable') & (df[\"transcript\"] != 'VideoUnavailable')]\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5      0\n",
       "7      0\n",
       "10     0\n",
       "21     0\n",
       "28     0\n",
       "      ..\n",
       "727    1\n",
       "728    1\n",
       "729    1\n",
       "730    1\n",
       "731    1\n",
       "Name: attitude, Length: 635, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y = df['attitude']\n",
    "# y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing we'll do is removing stopwords. These words do not have any value for predicting the sentiment.Also, we remove the http link in the texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate repeated K-fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "repeated: 0\n",
      "Shape of train set: (571, 20)\n",
      "Shape of y: (571, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "WARNING:tensorflow:From <ipython-input-12-5c2f571e10d2>:81: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "> Fold 1 - Precison: 0.6899671052631579 - Recall: 0.23684210526315788%\n",
      "Shape of train set: (571, 20)\n",
      "Shape of y: (571, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "> Fold 2 - Precison: 0.703125 - Recall: 1.0%\n",
      "Shape of train set: (571, 20)\n",
      "Shape of y: (571, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "> Fold 3 - Precison: 0.612812758478081 - Recall: 0.9743589743589743%\n",
      "Shape of train set: (571, 20)\n",
      "Shape of y: (571, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "> Fold 4 - Precison: 0.6426113613613613 - Recall: 0.5135135135135135%\n",
      "Shape of train set: (571, 20)\n",
      "Shape of y: (571, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd0d66d5cb0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 5 - Precison: 0.5079449152542372 - Recall: 0.9375%\n",
      "Shape of train set: (572, 20)\n",
      "Shape of y: (572, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 6 ...\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd0d949dc20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 6 - Precison: 0.6934966654248752 - Recall: 0.9024390243902439%\n",
      "Shape of train set: (572, 20)\n",
      "Shape of y: (572, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 7 ...\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd0da866b90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 7 - Precison: 0.6886446886446886 - Recall: 0.3333333333333333%\n",
      "Shape of train set: (572, 20)\n",
      "Shape of y: (572, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 8 ...\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd0db330b00> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 8 - Precison: 0.5710395269218799 - Recall: 0.9117647058823529%\n",
      "Shape of train set: (572, 20)\n",
      "Shape of y: (572, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 9 ...\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd0d644c050> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 9 - Precison: 0.7164299115518628 - Recall: 0.7073170731707317%\n",
      "Shape of train set: (572, 20)\n",
      "Shape of y: (572, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 10 ...\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd0dbb1ea70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 10 - Precison: 0.5418103553696774 - Recall: 0.9696969696969697%\n",
      "------------------------------------------------------------------------\n",
      "> Precison: 0.6367882288269822 (+- 0.07073140511411818)\n",
      "> Recall: 0.7486765699609277\n",
      "------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "precision = []\n",
    "recall = []\n",
    "\n",
    "for i in range(1):\n",
    "    \n",
    "    print('repeated:',i)\n",
    "    num_folds = 10\n",
    "    # Define per-fold score containers <-- these are new\n",
    "    acc_per_fold = []\n",
    "    loss_per_fold = []\n",
    "\n",
    "    # Define the K-fold Cross Validator\n",
    "    kfold = KFold(n_splits=num_folds, shuffle=True)\n",
    "\n",
    "    inputs = X\n",
    "    targets = y\n",
    "\n",
    "#     print('# inputs data samples:', inputs.shape[0])\n",
    "#     print('# targets data samples:', targets.shape[0])\n",
    "\n",
    "    # K-fold Cross Validation model evaluation\n",
    "    fold_no = 1\n",
    "    for train, test in kfold.split(inputs, targets):\n",
    "\n",
    "    #     tk = Tokenizer(num_words=NB_WORDS,\n",
    "    #                filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
    "    #                lower=True,\n",
    "    #                split=\" \")\n",
    "    #     tk.fit_on_texts(inputs.iloc[train])\n",
    "\n",
    "    #     X_train_seq = tk.texts_to_sequences(inputs.iloc[train])\n",
    "    #     X_test_seq = tk.texts_to_sequences(inputs.iloc[test])\n",
    "\n",
    "\n",
    "        X_train_oh = inputs.iloc[train]\n",
    "        X_test_oh = inputs.iloc[test]\n",
    "\n",
    "        print('Shape of train set:',X_train_oh.shape)\n",
    "\n",
    "\n",
    "        y_train_le = targets.iloc[train]\n",
    "        y_train_oh = to_categorical(y_train_le)\n",
    "\n",
    "\n",
    "        y_test_le = targets.iloc[test]\n",
    "        y_test_oh = to_categorical(y_test_le)\n",
    "\n",
    "\n",
    "\n",
    "        print('Shape of y:',y_train_oh.shape)\n",
    "\n",
    "        # Define the model architecture\n",
    "        base_model = models.Sequential()\n",
    "        base_model.add(layers.Dense(64, activation='relu', input_shape=(20,)))\n",
    "        base_model.add(layers.Dense(64, activation='relu'))\n",
    "        base_model.add(layers.Dense(2, activation='softmax'))\n",
    "\n",
    "        # Compile the model\n",
    "        base_model.compile(optimizer='rmsprop'\n",
    "                      , loss='categorical_crossentropy'\n",
    "                      , metrics=['accuracy',tf.keras.metrics.Precision(),tf.keras.metrics.Recall()])\n",
    "\n",
    "\n",
    "        # Generate a print\n",
    "        print('------------------------------------------------------------------------')\n",
    "        print(f'Training for fold {fold_no} ...')\n",
    "#         print('Shape of validation set:',X_test_oh.shape)\n",
    "\n",
    "        # Fit data to model\n",
    "        history = base_model.fit(X_train_oh\n",
    "                           ,y_train_oh\n",
    "                           , epochs=50\n",
    "                           , batch_size=BATCH_SIZE\n",
    "                           , verbose=0)\n",
    "#         print(history.history)\n",
    "\n",
    "\n",
    "        # Generate generalization metrics\n",
    "        from sklearn.metrics import classification_report\n",
    "        y_pred = base_model.predict_classes(X_test_oh)\n",
    "\n",
    "        average_recall = recall_score(y_test_le, y_pred)\n",
    "        average_precision = average_precision_score(y_test_le, y_pred)\n",
    "        print(f'> Fold {fold_no} - Precison: {average_precision} - Recall: {average_recall}%')\n",
    "\n",
    "        acc_per_fold.append(average_precision)\n",
    "        loss_per_fold.append(average_recall)\n",
    "\n",
    "        # Increase fold number\n",
    "        fold_no = fold_no + 1\n",
    "\n",
    "# == Provide average scores ==\n",
    "    print('------------------------------------------------------------------------')\n",
    "\n",
    "    print(f'> Precison: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "    precision.append(np.mean(acc_per_fold))\n",
    "    print(f'> Recall: {np.mean(loss_per_fold)}')\n",
    "    print('------------------------------------------------------------------------')\n",
    "    recall.append(np.mean(loss_per_fold))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6527335447500715,\n",
       " 0.6573429823604445,\n",
       " 0.6669886109845322,\n",
       " 0.6561405736821118,\n",
       " 0.6639379076502502,\n",
       " 0.6304265609799719,\n",
       " 0.6281532361315454,\n",
       " 0.6476786072832214,\n",
       " 0.6379359644402353,\n",
       " 0.671143081345722]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0142294029337344"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6512481069608105"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6405183917047855, 0.6619778222168354)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy.stats as st\n",
    "\n",
    "st.t.interval(0.95, len(precision)-1, loc=np.mean(precision), scale=st.sem(precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7109331797235023,\n",
       " 0.6191738524569689,\n",
       " 0.7585654351622093,\n",
       " 0.7647656265303324,\n",
       " 0.6462796887090365,\n",
       " 0.7405021665754424,\n",
       " 0.7044354648974215,\n",
       " 0.8176221001221,\n",
       " 0.5975995375008348,\n",
       " 0.557907018907019]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6320899565890794, 0.751466857527894)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st.t.interval(0.95, len(recall)-1, loc=np.mean(recall), scale=st.sem(recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07915690136721241"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6917784070584867"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier, KerasRegressor\n",
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "\n",
    "base_model = models.Sequential()\n",
    "base_model.add(layers.Dense(128, activation='relu', input_shape=(10020,)))\n",
    "base_model.add(layers.Dense(64, activation='relu'))\n",
    "base_model.add(layers.Dense(2, activation='softmax'))\n",
    "\n",
    "X = result\n",
    "y = y\n",
    "\n",
    "my_model = KerasRegressor(build_fn=basemodel, **sk_params)    \n",
    "my_model.fit(X,y)\n",
    "\n",
    "perm = PermutationImportance(my_model, random_state=1).fit(X,y)\n",
    "eli5.show_weights(perm, feature_names = X.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_metric(history, metric_name):\n",
    "    metric = history.history[metric_name]\n",
    "    val_metric = history.history['val_' + metric_name+'_24']\n",
    "\n",
    "    e = range(1, NB_START_EPOCHS + 1)\n",
    "\n",
    "    plt.plot(e, metric, 'bo', label='Train ' + metric_name)\n",
    "    plt.plot(e, val_metric, 'b', label='Validation ' + metric_name)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.save(\"mlp with visual(normal).h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31, 10020)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_oh.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31,)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_le.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31, 10020)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_oh.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Train data samples: 509\n",
      "# Test data samples: 57\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.video_description, df.Relevancy, test_size=0.1, random_state=37)\n",
    "print('# Train data samples:', X_train.shape[0])\n",
    "print('# Test data samples:', X_test.shape[0])\n",
    "assert X_train.shape[0] == y_train.shape[0]\n",
    "assert X_test.shape[0] == y_test.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting words to numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use the text as input for a model, we first need to convert the tweet's words into tokens, which simply means converting the words to integers that refer to an index in a dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will only keep the most frequent words in the train set.\n",
    "\n",
    "We clean up the text by applying filters and putting the words to lowercase. Words are separated by spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitted tokenizer on 509 documents\n",
      "10000 words in dictionary\n",
      "Top 5 most common words are: [('coronavirus', 624), ('news', 521), ('us', 271), ('follow', 260), ('subscribe', 255), ('channel', 255), ('virus', 239), ('watch', 230), ('5g', 215), ('dr', 215), ('covid', 214), ('twitter', 214), ('video', 211), ('not', 206), ('like', 205), ('facebook', 204), ('19', 201), ('this', 184), ('people', 183), ('playlist', 181)]\n"
     ]
    }
   ],
   "source": [
    "tk = Tokenizer(num_words=NB_WORDS,\n",
    "               filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
    "               lower=True,\n",
    "               split=\" \")\n",
    "tk.fit_on_texts(X_train)\n",
    "\n",
    "print('Fitted tokenizer on {} documents'.format(tk.document_count))\n",
    "print('{} words in dictionary'.format(tk.num_words))\n",
    "print('Top 5 most common words are:', collections.Counter(tk.word_counts).most_common(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After having created the dictionary we can convert the text to a list of integer indexes. This is done with the text_to_sequences method of the Tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"With theories circulating online 5G technology blame COVID-19 pandemic, experts present facts behind claims. Subscribe 7NEWS latest video ¬ª  Connect 7NEWS online Visit ¬ª  Facebook ¬ª  Twitter ¬ª  Instagram ¬ª  #BreakingNews #coronavirus #COVID19 #7NEWS\" is converted into [2045, 2546, 2547, 3245, 1761, 2548, 1039, 4683, 33, 124, 582, 83, 111, 818, 1, 220, 221, 115, 3246, 32, 120, 1762, 236, 486, 765, 1, 263, 660]\n"
     ]
    }
   ],
   "source": [
    "X_train_seq = tk.texts_to_sequences(X_train)\n",
    "X_test_seq = tk.texts_to_sequences(X_test)\n",
    "\n",
    "print('\"{}\" is converted into {}'.format(X_train[0], X_train_seq[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These integers should now be converted into a one-hot encoded features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_seq(seqs, nb_features = NB_WORDS):\n",
    "    ohs = np.zeros((len(seqs), nb_features))\n",
    "    for i, s in enumerate(seqs):\n",
    "        ohs[i, s] = 1.\n",
    "    return ohs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting the target classes to numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"1\" is converted into 1\n",
      "\"1\" is converted into [0. 1.]\n"
     ]
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "y_train_le = le.fit_transform(y_train)\n",
    "y_test_le = le.transform(y_test)\n",
    "y_train_oh = to_categorical(y_train_le)\n",
    "y_test_oh = to_categorical(y_test_le)\n",
    "\n",
    "print('\"{}\" is converted into {}'.format(y_train[0], y_train_le[0]))\n",
    "print('\"{}\" is converted into {}'.format(y_train_le[0], y_train_oh[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting of a validation set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of validation set: (51, 10000)\n"
     ]
    }
   ],
   "source": [
    "X_train_rest, X_valid, y_train_rest, y_valid = train_test_split(X_train_oh, y_train_oh, test_size=0.1, random_state=37)\n",
    "\n",
    "assert X_valid.shape[0] == y_valid.shape[0]\n",
    "assert X_train_rest.shape[0] == y_train_rest.shape[0]\n",
    "\n",
    "print('Shape of validation set:',X_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Implementation\n",
    "## Baseline model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start with a model with 2 densely connected layers of 64 hidden elements. The input_shape for the first layer is equal to the number of words we allowed in the dictionary and for which we created one-hot-encoded features.\n",
    "\n",
    " The softmax activation function makes sure the three probabilities sum up to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 64)                640064    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 644,354\n",
      "Trainable params: 644,354\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model = models.Sequential()\n",
    "base_model.add(layers.Dense(64, activation='relu', input_shape=(NB_WORDS,)))\n",
    "base_model.add(layers.Dense(64, activation='relu'))\n",
    "base_model.add(layers.Dense(2, activation='softmax'))\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because this project is a multi-class, single-label prediction, we use categorical_crossentropy as the loss function and softmax as the final activation function. We fit the model on the remaining train data and validate on the validation set. We run for a predetermined number of epochs and will see when the model starts to overfit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_model(model):\n",
    "    model.compile(optimizer='rmsprop'\n",
    "                  , loss='categorical_crossentropy'\n",
    "                  , metrics=['accuracy',tf.keras.metrics.Precision(),tf.keras.metrics.Recall()])\n",
    "    \n",
    "    history = model.fit(X_train_rest\n",
    "                       , y_train_rest\n",
    "                       , epochs=NB_START_EPOCHS\n",
    "                       , batch_size=BATCH_SIZE\n",
    "                       , validation_data=(X_valid, y_valid)\n",
    "                       , verbose=0)\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.7070090174674988,\n",
       "  0.5174614787101746,\n",
       "  0.3788684904575348,\n",
       "  0.3041400909423828,\n",
       "  0.25723156332969666,\n",
       "  0.22602522373199463,\n",
       "  0.2032897025346756,\n",
       "  0.1780741959810257,\n",
       "  0.1627146452665329,\n",
       "  0.1489810198545456,\n",
       "  0.13913194835186005,\n",
       "  0.12844568490982056,\n",
       "  0.11971041560173035,\n",
       "  0.11082577705383301,\n",
       "  0.10460763424634933,\n",
       "  0.09958921372890472,\n",
       "  0.09780213981866837,\n",
       "  0.09410517662763596,\n",
       "  0.089164137840271,\n",
       "  0.08444852381944656],\n",
       " 'accuracy': [0.3995633125305176,\n",
       "  0.8253275156021118,\n",
       "  0.8668122291564941,\n",
       "  0.9017467498779297,\n",
       "  0.9366812109947205,\n",
       "  0.9344978332519531,\n",
       "  0.9410480260848999,\n",
       "  0.9454148411750793,\n",
       "  0.9563318490982056,\n",
       "  0.9541484713554382,\n",
       "  0.9563318490982056,\n",
       "  0.9563318490982056,\n",
       "  0.960698664188385,\n",
       "  0.960698664188385,\n",
       "  0.960698664188385,\n",
       "  0.960698664188385,\n",
       "  0.9628821015357971,\n",
       "  0.9628821015357971,\n",
       "  0.9628821015357971,\n",
       "  0.9628821015357971],\n",
       " 'precision': [0.39427313208580017,\n",
       "  0.8253275156021118,\n",
       "  0.8668122291564941,\n",
       "  0.9017467498779297,\n",
       "  0.9366812109947205,\n",
       "  0.9344978332519531,\n",
       "  0.9410480260848999,\n",
       "  0.9454148411750793,\n",
       "  0.9563318490982056,\n",
       "  0.9541484713554382,\n",
       "  0.9563318490982056,\n",
       "  0.9563318490982056,\n",
       "  0.960698664188385,\n",
       "  0.960698664188385,\n",
       "  0.960698664188385,\n",
       "  0.960698664188385,\n",
       "  0.9628821015357971,\n",
       "  0.9628821015357971,\n",
       "  0.9628821015357971,\n",
       "  0.9628821015357971],\n",
       " 'recall': [0.3908296823501587,\n",
       "  0.8253275156021118,\n",
       "  0.8668122291564941,\n",
       "  0.9017467498779297,\n",
       "  0.9366812109947205,\n",
       "  0.9344978332519531,\n",
       "  0.9410480260848999,\n",
       "  0.9454148411750793,\n",
       "  0.9563318490982056,\n",
       "  0.9541484713554382,\n",
       "  0.9563318490982056,\n",
       "  0.9563318490982056,\n",
       "  0.960698664188385,\n",
       "  0.960698664188385,\n",
       "  0.960698664188385,\n",
       "  0.960698664188385,\n",
       "  0.9628821015357971,\n",
       "  0.9628821015357971,\n",
       "  0.9628821015357971,\n",
       "  0.9628821015357971],\n",
       " 'val_loss': [0.5335533022880554,\n",
       "  0.43902894854545593,\n",
       "  0.3966190814971924,\n",
       "  0.36304351687431335,\n",
       "  0.36193162202835083,\n",
       "  0.3229401409626007,\n",
       "  0.33019882440567017,\n",
       "  0.3119520843029022,\n",
       "  0.3339370787143707,\n",
       "  0.302752822637558,\n",
       "  0.33394140005111694,\n",
       "  0.2985526919364929,\n",
       "  0.32714682817459106,\n",
       "  0.30503079295158386,\n",
       "  0.3339540362358093,\n",
       "  0.29546359181404114,\n",
       "  0.3473667800426483,\n",
       "  0.3011917769908905,\n",
       "  0.33582183718681335,\n",
       "  0.30534660816192627],\n",
       " 'val_accuracy': [0.9019607901573181,\n",
       "  0.9019607901573181,\n",
       "  0.9019607901573181,\n",
       "  0.9019607901573181,\n",
       "  0.9019607901573181,\n",
       "  0.8823529481887817,\n",
       "  0.9019607901573181,\n",
       "  0.9019607901573181,\n",
       "  0.9019607901573181,\n",
       "  0.9019607901573181,\n",
       "  0.9019607901573181,\n",
       "  0.9019607901573181,\n",
       "  0.8823529481887817,\n",
       "  0.9019607901573181,\n",
       "  0.9019607901573181,\n",
       "  0.9019607901573181,\n",
       "  0.9019607901573181,\n",
       "  0.9019607901573181,\n",
       "  0.9019607901573181,\n",
       "  0.9019607901573181],\n",
       " 'val_precision': [0.9019607901573181,\n",
       "  0.9019607901573181,\n",
       "  0.9019607901573181,\n",
       "  0.9019607901573181,\n",
       "  0.9019607901573181,\n",
       "  0.8823529481887817,\n",
       "  0.9019607901573181,\n",
       "  0.9019607901573181,\n",
       "  0.9019607901573181,\n",
       "  0.9019607901573181,\n",
       "  0.9019607901573181,\n",
       "  0.9019607901573181,\n",
       "  0.8823529481887817,\n",
       "  0.9019607901573181,\n",
       "  0.9019607901573181,\n",
       "  0.9019607901573181,\n",
       "  0.9019607901573181,\n",
       "  0.9019607901573181,\n",
       "  0.9019607901573181,\n",
       "  0.9019607901573181],\n",
       " 'val_recall': [0.9019607901573181,\n",
       "  0.9019607901573181,\n",
       "  0.9019607901573181,\n",
       "  0.9019607901573181,\n",
       "  0.9019607901573181,\n",
       "  0.8823529481887817,\n",
       "  0.9019607901573181,\n",
       "  0.9019607901573181,\n",
       "  0.9019607901573181,\n",
       "  0.9019607901573181,\n",
       "  0.9019607901573181,\n",
       "  0.9019607901573181,\n",
       "  0.8823529481887817,\n",
       "  0.9019607901573181,\n",
       "  0.9019607901573181,\n",
       "  0.9019607901573181,\n",
       "  0.9019607901573181,\n",
       "  0.9019607901573181,\n",
       "  0.9019607901573181,\n",
       "  0.9019607901573181]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_history = first_model(base_model)\n",
    "base_history.history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate the model performance, we will look at the training and validation loss and accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Validation\n",
    "\n",
    "lets check the model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, epoch_stop):\n",
    "    model.fit(X_train_oh\n",
    "              , y_train_oh\n",
    "              , epochs=epoch_stop\n",
    "              , batch_size=BATCH_SIZE\n",
    "              , verbose=0)\n",
    "    results = model.evaluate(X_test_oh, y_test_oh)\n",
    "    \n",
    "    return results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 1ms/step - loss: 0.8903 - accuracy: 0.8947 - precision_1: 0.8947 - recall_1: 0.8947\n",
      "[0.8902625441551208, 0.8947368264198303, 0.8947368264198303, 0.8947368264198303]\n",
      "Test accuracy of baseline model: 89.47%\n"
     ]
    }
   ],
   "source": [
    "test_results = test_model(base_model,30)\n",
    "print(test_results)\n",
    "print('Test accuracy of baseline model: {0:.2f}%'.format(test_results[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 0 1 1 1 1 1 1 1 0 0 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 0 1 0 0 1 1\n",
      " 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "y_score = base_model.predict_classes(X_test_oh)\n",
    "print(y_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.75      0.75        12\n",
      "           1       0.93      0.93      0.93        45\n",
      "\n",
      "    accuracy                           0.89        57\n",
      "   macro avg       0.84      0.84      0.84        57\n",
      "weighted avg       0.89      0.89      0.89        57\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = base_model.predict_classes(X_test_oh)\n",
    "print(y_test.ndim)\n",
    "print(classification_report(y_test_le, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9237426900584795\n",
      "0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "\n",
    "average_precision = average_precision_score(y_test_le, y_pred)\n",
    "print(average_precision)\n",
    "average_recall = recall_score(y_test_le, y_pred)\n",
    "print(average_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_arr = np.column_stack((y_test_le, y_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [0, 0]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
