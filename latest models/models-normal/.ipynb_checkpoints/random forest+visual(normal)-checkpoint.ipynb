{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocressing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'video_id', 'attitude', 'transcript', 'var_r', 'var_g',\n",
       "       'var_b', 'var_h', 'var_s', 'var_v', 'var_bright', 'var_bright_sd',\n",
       "       'var_contrast', 'var_colorful', 'median_r', 'median_g', 'median_b',\n",
       "       'median_h', 'median_s', 'median_v', 'median_bright', 'median_bright_sd',\n",
       "       'median_contrast', 'median_colorful'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('normal_handlabel_feature.csv')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(732, 24)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'video_id', 'attitude', 'transcript', 'var_r', 'var_g',\n",
       "       'var_b', 'var_h', 'var_s', 'var_v', 'var_bright', 'var_bright_sd',\n",
       "       'var_contrast', 'var_colorful', 'median_r', 'median_g', 'median_b',\n",
       "       'median_h', 'median_s', 'median_v', 'median_bright', 'median_bright_sd',\n",
       "       'median_contrast', 'median_colorful'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['attitude'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'transcript'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns.tolist()[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['var_r',\n",
       " 'var_g',\n",
       " 'var_b',\n",
       " 'var_h',\n",
       " 'var_s',\n",
       " 'var_v',\n",
       " 'var_bright',\n",
       " 'var_bright_sd',\n",
       " 'var_contrast',\n",
       " 'var_colorful',\n",
       " 'median_r',\n",
       " 'median_g',\n",
       " 'median_b',\n",
       " 'median_h',\n",
       " 'median_s',\n",
       " 'median_v',\n",
       " 'median_bright',\n",
       " 'median_bright_sd',\n",
       " 'median_contrast',\n",
       " 'median_colorful']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns.tolist()[4:24]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deal with categorical variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "df['attitude'] = le.fit_transform(df['attitude'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[df.columns[4:24]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_r</th>\n",
       "      <th>var_g</th>\n",
       "      <th>var_b</th>\n",
       "      <th>var_h</th>\n",
       "      <th>var_s</th>\n",
       "      <th>var_v</th>\n",
       "      <th>var_bright</th>\n",
       "      <th>var_bright_sd</th>\n",
       "      <th>var_contrast</th>\n",
       "      <th>var_colorful</th>\n",
       "      <th>median_r</th>\n",
       "      <th>median_g</th>\n",
       "      <th>median_b</th>\n",
       "      <th>median_h</th>\n",
       "      <th>median_s</th>\n",
       "      <th>median_v</th>\n",
       "      <th>median_bright</th>\n",
       "      <th>median_bright_sd</th>\n",
       "      <th>median_contrast</th>\n",
       "      <th>median_colorful</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>611.670255</td>\n",
       "      <td>710.533599</td>\n",
       "      <td>704.285521</td>\n",
       "      <td>565.782339</td>\n",
       "      <td>267.640542</td>\n",
       "      <td>616.471287</td>\n",
       "      <td>661.184079</td>\n",
       "      <td>185.405393</td>\n",
       "      <td>48.207604</td>\n",
       "      <td>226.281947</td>\n",
       "      <td>178.297660</td>\n",
       "      <td>182.070140</td>\n",
       "      <td>183.746428</td>\n",
       "      <td>67.315794</td>\n",
       "      <td>5.285804</td>\n",
       "      <td>184.217756</td>\n",
       "      <td>181.100160</td>\n",
       "      <td>92.073127</td>\n",
       "      <td>255.0</td>\n",
       "      <td>10.850100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>452.356980</td>\n",
       "      <td>478.186275</td>\n",
       "      <td>419.175631</td>\n",
       "      <td>355.090668</td>\n",
       "      <td>468.120127</td>\n",
       "      <td>488.873792</td>\n",
       "      <td>444.666475</td>\n",
       "      <td>45.390127</td>\n",
       "      <td>783.693329</td>\n",
       "      <td>53.253433</td>\n",
       "      <td>58.932432</td>\n",
       "      <td>48.911764</td>\n",
       "      <td>50.621008</td>\n",
       "      <td>91.027888</td>\n",
       "      <td>61.974344</td>\n",
       "      <td>60.291964</td>\n",
       "      <td>52.098780</td>\n",
       "      <td>57.203108</td>\n",
       "      <td>223.0</td>\n",
       "      <td>22.048810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>255.602928</td>\n",
       "      <td>227.562307</td>\n",
       "      <td>115.534510</td>\n",
       "      <td>82.652435</td>\n",
       "      <td>56.376545</td>\n",
       "      <td>233.168950</td>\n",
       "      <td>201.218955</td>\n",
       "      <td>67.706699</td>\n",
       "      <td>411.482719</td>\n",
       "      <td>23.133398</td>\n",
       "      <td>162.885660</td>\n",
       "      <td>127.777572</td>\n",
       "      <td>135.631998</td>\n",
       "      <td>73.192558</td>\n",
       "      <td>136.100062</td>\n",
       "      <td>191.345718</td>\n",
       "      <td>139.447290</td>\n",
       "      <td>43.736392</td>\n",
       "      <td>183.0</td>\n",
       "      <td>102.317861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>346.926190</td>\n",
       "      <td>328.023541</td>\n",
       "      <td>306.858307</td>\n",
       "      <td>148.598571</td>\n",
       "      <td>82.680316</td>\n",
       "      <td>307.033028</td>\n",
       "      <td>328.973162</td>\n",
       "      <td>179.992448</td>\n",
       "      <td>851.291335</td>\n",
       "      <td>56.403953</td>\n",
       "      <td>199.799596</td>\n",
       "      <td>195.907756</td>\n",
       "      <td>194.418024</td>\n",
       "      <td>27.569884</td>\n",
       "      <td>9.146088</td>\n",
       "      <td>199.960340</td>\n",
       "      <td>196.905496</td>\n",
       "      <td>33.385873</td>\n",
       "      <td>135.0</td>\n",
       "      <td>12.993900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29.583790</td>\n",
       "      <td>22.456832</td>\n",
       "      <td>16.950847</td>\n",
       "      <td>20.298046</td>\n",
       "      <td>39.189503</td>\n",
       "      <td>29.754383</td>\n",
       "      <td>20.640310</td>\n",
       "      <td>5.748194</td>\n",
       "      <td>48.051666</td>\n",
       "      <td>10.437365</td>\n",
       "      <td>143.555642</td>\n",
       "      <td>127.917176</td>\n",
       "      <td>135.183554</td>\n",
       "      <td>54.865530</td>\n",
       "      <td>46.820690</td>\n",
       "      <td>151.462780</td>\n",
       "      <td>133.429320</td>\n",
       "      <td>69.593465</td>\n",
       "      <td>226.0</td>\n",
       "      <td>47.625559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727</th>\n",
       "      <td>334.730822</td>\n",
       "      <td>254.877648</td>\n",
       "      <td>387.643863</td>\n",
       "      <td>293.302871</td>\n",
       "      <td>564.886554</td>\n",
       "      <td>276.912982</td>\n",
       "      <td>241.962444</td>\n",
       "      <td>221.068737</td>\n",
       "      <td>1205.208298</td>\n",
       "      <td>265.277754</td>\n",
       "      <td>129.959738</td>\n",
       "      <td>141.942548</td>\n",
       "      <td>155.307650</td>\n",
       "      <td>88.752460</td>\n",
       "      <td>55.131008</td>\n",
       "      <td>159.591224</td>\n",
       "      <td>140.166896</td>\n",
       "      <td>52.745051</td>\n",
       "      <td>183.0</td>\n",
       "      <td>34.085110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728</th>\n",
       "      <td>16.959293</td>\n",
       "      <td>16.575534</td>\n",
       "      <td>15.332936</td>\n",
       "      <td>0.641947</td>\n",
       "      <td>2.560193</td>\n",
       "      <td>15.322383</td>\n",
       "      <td>16.490195</td>\n",
       "      <td>1.800106</td>\n",
       "      <td>9.611709</td>\n",
       "      <td>0.157558</td>\n",
       "      <td>173.011236</td>\n",
       "      <td>161.605272</td>\n",
       "      <td>149.347840</td>\n",
       "      <td>46.979532</td>\n",
       "      <td>52.754576</td>\n",
       "      <td>178.983920</td>\n",
       "      <td>163.657364</td>\n",
       "      <td>55.929633</td>\n",
       "      <td>214.0</td>\n",
       "      <td>42.756157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729</th>\n",
       "      <td>820.036766</td>\n",
       "      <td>1169.309838</td>\n",
       "      <td>1175.549922</td>\n",
       "      <td>335.253698</td>\n",
       "      <td>132.699446</td>\n",
       "      <td>853.096095</td>\n",
       "      <td>1051.933567</td>\n",
       "      <td>421.973576</td>\n",
       "      <td>3692.410128</td>\n",
       "      <td>67.948962</td>\n",
       "      <td>182.975658</td>\n",
       "      <td>178.023416</td>\n",
       "      <td>182.162994</td>\n",
       "      <td>83.686968</td>\n",
       "      <td>25.096562</td>\n",
       "      <td>190.164112</td>\n",
       "      <td>178.605554</td>\n",
       "      <td>55.327353</td>\n",
       "      <td>198.5</td>\n",
       "      <td>23.978003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>273.171022</td>\n",
       "      <td>421.142066</td>\n",
       "      <td>412.096403</td>\n",
       "      <td>58.687157</td>\n",
       "      <td>346.328848</td>\n",
       "      <td>274.837309</td>\n",
       "      <td>329.884662</td>\n",
       "      <td>38.341451</td>\n",
       "      <td>633.204244</td>\n",
       "      <td>133.186585</td>\n",
       "      <td>141.727648</td>\n",
       "      <td>116.764844</td>\n",
       "      <td>105.792188</td>\n",
       "      <td>24.693460</td>\n",
       "      <td>70.736796</td>\n",
       "      <td>142.607112</td>\n",
       "      <td>122.703036</td>\n",
       "      <td>52.090848</td>\n",
       "      <td>196.0</td>\n",
       "      <td>40.338692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>731</th>\n",
       "      <td>106.808154</td>\n",
       "      <td>139.723951</td>\n",
       "      <td>134.030401</td>\n",
       "      <td>239.983373</td>\n",
       "      <td>74.746906</td>\n",
       "      <td>88.435287</td>\n",
       "      <td>123.775648</td>\n",
       "      <td>117.920362</td>\n",
       "      <td>1094.601656</td>\n",
       "      <td>206.854300</td>\n",
       "      <td>224.751184</td>\n",
       "      <td>222.913080</td>\n",
       "      <td>220.755072</td>\n",
       "      <td>61.273382</td>\n",
       "      <td>12.545956</td>\n",
       "      <td>228.069894</td>\n",
       "      <td>223.331286</td>\n",
       "      <td>53.997297</td>\n",
       "      <td>191.0</td>\n",
       "      <td>18.150359</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>635 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          var_r        var_g        var_b       var_h       var_s       var_v  \\\n",
       "5    611.670255   710.533599   704.285521  565.782339  267.640542  616.471287   \n",
       "7    452.356980   478.186275   419.175631  355.090668  468.120127  488.873792   \n",
       "10   255.602928   227.562307   115.534510   82.652435   56.376545  233.168950   \n",
       "21   346.926190   328.023541   306.858307  148.598571   82.680316  307.033028   \n",
       "28    29.583790    22.456832    16.950847   20.298046   39.189503   29.754383   \n",
       "..          ...          ...          ...         ...         ...         ...   \n",
       "727  334.730822   254.877648   387.643863  293.302871  564.886554  276.912982   \n",
       "728   16.959293    16.575534    15.332936    0.641947    2.560193   15.322383   \n",
       "729  820.036766  1169.309838  1175.549922  335.253698  132.699446  853.096095   \n",
       "730  273.171022   421.142066   412.096403   58.687157  346.328848  274.837309   \n",
       "731  106.808154   139.723951   134.030401  239.983373   74.746906   88.435287   \n",
       "\n",
       "      var_bright  var_bright_sd  var_contrast  var_colorful    median_r  \\\n",
       "5     661.184079     185.405393     48.207604    226.281947  178.297660   \n",
       "7     444.666475      45.390127    783.693329     53.253433   58.932432   \n",
       "10    201.218955      67.706699    411.482719     23.133398  162.885660   \n",
       "21    328.973162     179.992448    851.291335     56.403953  199.799596   \n",
       "28     20.640310       5.748194     48.051666     10.437365  143.555642   \n",
       "..           ...            ...           ...           ...         ...   \n",
       "727   241.962444     221.068737   1205.208298    265.277754  129.959738   \n",
       "728    16.490195       1.800106      9.611709      0.157558  173.011236   \n",
       "729  1051.933567     421.973576   3692.410128     67.948962  182.975658   \n",
       "730   329.884662      38.341451    633.204244    133.186585  141.727648   \n",
       "731   123.775648     117.920362   1094.601656    206.854300  224.751184   \n",
       "\n",
       "       median_g    median_b   median_h    median_s    median_v  median_bright  \\\n",
       "5    182.070140  183.746428  67.315794    5.285804  184.217756     181.100160   \n",
       "7     48.911764   50.621008  91.027888   61.974344   60.291964      52.098780   \n",
       "10   127.777572  135.631998  73.192558  136.100062  191.345718     139.447290   \n",
       "21   195.907756  194.418024  27.569884    9.146088  199.960340     196.905496   \n",
       "28   127.917176  135.183554  54.865530   46.820690  151.462780     133.429320   \n",
       "..          ...         ...        ...         ...         ...            ...   \n",
       "727  141.942548  155.307650  88.752460   55.131008  159.591224     140.166896   \n",
       "728  161.605272  149.347840  46.979532   52.754576  178.983920     163.657364   \n",
       "729  178.023416  182.162994  83.686968   25.096562  190.164112     178.605554   \n",
       "730  116.764844  105.792188  24.693460   70.736796  142.607112     122.703036   \n",
       "731  222.913080  220.755072  61.273382   12.545956  228.069894     223.331286   \n",
       "\n",
       "     median_bright_sd  median_contrast  median_colorful  \n",
       "5           92.073127            255.0        10.850100  \n",
       "7           57.203108            223.0        22.048810  \n",
       "10          43.736392            183.0       102.317861  \n",
       "21          33.385873            135.0        12.993900  \n",
       "28          69.593465            226.0        47.625559  \n",
       "..                ...              ...              ...  \n",
       "727         52.745051            183.0        34.085110  \n",
       "728         55.929633            214.0        42.756157  \n",
       "729         55.327353            198.5        23.978003  \n",
       "730         52.090848            196.0        40.338692  \n",
       "731         53.997297            191.0        18.150359  \n",
       "\n",
       "[635 rows x 20 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5      0\n",
       "7      0\n",
       "10     0\n",
       "21     0\n",
       "28     0\n",
       "      ..\n",
       "727    1\n",
       "728    1\n",
       "729    1\n",
       "730    1\n",
       "731    1\n",
       "Name: attitude, Length: 635, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df['attitude']\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting eli5\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/97/2f/c85c7d8f8548e460829971785347e14e45fa5c6617da374711dec8cb38cc/eli5-0.10.1-py2.py3-none-any.whl (105kB)\n",
      "\u001b[K     |████████████████████████████████| 112kB 775kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: graphviz in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from eli5) (0.15)\n",
      "Collecting tabulate>=0.7.7 (from eli5)\n",
      "  Downloading https://files.pythonhosted.org/packages/c4/f4/770ae9385990f5a19a91431163d262182d3203662ea2b5739d0fcfc080f1/tabulate-0.8.7-py3-none-any.whl\n",
      "Requirement already satisfied: scipy in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from eli5) (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.9.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from eli5) (1.18.5)\n",
      "Requirement already satisfied: scikit-learn>=0.18 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from eli5) (0.23.1)\n",
      "Requirement already satisfied: attrs>16.0.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from eli5) (19.3.0)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from eli5) (2.11.2)\n",
      "Requirement already satisfied: six in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from eli5) (1.15.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from scikit-learn>=0.18->eli5) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from scikit-learn>=0.18->eli5) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from jinja2->eli5) (1.1.1)\n",
      "Installing collected packages: tabulate, eli5\n",
      "Successfully installed eli5-0.10.1 tabulate-0.8.7\n",
      "\u001b[33mWARNING: You are using pip version 19.2.3, however version 20.3.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install eli5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1 : Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.70\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "\n",
    "boost = GradientBoostingClassifier(\n",
    "    learning_rate=0.01,\n",
    "    n_estimators=600,\n",
    "    max_depth = 4,\n",
    "    random_state=1)\n",
    "\n",
    "boost.fit(newX_train, newy_train)\n",
    "    \n",
    "print(\"Test Accuracy: %0.2f\" % boost.score(newX_test, newy_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: [0.41666667 0.75714286]\n",
      "recall: [0.22727273 0.88333333]\n",
      "fscore: [0.29411765 0.81538462]\n",
      "support: [22 60]\n",
      "Confusion Matrix:\n",
      "[[ 5 17]\n",
      " [ 7 53]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.23      0.29        22\n",
      "           1       0.76      0.88      0.82        60\n",
      "\n",
      "    accuracy                           0.71        82\n",
      "   macro avg       0.59      0.56      0.55        82\n",
      "weighted avg       0.67      0.71      0.68        82\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "predictions = boost.predict(X_test)\n",
    "precision, recall, fscore, support = score(y_test, predictions)\n",
    "print('precision: {}'.format(precision))\n",
    "print('recall: {}'.format(recall))\n",
    "print('fscore: {}'.format(fscore))\n",
    "print('support: {}'.format(support))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average precision-recall score: 0.82\n"
     ]
    }
   ],
   "source": [
    "y_score = boost.decision_function(X_test_std)\n",
    "from sklearn.metrics import average_precision_score\n",
    "average_precision = average_precision_score(y_test, y_score)\n",
    "\n",
    "print('Average precision-recall score: {0:0.2f}'.format(\n",
    "      average_precision))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression(C=1e3,max_iter=200)\n",
    "\n",
    "# Create an instance of Logistic Regression Classifier and fit the data.\n",
    "logreg.fit(X_train, y_train)\n",
    "    \n",
    "print(\"Test Accuracy: %0.2f\" % logreg.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7375460480723638\n",
      "0.9432183908045977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "cv = cross_validate(logreg, X, y, cv=10,scoring = ['precision','recall'])\n",
    "\n",
    "\n",
    "print(cv['test_precision'].mean())\n",
    "print(cv['test_recall'].mean())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: [0.33333333 0.74285714]\n",
      "recall: [0.18181818 0.86666667]\n",
      "fscore: [0.23529412 0.8       ]\n",
      "support: [22 60]\n",
      "Confusion Matrix:\n",
      "[[ 4 18]\n",
      " [ 8 52]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.18      0.24        22\n",
      "           1       0.74      0.87      0.80        60\n",
      "\n",
      "    accuracy                           0.68        82\n",
      "   macro avg       0.54      0.52      0.52        82\n",
      "weighted avg       0.63      0.68      0.65        82\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "predictions = logreg.predict(X_test)\n",
    "precision, recall, fscore, support = score(y_test, predictions)\n",
    "print('precision: {}'.format(precision))\n",
    "print('recall: {}'.format(recall))\n",
    "print('fscore: {}'.format(fscore))\n",
    "print('support: {}'.format(support))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average precision-recall score: 0.77\n"
     ]
    }
   ],
   "source": [
    "y_score = logreg.decision_function(X_test)\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import precision_score\n",
    "average_precision = average_precision_score(y_test, y_score)\n",
    "\n",
    "print('Average precision-recall score: {0:0.2f}'.format(\n",
    "      average_precision))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "precision = []\n",
    "recall = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn import datasets\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "for i in range(10):\n",
    "    forest = RandomForestClassifier(n_estimators=500,\n",
    "                                 min_samples_split= 5)\n",
    "    cv = cross_validate(forest, X, y, cv=10,scoring = ['precision','recall'])\n",
    "\n",
    "    precision.append(cv['test_precision'].mean())\n",
    "    recall.append(cv['test_recall'].mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7464262598325425,\n",
       " 0.7559134989932678,\n",
       " 0.7446049533920414,\n",
       " 0.7496597289799991,\n",
       " 0.7399789499000932,\n",
       " 0.7539547167450518,\n",
       " 0.7469602122854433,\n",
       " 0.7493294622777189,\n",
       " 0.7470306352346934,\n",
       " 0.7437628821733002]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8165007112375534,\n",
       " 0.8165007112375534,\n",
       " 0.816429587482219,\n",
       " 0.8218349928876245,\n",
       " 0.816429587482219,\n",
       " 0.819203413940256,\n",
       " 0.8245376955903272,\n",
       " 0.8136557610241821,\n",
       " 0.819203413940256,\n",
       " 0.8191322901849217]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.004476077578804402\n",
      "0.7477621299814151\n",
      "(0.7443869329961229, 0.7511373269667073)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "\n",
    "\n",
    "print(np.std(precision))\n",
    "print(np.mean(precision))\n",
    "print(st.t.interval(0.95, len(precision)-1, loc=np.mean(precision), scale=st.sem(precision)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.002979134616827655\n",
      "0.8183428165007113\n",
      "(0.8160963929299692, 0.8205892400714534)\n"
     ]
    }
   ],
   "source": [
    "print(np.std(recall))\n",
    "print(np.mean(recall))\n",
    "print(st.t.interval(0.95, len(recall)-1, loc=np.mean(recall), scale=st.sem(recall)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['random_forest_visual(normal).joblib']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(forest, \"random_forest_visual(normal).joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.evaluate import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5, 17],\n",
       "       [ 4, 56]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confmat = confusion_matrix(y_test, predictions)\n",
    "confmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 144x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "\n",
    "fig,ax = plot_confusion_matrix(conf_mat = confmat, figsize=(2,2))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7671232876712328"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "precision_score(y_true = y_test, y_pred = predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9333333333333333"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_true = y_test, y_pred = predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: [0.55555556 0.76712329]\n",
      "recall: [0.22727273 0.93333333]\n",
      "fscore: [0.32258065 0.84210526]\n",
      "support: [22 60]\n",
      "Confusion Matrix:\n",
      "[[ 5 17]\n",
      " [ 4 56]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.23      0.32        22\n",
      "           1       0.77      0.93      0.84        60\n",
      "\n",
      "    accuracy                           0.74        82\n",
      "   macro avg       0.66      0.58      0.58        82\n",
      "weighted avg       0.71      0.74      0.70        82\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "predictions = forest.fit(X_train,y_train).predict(X_test)\n",
    "precision, recall, fscore, support = score(y_test, predictions)\n",
    "print('precision: {}'.format(precision))\n",
    "print('recall: {}'.format(recall))\n",
    "print('fscore: {}'.format(fscore))\n",
    "print('support: {}'.format(support))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.77522302, 0.74089813, 0.72205997, 0.73048186, 0.72541595,\n",
       "        0.72606993, 0.74011517, 0.78116822, 0.71582007, 0.76832056]),\n",
       " 'score_time': array([0.03804803, 0.03807902, 0.03732491, 0.0383811 , 0.03753877,\n",
       "        0.03639913, 0.03754592, 0.03752589, 0.03756785, 0.0375843 ]),\n",
       " 'test_precision': array([0.75      , 0.8       , 0.74358974, 0.76923077, 0.71794872,\n",
       "        0.75      , 0.72972973, 0.74358974, 0.71794872, 0.77777778]),\n",
       " 'test_recall': array([0.9       , 0.93333333, 0.96666667, 1.        , 0.93333333,\n",
       "        0.9       , 0.9       , 1.        , 0.96551724, 0.93333333])}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.74998151998152\n",
      "0.9432183908045977\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(cv['test_precision'].mean())\n",
    "print(cv['test_recall'].mean())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.metrics.scorer module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.feature_selection.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.feature_selection. Anything that cannot be imported from sklearn.feature_selection is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        <table class=\"eli5-weights eli5-feature-importances\" style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto;\">\n",
       "    <thead>\n",
       "    <tr style=\"border: none;\">\n",
       "        <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">Weight</th>\n",
       "        <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "    </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 83.65%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0146\n",
       "                \n",
       "                    &plusmn; 0.0183\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                var_h\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 85.61%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0122\n",
       "                \n",
       "                    &plusmn; 0.0154\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                median_bright_sd\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 85.61%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0122\n",
       "                \n",
       "                    &plusmn; 0.0267\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                median_contrast\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 87.69%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0098\n",
       "                \n",
       "                    &plusmn; 0.0183\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                var_s\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 87.69%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0098\n",
       "                \n",
       "                    &plusmn; 0.0098\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                median_r\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 87.69%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0098\n",
       "                \n",
       "                    &plusmn; 0.0098\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                var_contrast\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 89.93%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0073\n",
       "                \n",
       "                    &plusmn; 0.0119\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                var_r\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 89.93%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0073\n",
       "                \n",
       "                    &plusmn; 0.0119\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                var_bright\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 92.42%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0049\n",
       "                \n",
       "                    &plusmn; 0.0195\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                var_bright_sd\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 92.42%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0049\n",
       "                \n",
       "                    &plusmn; 0.0119\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                var_g\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 92.42%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0049\n",
       "                \n",
       "                    &plusmn; 0.0119\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                var_b\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 95.33%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0024\n",
       "                \n",
       "                    &plusmn; 0.0098\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                var_v\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0\n",
       "                \n",
       "                    &plusmn; 0.0000\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                var_colorful\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0000\n",
       "                \n",
       "                    &plusmn; 0.0267\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                median_h\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 92.42%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                -0.0049\n",
       "                \n",
       "                    &plusmn; 0.0119\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                median_v\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 87.69%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                -0.0098\n",
       "                \n",
       "                    &plusmn; 0.0098\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                median_bright\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 87.69%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                -0.0098\n",
       "                \n",
       "                    &plusmn; 0.0098\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                median_colorful\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 85.61%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                -0.0122\n",
       "                \n",
       "                    &plusmn; 0.0154\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                median_b\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 81.78%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                -0.0171\n",
       "                \n",
       "                    &plusmn; 0.0195\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                median_g\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 80.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                -0.0195\n",
       "                \n",
       "                    &plusmn; 0.0119\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                median_s\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "    \n",
       "    </tbody>\n",
       "</table>\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.2, shuffle = True, random_state = 123, stratify = y)\n",
    "model = forest.fit(X_train,y_train)\n",
    "perm = PermutationImportance(model).fit(X_test, y_test)\n",
    "eli5.show_weights(perm, feature_names=X_test.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(82, 20)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mlxtend.evaluate import feature_importance_permutation\n",
    "from sklearn.metrics import f1_score\n",
    "imp_vals, imp_all = feature_importance_permutation(\n",
    "    predict_method= model.predict, \n",
    "    X=X_test.values,\n",
    "    y=y_test,\n",
    "    metric=f1_score,\n",
    "    num_rounds=10,\n",
    "    seed=1)\n",
    "\n",
    "\n",
    "std = np.std(imp_all, axis=1)\n",
    "indices = np.argsort(imp_vals)[::-1]\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Random Forest feature importance via permutation importance w. std. dev.\")\n",
    "plt.bar(range(X.shape[1]), imp_vals[indices],\n",
    "        yerr=std[indices])\n",
    "plt.xticks(range(X.shape[1]), indices)\n",
    "plt.xlim([-1, X.shape[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.78\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "\n",
    "forest = ExtraTreesClassifier(n_estimators=500,\n",
    "                              random_state=1,\n",
    "                             max_features=None,max_depth=None,min_samples_split=2)\n",
    "\n",
    "forest.fit(X, y_train)\n",
    "    \n",
    "print(\"Test Accuracy: %0.2f\" % forest.score(X_test_std, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: [0.52631579 0.79368932]\n",
      "recall: [0.10526316 0.97321429]\n",
      "fscore: [0.1754386  0.87433155]\n",
      "support: [ 95 336]\n",
      "Confusion Matrix:\n",
      "[[ 10  85]\n",
      " [  9 327]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.11      0.18        95\n",
      "           1       0.79      0.97      0.87       336\n",
      "\n",
      "    accuracy                           0.78       431\n",
      "   macro avg       0.66      0.54      0.52       431\n",
      "weighted avg       0.73      0.78      0.72       431\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = forest.predict(X_test_std)\n",
    "precision, recall, fscore, support = score(y_test, predictions)\n",
    "print('precision: {}'.format(precision))\n",
    "print('recall: {}'.format(recall))\n",
    "print('fscore: {}'.format(fscore))\n",
    "print('support: {}'.format(support))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
