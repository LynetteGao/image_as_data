{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set-up of the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/lynette/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Basic packages\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import re\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "# Packages for data preparation\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Packages for modeling\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import regularizers\n",
    "\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import recall_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set some parameters that will be used throughout the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We read in the csv with the tweets data and perform a random shuffle. It's a good practice to shuffle the data before splitting between a train and test set. We'll only keep the video decription column as input and the Relvancy column as the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'video_id', 'channel_title', 'channel_id',\n",
       "       'video_publish_date', 'video_title', 'video_description',\n",
       "       'video_category', 'video_view_count', 'video_comment_count',\n",
       "       'video_like_count', 'video_dislike_count', 'video_thumbnail',\n",
       "       'video_tags', 'collection_date', 'science.topic', 'Relevancy',\n",
       "       'attitude', 'Text/video', 'search.term', 'cld2', 'transcript',\n",
       "       'transcript_nchar', 'videoid', 'conspiracy', 'var_r', 'var_g', 'var_b',\n",
       "       'var_h', 'var_s', 'var_v', 'var_bright', 'var_bright_sd',\n",
       "       'var_contrast', 'var_colorful', 'median_r', 'median_g', 'median_b',\n",
       "       'median_h', 'median_s', 'median_v', 'median_bright', 'median_bright_sd',\n",
       "       'median_contrast', 'median_colorful', 'r_mean', 'g_mean', 'b_mean',\n",
       "       'h_mean', 's_mean', 'v_mean', 'bright_mean', 'lightning_mean',\n",
       "       'contrast_mean', 'colorful_mean', 'color_lag'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('handlabel_feature.csv')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['transcript']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>with coronavirus completely changing our way o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>you all know I'm a big fan of conspiracy theor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>how do you handle an epidemic in the age of fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CaptionUnavailable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>what's up guys Stephen here and welcome back t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>so the government work for us we don't work fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>but even if 5g has nothing to do with this cor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>um some people believe that 5g like like for c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>this is a podcast from the South China Morning...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>we're all catching the wires because of the fi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>407 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            transcript\n",
       "0    with coronavirus completely changing our way o...\n",
       "1    you all know I'm a big fan of conspiracy theor...\n",
       "2    how do you handle an epidemic in the age of fa...\n",
       "3                                   CaptionUnavailable\n",
       "4    what's up guys Stephen here and welcome back t...\n",
       "..                                                 ...\n",
       "402  so the government work for us we don't work fo...\n",
       "403  but even if 5g has nothing to do with this cor...\n",
       "404  um some people believe that 5g like like for c...\n",
       "405  this is a podcast from the South China Morning...\n",
       "406  we're all catching the wires because of the fi...\n",
       "\n",
       "[407 rows x 1 columns]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X[(X[\"transcript\"] != 'CaptionUnavailable') & (X[\"transcript\"] != 'VideoUnavailable')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(313, 1)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "df['attitude'] = le.fit_transform(df['attitude'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      0\n",
       "2      0\n",
       "4      0\n",
       "5      1\n",
       "      ..\n",
       "402    1\n",
       "403    0\n",
       "404    0\n",
       "405    0\n",
       "406    0\n",
       "Name: attitude, Length: 313, dtype: int64"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df['attitude'][(df[\"transcript\"] != 'CaptionUnavailable') & (df[\"transcript\"] != 'VideoUnavailable')]\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing we'll do is removing stopwords. These words do not have any value for predicting the sentiment.Also, we remove the http link in the texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting beautifulsoup4\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/41/e6495bd7d3781cee623ce23ea6ac73282a373088fcd0ddc809a047b18eae/beautifulsoup4-4.9.3-py3-none-any.whl (115kB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 122kB 3.5MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting soupsieve>1.2; python_version >= \"3.0\" (from beautifulsoup4)\n",
      "  Downloading https://files.pythonhosted.org/packages/02/fb/1c65691a9aeb7bd6ac2aa505b84cb8b49ac29c976411c6ab3659425e045f/soupsieve-2.1-py3-none-any.whl\n",
      "Installing collected packages: soupsieve, beautifulsoup4\n",
      "Successfully installed beautifulsoup4-4.9.3 soupsieve-2.1\n",
      "\u001b[33mWARNING: You are using pip version 19.2.3, however version 20.3.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 313/313 [00:06<00:00, 48.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "nltk.download()\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def clean_sentences(df):\n",
    "    reviews = []\n",
    "\n",
    "    for sent in tqdm(df['transcript']):\n",
    "        \n",
    "        #remove html content\n",
    "        review_text = BeautifulSoup(sent).get_text()\n",
    "        \n",
    "        #remove non-alphabetic characters\n",
    "        review_text = re.sub(\"[^a-zA-Z]\",\" \", review_text)\n",
    "    \n",
    "        #tokenize the sentences\n",
    "        words = word_tokenize(review_text.lower())\n",
    "    \n",
    "        #stop words removal\n",
    "        omit_words = set(stopwords.words('english'))\n",
    "        words = [x for x in words if x not in omit_words]\n",
    "        \n",
    "        #lemmatize each word to its lemma\n",
    "        lemma_words = [lemmatizer.lemmatize(i) for i in words]\n",
    "    \n",
    "        reviews.append(lemma_words)\n",
    "\n",
    "    return(reviews)\n",
    "\n",
    "#cleaned reviews for both train and test set retrieved\n",
    "train_sentences = clean_sentences(X)\n",
    "print(len(train_sentences))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/70/cf/87b25b265d23498b2b70ce873495cf7ef91394c4baff240210e26f3bc18a/gensim-3.8.3-cp37-cp37m-macosx_10_9_x86_64.whl (24.2MB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24.2MB 15.0MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy>=1.11.3 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from gensim) (1.18.5)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.5.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from gensim) (1.15.0)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.18.1 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from gensim) (1.4.1)\n",
      "Collecting smart-open>=1.8.1 (from gensim)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/9c/a16951b5a66c86f0ea8ff5aca8d5c700138e708a76412ee7a2ec7fbd4b44/smart_open-4.1.0.tar.gz (116kB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 122kB 13.0MB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: smart-open\n",
      "  Building wheel for smart-open (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for smart-open: filename=smart_open-4.1.0-cp37-none-any.whl size=106205 sha256=14fdc46604f5469e9e897ff7cb11a539d1a1137f86b3a6bd8062effa2875e356\n",
      "  Stored in directory: /Users/lynette/Library/Caches/pip/wheels/eb/83/5c/ead33ff91d363db5c2527b563746ba23887669c0221bd2484f\n",
      "Successfully built smart-open\n",
      "Installing collected packages: smart-open, gensim\n",
      "Successfully installed gensim-3.8.3 smart-open-4.1.0\n",
      "\u001b[33mWARNING: You are using pip version 19.2.3, however version 20.3.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install --upgrade gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm \n",
    "tqdm.pandas(desc=\"progress-bar\") \n",
    "from gensim.models.doc2vec import LabeledSentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To implement doc2vec, we have to labelise or tag each tokenised tweet with unique IDs. We can do so by using Gensimâ€™s LabeledSentence() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range(0, 313)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "range(0,len(train_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:4: DeprecationWarning: Call to deprecated `LabeledSentence` (Class will be removed in 4.0.0, use TaggedDocument instead).\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "def add_label(twt):\n",
    "    output = []\n",
    "    for i, s in zip(range(0,len(twt)), twt):\n",
    "        output.append(LabeledSentence(s, [\"transcript_\" + str(i)]))\n",
    "    return output\n",
    "\n",
    "labeled_X = add_label(train_sentences) # label all the tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LabeledSentence(words=['coronavirus', 'completely', 'changing', 'way', 'life', 'many', 'question', 'forced', 'u', 'ask', 'like', 'grocery', 'store', 'worker', 'delivery', 'people', 'essential', 'worker', 'earn', 'living', 'wage', 'health', 'care', 'tied', 'employment', 'okay', 'romantic', 'relationship', 'houseplant', 'get', 'done', 'finally', 'leave', 'house', 'normal', 'thing', 'like', 'tongue', 'kiss', 'uber', 'driver', 'gon', 'na', 'one', 'question', 'one', 'question', 'people', 'want', 'answer', 'anything', 'hell', 'disease', 'come', 'virus', 'shut', 'world', 'people', 'happy', 'people', 'happy', 'accept', 'official', 'explanation', 'china', 'virus', 'originated', 'live', 'animal', 'market', 'somehow', 'jumped', 'bat', 'human', 'like', 'okay', 'think', 'plot', 'dark', 'night', 'accept', 'u', 'stuck', 'house', 'nothing', 'except', 'throw', 'cat', 'birthday', 'party', 'zoo', 'everyone', 'everyone', 'home', 'time', 'come', 'theory', 'exactly', 'think', 'whole', 'thing', 'went', 'also', 'spending', 'lot', 'time', 'online', 'common', 'conspiracy', 'theory', 'seen', 'virus', 'jumped', 'bat', 'human', 'way', 'oreo', 'jumped', 'packaging', 'roommate', 'mouth', 'know', 'going', 'billy', 'see', 'theory', 'many', 'people', 'willing', 'accept', 'racism', 'people', 'saying', 'china', 'eat', 'kind', 'crazy', 'thing', 'hell', 'heard', 'eat', 'cooky', 'piece', 'paper', 'inside', 'also', 'ready', 'believe', 'pandemic', 'could', 'started', 'food', 'thing', 'look', 'man', 'situation', 'food', 'start', 'thing', 'like', 'flight', 'one', 'person', 'eats', 'tuna', 'sandwich', 'paid', 'price', 'story', 'made', 'sense', 'came', 'viral', 'video', 'people', 'eating', 'bad', 'soup', 'one', 'even', 'filmed', 'china', 'yeah', 'found', 'virus', 'survive', 'cooking', 'anyway', 'window', 'heard', 'different', 'conspiracy', 'theory', 'totally', 'make', 'sense', 'see', 'turn', 'corona', 'never', 'virus', 'actually', 'weapon', 'created', 'take', 'old', 'people', 'go', 'online', 'shortage', 'conspiracy', 'theory', 'alright', 'one', 'virus', 'bioengineered', 'lab', 'scientist', 'used', 'weapon', 'form', 'population', 'control', 'theory', 'former', 'politician', 'bronwyn', 'bishop', 'also', 'suggested', 'get', 'rid', 'non', 'productive', 'chinese', 'chinese', 'community', 'word', 'george', 'furniture', 'eliminated', 'filled', 'roseanne', 'barr', 'calling', 'novel', 'coronavirus', 'pandemic', 'ploy', 'kill', 'baby', 'boomer', 'alright', 'theory', 'theory', 'made', 'complete', 'sense', 'dye', 'virus', 'old', 'people', 'dy', 'anyway', 'old', 'people', 'bam', 'perfect', 'crime', 'think', 'soon', 'people', 'started', 'saying', 'okay', 'booma', 'sudden', 'got', 'coronavirus', 'old', 'people', 'dying', 'coincidence', 'might', 'asking', 'oh', 'would', 'anyone', 'would', 'anyone', 'want', 'take', 'old', 'people', 'well', 'know', 'maybe', 'someone', 'tired', 'giving', 'seat', 'bus', 'maybe', 'restaurant', 'owner', 'tired', 'open', 'dinner', 'p', 'maybe', 'young', 'people', 'tired', 'getting', 'as', 'whipped', 'bingo', 'point', 'motive', 'admit', 'much', 'wanted', 'believe', 'theory', 'ayah', 'let', 'go', 'okay', 'team', 'scientist', 'scientist', 'degree', 'qualification', 'sequenced', 'genome', 'corona', 'virus', 'broke', 'found', 'unlike', 'every', 'miami', 'virus', 'definitely', 'man', 'made', 'okay', 'fine', 'maybe', 'biological', 'weapon', 'designed', 'destroy', 'slot', 'machine', 'economy', 'favorite', 'theory', 'anyway', 'one', 'theory', 'one', 'theory', 'actually', 'make', 'sense', 'conspiracy', 'theory', 'sweeping', 'globe', 'coronavirus', 'caused', 'g', 'technology', 'theory', 'g', 'damage', 'human', 'immune', 'system', 'u', 'know', 'taking', 'place', 'right', 'nose', 'five', 'jack', 'actually', 'absorbs', 'oxygen', 'really', 'important', 'know', 'five', 'get', 'switched', 'people', 'drop', 'like', 'fly', 'sudden', 'got', 'excuse', 'well', 'virus', 'going', 'people', 'uk', 'bought', 'much', 'started', 'lighting', 'cellphone', 'tower', 'fire', 'fuzzy', 'bunny', 'yes', 'yeah', 'got', 'put', 'end', 'coronavirus', 'group', 'chat', 'know', 'people', 'part', 'group', 'know', 'sitting', 'home', 'right', 'smuggling', 'oh', 'g', 'cuz', 'virus', 'tell', 'ask', 'question', 'g', 'superfast', 'network', 'run', 'air', 'know', 'else', 'go', 'air', 'cooler', 'virus', 'else', 'go', 'air', 'superman', 'burger', 'eat', 'watching', 'last', 'superman', 'movie', 'five', 'guy', 'five', 'guy', 'g', 'rest', 'case', 'gon', 'na', 'lie', 'coverage', 'gap', 'g', 'theory', 'thing', 'make', 'doubt', 'starter', 'every', 'part', 'theory', 'completely', 'ridiculous', 'biologically', 'impossible', 'mention', 'coronavirus', 'also', 'exploded', 'place', 'even', 'g', 'figured', 'yet', 'g', 'like', 'g', 'g', 'broadcast', 'low', 'frequency', 'weak', 'damage', 'yeah', 'saying', 'g', 'make', 'sick', 'sort', 'like', 'saying', 'iphone', 'flashlight', 'gave', 'sunburn', 'fact', 'g', 'broadcast', 'range', 'normal', 'radio', 'yeah', 'let', 'honest', 'dangerous', 'thing', 'gotten', 'radio', 'virus', 'mumble', 'number', 'five', 'killed', 'people', 'top', 'corona', 'virus', 'come', 'fro', 'know', 'happy', 'said', 'know', 'tell', 'care', 'conspiracy', 'theory', 'debunked', 'taking', 'chance', 'longer', 'ordering', 'popeyes', 'spicy', 'bad', 'sandwich', 'even', 'though', 'delicious', 'also', 'decided', 'gon', 'na', 'get', 'old', 'risky', 'importantly', 'stopped', 'using', 'cell', 'phone', 'yeah', 'g', 'use', 'pager', 'ya', 'know', 'make', 'harder', 'send', 'nude', 'gon', 'na', 'best', 'know', 'alternative', 'could', 'wait', 'doctor', 'scientist', 'figure', 'virus', 'came', 'mean', 'come', 'man', 'crazy', 'well', 'show', 'tonight', 'go', 'able', 'help', 'people', 'going', 'hungry', 'pandemic', 'please', 'consider', 'donation', 'feeding', 'america', 'supplying', 'food', 'million', 'people', 'america', 'every', 'single', 'day', 'could', 'really', 'use', 'help', 'even', 'dollar', 'help', 'somebody', 'get', 'meal', 'stay', 'safe', 'wash', 'hand', 'remember', 'thing', 'need', 'get', 'crisis', 'right', 'keep', 'weed', 'inside', 'see', 'next', 'week'], tags=['transcript_0']),\n",
       " LabeledSentence(words=['know', 'big', 'fan', 'conspiracy', 'theory', 'long', 'harmless', 'fun', 'one', 'know', 'reptilian', 'controlling', 'world', 'talking', 'like', 'zipper', 'side', 'powerful', 'people', 'neck', 'reveal', 'giant', 'lizard', 'underneath', 'human', 'skin', 'suit', 'flat', 'earth', 'always', 'classic', 'fun', 'one', 'play', 'dangerous', 'one', 'think', 'one', 'really', 'taking', 'huge', 'upswing', 'amount', 'people', 'believe', 'g', 'causing', 'corona', 'virus', 'month', 'ago', 'fucking', 'joke', 'across', 'entire', 'internet', 'last', 'month', 'everyone', 'quarantine', 'lockdown', 'desperate', 'bored', 'think', 'getting', 'fucking', 'dumber', 'many', 'people', 'ironically', 'believing', 'g', 'cause', 'coronavirus', 'actually', 'believe', 'people', 'probably', 'believe', 'chocolate', 'milk', 'come', 'brown', 'cow', 'take', 'mere', 'minute', 'research', 'outside', 'facebook', 'auntie', 'vax', 'actual', 'scientific', 'research', 'take', 'minute', 'immediately', 'disprove', 'find', 'connection', 'g', 'tower', 'corona', 'virus', 'shocking', 'majority', 'people', 'people', 'speaking', 'blasphemy', 'puppet', 'illuminati', 'people', 'saying', 'people', 'see', 'truth', 'high', 'school', 'dropout', 'failed', 'every', 'fucking', 'course', 'know', 'one', 'understand', 'g', 'connection', 'corona', 'virus', 'scientist', 'expert', 'fucking', 'limp', 'dicked', 'fucking', 'idiot', 'sitting', 'basement', 'fear', 'government', 'listening', 'alarm', 'clock', 'tinfoil', 'hat', 'condom', 'real', 'intellectual', 'spreading', 'kind', 'shit', 'internet', 'laughable', 'fun', 'make', 'fun', 'starting', 'set', 'cell', 'cell', 'phone', 'tower', 'fire', 'fucking', 'crazy', 'getting', 'actually', 'dangerous', 'start', 'fucking', 'science', 'professor', 'gon', 'na', 'tackle', 'every', 'angle', 'gon', 'na', 'point', 'common', 'obvious', 'fallacy', 'logic', 'g', 'corona', 'virus', 'culprit', 'one', 'really', 'controlling', 'government', 'big', 'brother', 'got', 'u', 'thumb', 'want', 'u', 'see', 'earth', 'really', 'flat', 'using', 'coronavirus', 'keep', 'u', 'inside', 'wrecked', 'g', 'tower', 'start', 'origin', 'conspiracy', 'least', 'regard', 'corona', 'virus', 'china', 'wuhan', 'g', 'tower', 'rolled', 'end', 'little', 'bit', 'corona', 'virus', 'broke', 'people', 'attributing', 'tower', 'cause', 'ground', 'zero', 'coronavirus', 'tower', 'caused', 'pretty', 'much', 'logic', 'end', 'spread', 'united', 'state', 'saying', 'g', 'tower', 'cause', 'coronavirus', 'u', 'contagious', 'know', 'spreading', 'around', 'people', 'tower', 'emitting', 'much', 'radiation', 'causing', 'corona', 'virus', 'corona', 'virus', 'even', 'real', 'made', 'hoax', 'cover', 'radiation', 'poisoning', 'spent', 'hour', 'researching', 'conspiracy', 'theory', 'looking', 'around', 'everyone', 'say', 'twitter', 'circle', 'truly', 'believe', 'stuff', 'seem', 'agree', 'corona', 'virus', 'real', 'radiation', 'sickness', 'symptom', 'radiation', 'sickness', 'similar', 'reported', 'corona', 'virus', 'basically', 'whole', 'conspiracy', 'nutshell', 'fucking', 'ridiculous', 'g', 'tower', 'existed', 'u', 'since', 'early', 'idea', 'g', 'existed', 'much', 'longer', 'people', 'seem', 'think', 'g', 'longer', 'really', 'start', 'getting', 'g', 'early', 'actual', 'tower', 'everything', 'built', 'around', 'u', 'make', 'believe', 'like', 'tooth', 'fairy', 'shit', 'real', 'go', 'see', 'g', 'tower', 'real', 'world', 'person', 'smoke', 'mirror', 'magic', 'trick', 'shit', 'since', 'case', 'corona', 'virus', 'u', 'throughout', 'case', 'corona', 'virus', 'u', 'china', 'incident', 'corona', 'virus', 'started', 'explode', 'know', 'story', 'go', 'spread', 'throughout', 'entire', 'world', 'seem', 'think', 'actually', 'spreading', 'human', 'human', 'contact', 'transmitted', 'via', 'beam', 'tower', 'g', 'seems', 'accepted', 'belief', 'gon', 'na', 'mmediately', 'poke', 'hole', 'israel', 'case', 'corona', 'virus', 'dead', 'israel', 'g', 'tower', 'none', 'fuck', 'happen', 'logic', 'enlightened', 'twitter', 'user', 'quick', 'point', 'radiation', 'sickness', 'transferred', 'someone', 'infected', 'tower', 'u', 'part', 'world', 'travel', 'israel', 'started', 'spreading', 'way', 'well', 'impossible', 'via', 'radiation', 'sickness', 'hypothesis', 'asian', 'sickness', 'contagious', 'watched', 'chernobyl', 'hbo', 'think', 'understand', 'everything', 'know', 'radiation', 'well', 'tell', 'one', 'thing', 'chernobyl', 'got', 'wrong', 'kind', 'walking', 'fucking', 'virus', 'radiation', 'sickness', 'someone', 'know', 'radiation', 'sickness', 'transfer', 'onto', 'entire', 'fucking', 'clothes', 'entire', 'wardrobe', 'covered', 'dense', 'radiation', 'suffer', 'try', 'suffocate', 'maybe', 'whole', 'radiation', 'sickness', 'contagious', 'immediately', 'throw', 'radiation', 'sickness', 'hypothesis', 'able', 'spread', 'corona', 'virus', 'exist', 'contagious', 'people', 'ordered', 'stay', 'inside', 'radiation', 'poisoning', 'radiation', 'sickness', 'matter', 'around', 'thousand', 'people', 'one', 'gon', 'na', 'catch', 'easy', 'poke', 'thousand', 'different', 'hole', 'g', 'coronavirus', 'conspiracy', 'turn', 'shit', 'fucking', 'pin', 'cushion', 'weak', 'many', 'people', 'still', 'believe', 'think', 'want', 'want', 'believe', 'something', 'bigger', 'like', 'like', 'grand', 'conspiracy', 'man', 'trying', 'keep', 'something', 'silly', 'look', 'going', 'hard', 'laugh', 'leap', 'conclusion', 'draw', 'nonsensical', 'ridiculous', 'picked', 'two', 'quick', 'one', 'point', 'two', 'obvious', 'one', 'really', 'answer', 'seen', 'sure', 'going', 'comment', 'video', 'immediately', 'disregard', 'shit', 'still', 'try', 'promote', 'idea', 'g', 'coronavirus', 'thing', 'real', 'pathetic', 'anyway', 'know', 'need', 'poke', 'hole', 'already', 'goddamn', 'silly', 'even', 'look', 'second', 'like', 'fucking', 'science', 'teacher', 'graduated', 'university', 'human', 'science', 'degree', 'understand', 'lot', 'stuff', 'granted', 'brushed', 'whole', 'field', 'used', 'mean', 'barely', 'fucking', 'use', 'knowledge', 'anymore', 'get', 'understand', 'fear', 'come', 'locked', 'inside', 'desperate', 'looking', 'answer', 'idea', 'else', 'turn', 'twitter', 'giant', 'fucking', 'platform', 'full', 'lunatic', 'seem', 'believe', 'promoting', 'real', 'thing', 'since', 'constantly', 'twitter', 'nothing', 'else', 'besides', 'jerk', 'read', 'bitch', 'twitter', 'post', 'see', 'started', 'accept', 'get', 'blaming', 'people', 'dangerous', 'thing', 'blindly', 'follow', 'shit', 'science', 'research', 'find', 'interesting', 'community', 'real', 'scientist', 'apprehensive', 'g', 'implementation', 'future', 'g', 'health', 'implication', 'could', 'line', 'conspiracy', 'side', 'thing', 'using', 'promote', 'idea', 'scientist', 'afraid', 'may', 'think', 'scientist', 'believe', 'caused', 'coronavirus', 'truth', 'scientist', 'afraid', 'five', 'g', 'implication', 'line', 'said', 'anything', 'coronavirus', 'related', 'focusing', 'scientist', 'main', 'concern', 'able', 'study', 'long', 'term', 'health', 'effect', 'g', 'could', 'future', 'nothing', 'corona', 'virus', 'anything', 'like', 'community', 'want', 'little', 'research', 'done', 'g', 'implemented', 'think', 'perhaps', 'bit', 'rushed', 'nothing', 'fucking', 'scientist', 'thinking', 'cause', 'corona', 'virus', 'small', 'community', 'either', 'look', 'g', 'video', 'youtube', 'right', 'overwhelmingly', 'disliked', 'thousand', 'comment', 'saying', 'bullshit', 'trust', 'rise', 'sheeple', 'time', 'take', 'back', 'life', 'let', 'control', 'mind', 'know', 'let', 'anyone', 'tell', 'believe', 'told', 'believe', 'somebody', 'else', 'know', 'questioning', 'medium', 'questioning', 'source', 'lot', 'research', 'form', 'opinion', 'find', 'seriously', 'hypocritical', 'community', 'keep', 'saying', 'trust', 'anyone', 'trust', 'make', 'sense', 'like', 'listen', 'anyone', 'let', 'anyone', 'tell', 'believe', 'told', 'believe', 'dude', 'shit', 'stained', 'underwear', 'chat', 'room', 'somewhere', 'fucking', 'silly', 'hypocritical', 'questioning', 'thing', 'see', 'medium', 'online', 'think', 'healthy', 'thing', 'start', 'entering', 'echo', 'chamber', 'looking', 'thing', 'support', 'want', 'believe', 'getting', 'anywhere', 'making', 'problem', 'worse', 'focusing', 'coronavirus', 'aspect', 'conspiracy', 'theory', 'go', 'much', 'deeper', 'g', 'rabbit', 'hole', 'crazy', 'amount', 'conspiracy', 'especially', 'youtube', 'reason', 'seems', 'lot', 'youtubers', 'youtube', 'commenters', 'really', 'believe', 'five', 'g', 'ultimate', 'boogeyman', 'like', 'final', 'bos', 'holding', 'back', 'human', 'specie', 'like', 'g', 'one', 'keeping', 'u', 'growing', 'wing', 'opening', 'third', 'eye', 'weird', 'know', 'everyone', 'latched', 'g', 'mega', 'evil', 'mastermind', 'shit', 'input', 'regard', 'coronavirus', 'want', 'focus', 'absolutely', 'possible', 'way', 'g', 'caused', 'coronavirus', 'look', 'data', 'like', 'real', 'time', 'couple', 'month', 'see', 'g', 'role', 'play', 'pretty', 'much', 'trace', 'coronavirus', 'started', 'area', 'right', 'fucking', 'finger', 'tit', 'need', 'look', 'second', 'real', 'actual', 'fucking', 'source', 'outside', 'bad', 'twitter', 'shit', 'post', 'anti', 'vaxxer', 'mom', 'group', 'real', 'fucking', 'research', 'form', 'opinion', 'one', 'silly', 'lighting', 'g', 'cellphone', 'tower', 'fire', 'anyone', 'good', 'causing', 'damage', 'chemical', 'put', 'air', 'fucking', 'burning', 'thing', 'g', 'raise', 'beam', 'fear', 'cellphone', 'networking', 'existed', 'long', 'communication', 'always', 'ridiculous', 'always', 'silly', 'laughable', 'twitter', 'place', 'matter', 'outlandish', 'ridiculous', 'belief', 'going', 'blow', 'going', 'big', 'movement', 'behind', 'matter', 'like', 'twitter', 'example', 'whole', 'community', 'people', 'fuck', 'dog', 'like', 'community', 'would', 'never', 'find', 'home', 'anywhere', 'find', 'home', 'twitter', 'thousand', 'chat', 'page', 'twitter', 'actively', 'talk', 'fucking', 'dog', 'ten', 'thousand', 'follower', 'support', 'thing', 'absolutely', 'fucking', 'disgusting', 'people', 'believe', 'cellphone', 'evil', 'dangerous', 'thing', 'people', 'want', 'feel', 'like', 'smarter', 'everyone', 'else', 'know', 'one', 'saw', 'truth', 'peek', 'behind', 'curtain', 'got', 'truth', 'believe', 'thing', 'spread', 'twitter', 'people', 'gullible', 'bored', 'susceptible', 'misinformation', 'start', 'believing', 'start', 'getting', 'real', 'riled', 'lead', 'absolute', 'chaos', 'lead', 'setting', 'g', 'tower', 'fire', 'fucking', 'reason', 'crazy', 'shit', 'get', 'people', 'targeting', 'g', 'coronavirus', 'specifically', 'really', 'nothing', 'piece', 'evidence', 'even', 'remotely', 'martin', 'jesus', 'remotely', 'true', 'g', 'tower', 'built', 'whoo', 'ha', 'n', 'couple', 'month', 'coronavirus', 'outbreak', 'another', 'thing', 'see', 'tossed', 'around', 'one', 'fucking', 'stupid', 'community', 'plotted', 'every', 'major', 'pandemic', 'every', 'major', 'flu', 'correlated', 'mobile', 'tower', 'networking', 'correlation', 'also', 'like', 'spanish', 'flu', 'world', 'first', 'prototype', 'mobile', 'network', 'coincidence', 'think', 'like', 'six', 'say', 'six', 'coincidence', 'impossible', 'fucking', 'stupid', 'go', 'history', 'correlate', 'every', 'single', 'one', 'pandemic', 'flu', 'something', 'else', 'know', 'peanut', 'butter', 'sandwich', 'invented', 'four', 'year', 'later', 'spanish', 'flu', 'interesting', 'peanut', 'butter', 'jelly', 'sandwich', 'start', 'getting', 'packaged', 'know', 'next', 'one', 'dumb', 'fucking', 'terrible', 'research', 'evidence', 'yet', 'people', 'believing', 'face', 'value', 'probably', 'boredom', 'quarantine', 'wanted', 'talk', 'cuz', 'good', 'got', 'fucking', 'fired', 'shit', 'wacky', 'kind', 'fun', 'laugh', 'conspiracy', 'theory', 'like', 'flat', 'earth', 'one', 'people', 'believing', 'fine', 'go', 'outside', 'spread', 'fucking', 'shit', 'place', 'especially', 'time', 'pandemic', 'like', 'convinced', 'know', 'truth', 'cell', 'phone', 'tower', 'coronavirus', 'hurting', 'everyone', 'around', 'think', 'terrible', 'wanted', 'talk', 'see', 'ya'], tags=['transcript_1']),\n",
       " LabeledSentence(words=['handle', 'epidemic', 'age', 'fake', 'news', 'carefully', 'orchestrated', 'official', 'message', 'fully', 'understand', 'public', 'concern', 'science', 'based', 'driven', 'expert', 'advice', 'currently', 'evidence', 'china', 'least', 'would', 'imply', 'child', 'much', 'le', 'disease', 'backed', 'advertising', 'mainstream', 'medium', 'lie', 'rumor', 'theory', 'spread', 'speed', 'around', 'social', 'medium', 'internet', 'new', 'challenge', 'government', 'treading', 'line', 'information', 'preparedness', 'panic', 'never', 'prevent', 'people', 'panicking', 'speculating', 'possible', 'cause', 'particularly', 'health', 'situation', 'however', 'think', 'seeing', 'much', 'proactive', 'stance', 'social', 'medium', 'company', 'compared', 'saw', 'response', 'disinformation', 'election', 'battle', 'infidel', 'ik', 'world', 'health', 'organization', 'fighting', 'reportedly', 'held', 'meeting', 'tech', 'group', 'like', 'facebook', 'amazon', 'airbnb', 'providing', 'accurate', 'information', 'today', 'facebook', 'founder', 'pledged', 'act', 'offering', 'free', 'advert', 'w', 'h', 'saying', 'would', 'remove', 'false', 'claim', 'block', 'exploitative', 'ad', 'social', 'medium', 'platform', 'raise', 'question', 'future', 'whether', 'bringing', 'much', 'establishment', 'much', 'role', 'say', 'broadcaster', 'take', 'responsibility', 'platform', 'effect', 'another', 'weapon', 'spread', 'fake', 'online', 'news', 'government', 'provision', 'clear', 'credible', 'information', 'crucial', 'part', 'battle', 'well', 'closed', 'strategy', 'something', 'nobody', 'recommends', 'people', 'recommend', 'powering', 'population', 'helping', 'understand', 'going', 'need', 'watching', 'order', 'prevent', 'getting', 'infected', 'prevent', 'others', 'getting', 'infected', 'really', 'openness', 'necessary', 'outbreak', 'contained', 'contained', 'say', 'air', 'type', 'pretty', 'close', 'air', 'tight', 'mean', 'country', 'leader', 'seemed', 'keen', 'play', 'seriousness', 'situation', 'politicizing', 'coronavirus', 'think', 'new', 'hoax', 'nonetheless', 'trump', 'white', 'house', 'say', 'took', 'strong', 'action', 'early', 'truth', 'western', 'democracy', 'generally', 'pretty', 'good', 'disseminating', 'information', 'citizen', 'u', 'administration', 'policy', 'advisor', 'told', 'news', 'night', 'questioned', 'whether', 'iran', 'tight', 'hold', 'information', 'exacerbated', 'spread', 'disease', 'regime', 'delay', 'telling', 'people', 'outbreak', 'corona', 'virus', 'consequence', 'people', 'take', 'necessary', 'precaution', 'today', 'iran', 'highest', 'death', 'rate', 'world', 'coronavirus', 'saw', 'interview', 'doctor', 'cuza', 'stan', 'province', 'said', 'regime', 'covered', 'month', 'clear', 'epidemic', 'regime', 'prepared', 'faith', 'politician', 'indeed', 'medium', 'important', 'public', 'health', 'crisis', 'covert', 'perhaps', 'hit', 'wrong', 'time', 'still', 'inclination', 'look', 'odd', 'place', 'answer', 'look', 'like', 'life', 'serious', 'thing', 'football', 'manager', 'opinion', 'important', 'politics', 'coronavirus', 'base', 'cap', 'bed', 'shade', 'challenge', 'barely', 'began', 'new', 'virus', 'could', 'also', 'raise', 'st', 'century', 'question', 'gatekeeper', 'information', 'crisis', 'ultimately', 'trust', 'joining', 'victoria', 'bane', 'former', 'facebook', 'trust', 'safety', 'manager', 'anna', 'sophie', 'harlan', 'news', 'guard', 'online', 'browser', 'extension', 'report', 'digital', 'misinformation', 'monitor', 'news', 'website', 'reliability', 'annasophia', 'start', 'look', 'inaccurate', 'source', 'information', 'online', 'come', 'coronavirus', 'found', 'seen', 'overwhelmingly', 'user', 'around', 'globe', 'going', 'source', 'like', 'facebook', 'twitter', 'accessing', 'would', 'call', 'read', 'rated', 'source', 'unreliable', 'source', 'crona', 'information', 'seen', 'source', 'like', 'w', 'show', 'u', 'center', 'disease', 'control', 'amassed', 'share', 'engagement', 'facebook', 'last', 'couple', 'week', 'around', 'whereas', 'read', 'rated', 'health', 'source', 'spreading', 'coronavirus', 'misinformation', 'amassed', 'something', 'like', 'fifty', 'two', 'million', 'engagement', 'quite', 'shocking', 'seeing', 'similar', 'number', 'coming', 'uk', 'despite', 'facebook', 'best', 'effort', 'nh', 'website', 'receiving', 'much', 'traffic', 'uk', 'opposed', 'u', 'red', 'rated', 'source', 'actually', 'seeing', 'shared', 'widely', 'uk', 'victoria', 'facebook', 'made', 'announcement', 'easy', 'take', 'sort', 'information', 'misinformation', 'understand', 'seen', 'reporting', 'taking', 'material', 'reported', 'one', 'measure', 'company', 'like', 'facebook', 'would', 'say', 'also', 'google', 'google', 'search', 'youtube', 'taking', 'moment', 'working', 'world', 'health', 'organization', 'nh', 'hotline', 'like', 'official', 'source', 'also', 'promoting', 'official', 'source', 'people', 'logging', 'facebook', 'today', 'using', 'google', 'search', 'today', 'noticed', 'so', 'alert', 'top', 'news', 'feed', 'search', 'page', 'search', 'coronavirus', 'behind', 'scene', 'also', 'another', 'approach', 'try', 'investigate', 'identify', 'remove', 'possible', 'source', 'coordinated', 'disinformation', 'something', 'president', 'putin', 'course', 'alluded', 'today', 'impossible', 'hostile', 'actor', 'looking', 'sow', 'disinformation', 'deliberately', 'saying', 'ana', 'sophie', 'misinformation', 'spreading', 'almost', 'quickly', 'virus', 'mean', 'look', 'mentioned', 'earlier', 'know', 'anti', 'vaxxers', 'talking', 'weaponized', 'disease', 'yeah', 'weaponized', 'know', 'issue', 'know', 'gon', 'na', 'undermine', 'brexit', 'sort', 'kind', 'crazy', 'idea', 'spreading', 'yeah', 'new', 'coronavirus', 'cause', 'misinformation', 'online', 'misinformation', 'disinformation', 'existed', 'long', 'tech', 'platform', 'existed', 'right', 'seeing', 'brought', 'foreground', 'tech', 'platform', 'really', 'taking', 'action', 'new', 'scart', 'would', 'like', 'see', 'sort', 'action', 'promoting', 'quality', 'content', 'bringing', 'greater', 'transparency', 'platform', 'educating', 'consumer', 'locate', 'quality', 'source', 'something', 'extend', 'beyond', 'coronavirus', 'really', 'kind', 'action', 'would', 'want', 'tech', 'platform', 'see', 'every', 'day', 'empower', 'consumer', 'quality', 'information', 'touched', 'earlier', 'russian', 'bot', 'example', 'spreading', 'conspiracy', 'theory', 'people', 'misinformed', 'putting', 'thing', 'wrong', 'online', 'far', 'seen', 'lot', 'evidence', 'russian', 'bot', 'although', 'may', 'emerge', 'time', 'follow', 'anna', 'anna', 'sophia', 'saying', 'would', 'really', 'like', 'see', 'much', 'responsibility', 'member', 'public', 'check', 'seeing', 'good', 'analogy', 'cybersecurity', 'spread', 'infection', 'nothing', 'talked', 'computer', 'virus', 'spreading', 'know', 'computer', 'infection', 'would', 'like', 'see', 'people', 'taking', 'responsibility', 'share', 'friend', 'family', 'exactly', 'way', 'talked', 'cough', 'sneeze', 'would', 'like', 'add', 'give', 'people', 'responsibility', 'also', 'need', 'give', 'tool', 'make', 'informed', 'decision', 'think', 'really', 'important', 'educate', 'online', 'user', 'locate', 'quality', 'source', 'identify', 'example', 'might', 'behind', 'certain', 'website', 'might', 'motivation', 'aside', 'bot', 'sort', 'foreign', 'born', 'propaganda', 'really', 'seeing', 'term', 'online', 'health', 'myth', 'disinformation', 'malicious', 'actor', 'take', 'advantage', 'fear', 'hysteria', 'surrounding', 'coronavirus', 'right', 'vaccine', 'kind', 'health', 'issue', 'order', 'turn', 'profit', 'might', 'publishing', 'false', 'information', 'get', 'ad', 'click', 'might', 'simply', 'trying', 'promote', 'certain', 'product', 'often', 'time', 'quite', 'harmful', 'product', 'need', 'teach', 'people', 'think', 'person', 'trying', 'get', 'message', 'coming', 'across', 'trying', 'motivate', 'attention', 'fear', 'likely', 'people', 'realize', 'self', 'regulate', 'tool', 'really', 'challenging', 'actually', 'live', 'environment', 'encouraged', 'online', 'interaction', 'click', 'click', 'offer', 'click', 'ad', 'delaying', 'gratification', 'one', 'challenge', 'u', 'work', 'cyber', 'security', 'challenge', 'stopping', 'people', 'clicking', 'link', 'malicious', 'software', 'phishing', 'email', 'instance', 'much', 'holy', 'grail', 'cyber', 'security', 'think', 'would', 'also', 'stress', 'promotion', 'legitimate', 'material', 'hoax', 'pushed', 'ranked', 'promotion', 'legitimate', 'material', 'remains', 'annasophia', 'harlan', 'thank', 'much'], tags=['transcript_2']),\n",
       " LabeledSentence(words=['guy', 'stephen', 'welcome', 'back', 'another', 'video', 'today', 'talking', 'really', 'serious', 'topic', 'well', 'last', 'day', 'little', 'bit', 'time', 'usual', 'check', 'social', 'medium', 'feed', 'found', 'one', 'post', 'facebook', 'guy', 'claimed', 'g', 'cause', 'coronavirus', 'outbreak', 'wuhan', 'china', 'advanced', 'g', 'lot', 'g', 'station', 'basically', 'comparing', 'symptom', 'rf', 'exposure', 'basically', 'radio', 'frequency', 'exposure', 'symptom', 'corona', 'virus', 'post', 'shared', 'couple', 'thousand', 'time', 'confusing', 'people', 'thought', 'still', 'lot', 'misunderstanding', 'g', 'today', 'video', 'tell', 'truth', 'g', 'health', 'effect', 'guy', 'dig', 'little', 'bit', 'deeper', 'need', 'find', 'g', 'g', 'fifth', 'generation', 'mobile', 'network', 'standard', 'g', 'fifth', 'generation', 'nothing', 'five', 'gigahertz', 'wi', 'fi', 'something', 'lot', 'people', 'mix', 'five', 'gigahertz', 'wi', 'fi', 'basically', 'wi', 'fi', 'operating', 'five', 'gigahertz', 'frequency', 'g', 'go', 'way', 'higher', 'frequency', 'also', 'called', 'millimeter', 'wave', 'talk', 'second', 'talking', 'g', 'need', 'separate', 'two', 'frequency', 'group', 'right', 'sub', 'gigahertz', 'band', 'basically', 'also', 'overlapping', 'little', 'bit', 'frequency', 'used', 'network', 'everything', 'megahertz', 'second', 'frequency', 'group', 'higher', 'also', 'called', 'millimeter', 'wave', 'start', 'gigahertz', 'second', 'frequency', 'group', 'something', 'giga', 'hertz', 'around', 'gerdes', 'actually', 'need', 'higher', 'frequency', 'g', 'well', 'g', 'make', 'speed', 'faster', 'therefore', 'need', 'bigger', 'bandwidth', 'essentially', 'frequency', 'instance', 'let', 'explain', 'megahertz', 'bandwidth', 'transporting', 'megahertz', 'carrier', 'frequency', 'actually', 'get', 'throughput', 'transporting', 'megahertz', 'bandwidth', 'instance', 'gigahertz', 'basically', 'gigahertz', 'carrier', 'frequency', 'really', 'tell', 'anything', 'fruit', 'term', 'speed', 'higher', 'frequency', 'also', 'way', 'higher', 'bandwidth', 'instance', 'g', 'go', 'around', 'megahertz', 'bandwidth', 'g', 'go', 'around', 'megahertz', 'bandwidth', 'mean', 'five', 'time', 'bandwidth', 'g', 'talking', 'bandwidth', 'actually', 'imagine', 'pipe', 'instance', 'imagine', 'pipe', 'g', 'like', 'size', 'g', 'like', 'five', 'time', 'bigger', 'transport', 'much', 'data', 'hundred', 'megahertz', 'bandwidth', 'channel', 'higher', 'frequency', 'used', 'g', 'past', 'need', 'high', 'frequency', 'actually', 'need', 'bandwidth', 'right', 'many', 'connected', 'device', 'iot', 'need', 'bandwidth', 'video', 'remain', 'k', 'k', 'well', 'mean', 'need', 'go', 'higher', 'frequency', 'higher', 'frequency', 'actually', 'nice', 'bandwidth', 'actually', 'put', 'data', 'bad', 'thing', 'also', 'travel', 'far', 'need', 'station', 'actually', 'build', 'network', 'range', 'lower', 'frequency', 'actually', 'much', 'higher', 'get', 'bandwidth', 'term', 'throughput', 'network', 'handset', 'much', 'client', 'network', 'iot', 'device', 'also', 'latency', 'need', 'really', 'low', 'latency', 'thing', 'like', 'autonomous', 'driving', 'car', 'need', 'communicate', 'fast', 'possible', 'network', 'something', 'g', 'also', 'two', 'version', 'g', 'g', 'non', 'stand', 'alone', 'g', 'standalone', 'country', 'right', 'g', 'running', 'g', 'infrastructure', 'easier', 'operator', 'roll', 'also', 'missing', 'full', 'g', 'feature', 'using', 'g', 'fortune', 'fruss', 'truck', 'sure', 'mean', 'g', 'signal', 'weak', 'reason', 'right', 'beginning', 'network', 'sometimes', 'little', 'bit', 'hard', 'get', 'really', 'good', 'g', 'signal', 'switch', 'back', 'oh', 'gee', 'handoff', 'actually', 'introducing', 'latency', 'network', 'latency', 'something', 'want', 'g', 'g', 'ultra', 'low', 'latency', 'five', 'cheese', 'standalone', 'actually', 'get', 'super', 'ultra', 'low', 'latency', 'guy', 'little', 'bit', 'basic', 'understand', 'higher', 'frequency', 'used', 'g', 'network', 'get', 'fruit', 'get', 'bandwidth', 'actually', 'need', 'get', 'speed', 'want', 'talk', 'little', 'bit', 'millimeter', 'wave', 'higher', 'frequency', 'called', 'millimeter', 'wave', 'actually', 'thing', 'people', 'think', 'dangerous', 'g', 'told', 'getting', 'gigahertz', 'may', 'even', 'future', 'everything', 'gigahertz', 'actually', 'categorized', 'millimeter', 'wave', 'frequency', 'people', 'think', 'cause', 'several', 'symptom', 'also', 'used', 'crowd', 'control', 'something', 'actually', 'true', 'fcc', 'actually', 'also', 'declared', 'back', 'august', 'last', 'year', 'g', 'save', 'last', 'day', 'big', 'news', 'icn', 'irp', 'pre', 'long', 'name', 'international', 'commission', 'non', 'ionizing', 'radiation', 'protection', 'based', 'germany', 'also', 'updated', 'guideline', 'new', 'standard', 'old', 'frequency', 'standard', 'sure', 'way', 'lower', 'need', 'data', 'analyzed', 'everything', 'said', 'okay', 'safe', 'certain', 'limit', 'right', 'g', 'really', 'way', 'limit', 'millimeter', 'wave', 'general', 'also', 'used', 'plenty', 'country', 'right', 'said', 'safe', 'really', 'need', 'differentiate', 'type', 'radiation', 'people', 'hear', 'radiation', 'g', 'think', 'chernobyl', 'something', 'like', 'radioactive', 'radiation', 'actually', 'non', 'ionizing', 'radiation', 'ionizing', 'radiation', 'ionizing', 'radiation', 'basically', 'break', 'chemical', 'bond', 'yeah', 'harm', 'body', 'non', 'ionizing', 'radiation', 'harmful', 'body', 'let', 'give', 'example', 'sun', 'ray', 'mostly', 'consists', 'non', 'ionizing', 'radiation', 'also', 'ionizing', 'radiation', 'long', 'ultraviolet', 'ray', 'mostly', 'get', 'absorbed', 'atmosphere', 'also', 'putting', 'protection', 'skin', 'non', 'ionizing', 'radiation', 'actually', 'harmful', 'body', 'yeah', 'g', 'non', 'ionizing', 'radiation', 'also', 'good', 'talk', 'thomas', 'ghia', 'huawei', 'invited', 'huawei', 'g', 'innovation', 'center', 'london', 'month', 'ago', 'something', 'like', 'showcased', 'new', 'g', 'technology', 'also', 'answering', 'lot', 'question', 'health', 'aspect', 'g', 'really', 'guy', 'guy', 'really', 'brilliant', 'know', 'lot', 'g', 'please', 'listen', 'carefully', 'say', 'health', 'aspect', 'g', 'right', 'guy', 'hawawa', 'ch', 'innovation', 'centre', 'thomas', 'gere', 'tell', 'u', 'something', 'today', 'g', 'answer', 'question', 'right', 'thomas', 'could', 'quickly', 'introduce', 'hi', 'thomas', 'gear', 'huawei', 'wireless', 'department', 'supported', 'opening', 'fabulous', 'place', 'london', 'actually', 'wondering', 'know', 'away', 'room', 'today', 'know', 'yeah', 'asked', 'pleasure', 'today', 'share', 'bit', 'exciting', 'know', 'experience', 'opened', 'center', 'london', 'right', 'consumer', 'simple', 'word', 'key', 'benefit', 'g', 'think', 'actually', 'biggest', 'invention', 'made', 'possible', 'due', 'g', 'yeah', 'mean', 'obviously', 'impacting', 'consumer', 'business', 'think', 'first', 'term', 'consumer', 'everybody', 'know', 'think', 'speed', 'example', 'behind', 'u', 'know', 'g', 'g', 'know', 'speed', 'know', 'screen', 'tester', 'showing', 'massive', 'difference', 'obviously', 'two', 'network', 'mean', 'mean', 'obviously', 'know', 'download', 'know', 'movie', 'episode', 'much', 'faster', 'g', 'two', 'day', 'know', 'data', 'hungry', 'world', 'make', 'big', 'difference', 'mean', 'well', 'inside', 'term', 'latency', 'know', 'consumer', 'gaming', 'lot', 'mobile', 'gaming', 'cloud', 'gaming', 'mean', 'know', 'multi', 'user', 'cloud', 'gaming', 'desktop', 'quality', 'mobile', 'actually', 'connect', 'g', 'modem', 'know', 'home', 'tv', 'know', 'desktop', 'quality', 'tv', 'need', 'go', 'expensive', 'pc', 'know', 'game', 'console', 'know', 'know', 'easy', 'switch', 'know', 'happy', 'larry', 'know', 'yes', 'right', 'far', 'g', 'show', 'people', 'already', 'g', 'answered', 'nowadays', 'yeah', 'think', 'starting', 'second', 'phase', 'would', 'sell', 'g', 'handset', 'meaning', 'expensive', 'one', 'know', 'big', 'format', 'people', 'want', 'show', 'could', 'know', 'g', 'know', 'really', 'anything', 'big', 'screen', 'know', 'lower', 'price', 'level', 'mid', 'range', 'handset', 'released', 'released', 'moment', 'term', 'way', 'u', 'good', 'thing', 'handset', 'multi', 'know', 'g', 'band', 'meaning', 'go', 'different', 'network', 'around', 'world', 'might', 'know', 'already', 'compatible', 'type', 'g', 'network', 'think', 'today', 'travel', 'people', 'travel', 'lot', 'quite', 'important', 'think', 'buy', 'g', 'phone', 'check', 'know', 'think', 'important', 'feature', 'check', 'yeah', 'right', 'heard', 'actually', 'g', 'phone', 'quite', 'big', 'like', 'may', 'g', 'um', 'probably', 'g', 'chip', 'work', 'right', 'dissipate', 'lot', 'heat', 'true', 'think', 'might', 'true', 'beginning', 'chipset', 'actually', 'improved', 'time', 'mate', 'pro', 'dice', 'released', 'market', 'proving', 'smaller', 'form', 'factor', 'know', 'heat', 'comparable', 'g', 'phone', 'know', 'lot', 'heat', 'dissipation', 'know', 'technology', 'know', 'worked', 'know', 'know', 'r', 'building', 'g', 'network', 'also', 'solving', 'problem', 'think', 'solved', 'almost', 'already', 'particular', 'okay', 'question', 'received', 'g', 'latency', 'lower', 'actually', 'whole', 'processing', 'thing', 'five', 'cheese', 'used', 'done', 'cloud', 'actually', 'know', 'whole', 'infrastructure', 'network', 'g', 'enabling', 'know', 'better', 'antenna', 'system', 'also', 'call', 'know', 'moment', 'g', 'know', 'base', 'network', 'network', 'upgrade', 'actually', 'enabling', 'lot', 'lower', 'latency', 'already', 'latency', 'lower', 'maybe', 'g', 'millisecond', 'noticeable', 'background', 'vr', 'last', 'year', 'know', 'latency', 'important', 'want', 'millisecond', 'vr', 'headset', 'know', 'see', 'difference', 'know', 'turn', 'head', 'start', 'get', 'know', 'sake', 'motion', 'sickness', 'important', 'actually', 'get', 'sub', 'sub', 'know', 'latency', 'already', 'two', 'day', 'g', 'version', 'network', 'think', 'big', 'deal', 'yeah', 'people', 'talk', 'g', 'already', 'think', 'radiation', 'dangerous', 'g', 'dangerous', 'yeah', 'mean', 'funny', 'subject', 'obviously', 'know', 'seen', 'lot', 'know', 'naysayer', 'distributing', 'leaflet', 'know', 'train', 'etc', 'think', 'people', 'every', 'time', 'technology', 'wave', 'know', 'something', 'talk', 'become', 'know', 'kind', 'activist', 'actually', 'lot', 'test', 'done', 'lot', 'neutral', 'know', 'organization', 'know', 'g', 'le', 'radiation', 'know', 'microwave', 'phone', 'know', 'actually', 'g', 'consuming', 'know', 'le', 'energy', 'term', 'antenna', 'g', 'antenna', 'know', 'would', 'health', 'risk', 'true', 'know', 'lot', 'evidence', 'around', 'know', 'look', 'gsma', 'website', 'know', 'one', 'key', 'asian', 'report', 'key', 'know', 'organization', 'coming', 'soon', 'think', 'people', 'need', 'actually', 'look', 'mobile', 'operator', 'website', 'well', 'actually', 'know', 'producing', 'know', 'research', 'people', 'see', 'actually', 'know', 'better', 'forgery', 'know', 'issue', 'far', 'concerned', 'yeah', 'graphic', 'seen', 'say', 'basically', 'g', 'radiation', 'called', 'radiation', 'meter', 'like', 'low', 'radiation', 'right', 'next', 'antenna', 'probably', 'high', 'ton', 'make', 'sure', 'affecting', 'people', 'near', 'regulation', 'place', 'antenna', 'something', 'like', 'g', 'need', 'lot', 'antenna', 'yeah', 'mean', 'lot', 'existing', 'regulation', 'around', 'antenna', 'know', 'always', 'case', 'reason', 'see', 'top', 'high', 'mast', 'top', 'building', 'engineer', 'know', 'allowed', 'actually', 'carry', 'repair', 'maintenance', 'switch', 'base', 'station', 'first', 'basically', 'antenna', 'dangerous', 'probably', 'within', 'one', 'two', 'three', 'meter', 'depending', 'know', 'power', 'know', 'actually', 'set', 'know', 'even', 'know', 'tv', 'program', 'covering', 'see', 'radiation', 'really', 'standing', 'front', 'industrial', 'know', 'level', 'antenna', 'know', 'really', 'know', 'nothing', 'consumer', 'people', 'like', 'walking', 'industry', 'antenna', 'would', 'mean', 'antenna', 'well', 'within', 'health', 'safety', 'regulation', 'put', 'well', 'know', 'top', 'building', 'structure', 'safe', 'know', 'everyone', 'right', 'regarding', 'safety', 'country', 'pretty', 'far', 'g', 'network', 'like', 'korea', 'instance', 'think', 'europe', 'level', 'yeah', 'guess', 'mean', 'end', 'end', 'know', 'g', 'network', 'get', 'gigabit', 'speed', 'yeah', 'obviously', 'older', 'infrastructure', 'know', 'country', 'dad', 'telecom', 'infrastructure', 'beginning', 'thing', 'upgrade', 'also', 'mobile', 'operator', 'think', 'already', 'happening', 'demand', 'specific', 'use', 'case', 'stadium', 'also', 'know', 'country', 'like', 'uk', 'need', 'actually', 'provide', 'know', 'fibre', 'speed', 'whole', 'nation', 'one', 'government', 'commitment', 'fibre', 'go', 'wireless', 'want', 'actually', 'know', 'reach', 'everybody', 'know', 'rural', 'area', 'well', 'dense', 'area', 'think', 'force', 'nature', 'happen', 'needed', 'know', 'guideline', 'target', 'know', 'government', 'alright', 'guy', 'thomas', 'big', 'thanks', 'information', 'interested', 'information', 'leave', 'link', 'scientific', 'resource', 'research', 'description', 'make', 'sure', 'check', 'see', 'believe', 'everything', 'internet', 'yeah', 'thank', 'guy', 'finally', 'answer', 'question', 'g', 'cause', 'coronavirus', 'anything', 'else', 'g', 'cause', 'anything', 'point', 'view', 'point', 'view', 'authority', 'commission', 'non', 'ionizing', 'radiation', 'protection', 'really', 'scientist', 'actually', 'causing', 'anything', 'harmful', 'really', 'crazy', 'misinformation', 'spread', 'internet', 'luckily', 'post', 'right', 'tagged', 'fake', 'news', 'facebook', 'well', 'people', 'actually', 'believe', 'shared', 'got', 'thousand', 'like', 'absolutely', 'crazy', 'please', 'guy', 'always', 'read', 'something', 'like', 'internet', 'research', 'talk', 'people', 'know', 'technology', 'always', 'new', 'technology', 'people', 'know', 'probably', 'scared', 'fully', 'understand', 'start', 'google', 'google', 'something', 'never', 'especially', 'sick', 'something', 'like', 'always', 'find', 'website', 'saying', 'entered', 'google', 'purpose', 'google', 'searching', 'something', 'find', 'something', 'exactly', 'googling', 'g', 'cause', 'cancer', 'find', 'website', 'saying', 'g', 'cause', 'cancer', 'already', 'information', 'bubble', 'yeah', 'go', 'crazy', 'actually', 'much', 'research', 'many', 'event', 'company', 'also', 'scientist', 'explaining', 'everything', 'also', 'austria', 'trip', 'magenta', 'basically', 'bought', 'emf', 'meter', 'electromagnetic', 'field', 'testing', 'near', 'g', 'station', 'actually', 'le', 'radiation', 'say', 'like', 'home', 'next', 'router', 'five', 'five', 'cheese', 'station', 'high', 'air', 'know', 'signal', 'travel', 'air', 'actually', 'loses', 'strength', 'every', 'distance', 'traveled', 'get', 'weaker', 'weaker', 'weaker', 'actually', 'radiation', 'directly', 'smartphone', 'pocket', 'putting', 'smartphone', 'directly', 'head', 'causing', 'radiation', 'coming', 'head', 'g', 'station', 'actually', 'g', 'station', 'mean', 'better', 'signal', 'wall', 'onto', 'smartphone', 'signal', 'smartphone', 'better', 'smartphone', 'need', 'transmit', 'much', 'power', 'mean', 'also', 'le', 'radiation', 'smartphone', 'need', 'transmit', 'much', 'power', 'get', 'better', 'signal', 'overall', 'g', 'point', 'view', 'le', 'radiation', 'right', 'sure', 'higher', 'frequency', 'well', 'studied', 'yeah', 'point', 'view', 'honest', 'want', 'say', 'scientist', 'something', 'really', 'think', 'safe', 'also', 'many', 'authority', 'right', 'tested', 'checked', 'result', 'increase', 'term', 'cancer', 'rate', 'pretty', 'pretty', 'safe', 'alrighty', 'guy', 'sorry', 'long', 'video', 'think', 'important', 'talk', 'topic', 'much', 'going', 'head', 'really', 'crazy', 'structure', 'thought', 'one', 'important', 'message', 'hard', 'time', 'right', 'first', 'stay', 'safe', 'stay', 'home', 'work', 'home', 'wash', 'hand', 'try', 'le', 'contact', 'people', 'important', 'message', 'right', 'especially', 'also', 'g', 'stop', 'believing', 'fake', 'news', 'internet', 'read', 'news', 'verified', 'source', 'stop', 'googling', 'negative', 'thing', 'get', 'negative', 'filter', 'bubble', 'basically', 'also', 'trump', 'president', 'right', 'power', 'social', 'medium', 'fake', 'news', 'spread', 'really', 'fast', 'stick', 'source', 'authority', 'scientist', 'something', 'like', 'yeah', 'important', 'thing', 'panic', 'stay', 'cool', 'really', 'hope', 'guy', 'enjoyed', 'video', 'well', 'want', 'see', 'topic', 'topic', 'future', 'please', 'make', 'sure', 'subscribe', 'also', 'big', 'thanks', 'huawei', 'inviting', 'trip', 'g', 'innovation', 'experience', 'center', 'also', 'big', 'thanks', 'faraway', 'supporting', 'hospital', 'wuhan', 'really', 'sure', 'guy', 'written', 'news', 'actually', 'supplied', 'g', 'station', 'network', 'keep', 'network', 'hard', 'time', 'right', 'think', 'really', 'cool', 'also', 'gave', 'away', 'free', 'cloud', 'storage', 'company', 'work', 'home', 'something', 'like', 'think', 'right', 'age', 'really', 'important', 'working', 'communication', 'always', 'guy', 'steven', 'tech', 'magnet', 'catch', 'next', 'one', 'nice', 'day', 'bye'], tags=['transcript_3']),\n",
       " LabeledSentence(words=['hi', 'guy', 'daniel', 'alexander', 'cannon', 'logic', 'authority', 'somewhat', 'emergency', 'broadcast', 'joke', 'theory', 'shutdown', 'lockdown', 'going', 'country', 'right', 'closing', 'school', 'something', 'would', 'going', 'already', 'thinking', 'probably', 'want', 'say', 'lead', 'anyone', 'number', 'people', 'contact', 'one', 'specifically', 'extremely', 'credible', 'want', 'read', 'interaction', 'okay', 'well', 'let', 'read', 'okay', 'contacted', 'initially', 'saying', 'hey', 'daniel', 'shut', 'channel', 'please', 'know', 'let', 'text', 'new', 'channel', 'later', 'date', 'put', 'video', 'last', 'night', 'person', 'text', 'said', 'work', 'local', 'school', 'board', 'ge', 'getting', 'lot', 'bad', 'press', 'lately', 'know', 'u', 'department', 'education', 'wanting', 'roll', 'g', 'network', 'many', 'district', 'school', 'unfortunately', 'parent', 'whole', 'would', 'try', 'stop', 'implementation', 'u', 'department', 'education', 'decided', 'close', 'school', 'dear', 'pandemic', 'two', 'reason', 'one', 'make', 'parent', 'think', 'child', 'safety', 'virus', 'two', 'install', 'g', 'network', 'many', 'district', 'school', 'g', 'company', 'instructed', 'use', 'guise', 'disinfecting', 'company', 'strict', 'order', 'anyone', 'asks', 'cleaning', 'company', 'two', 'dissing', 'fact', 'school', 'tell', 'anyone', 'installing', 'g', 'contractor', 'must', 'sign', 'nondisclosure', 'agreement', 'shit', 'getting', 'real', 'daniel', 'please', 'help', 'course', 'responded', 'okay', 'started', 'digging', 'show', 'little', 'bit', 'minute', 'conversation', 'continued', 'person', 'said', 'critical', 'information', 'classified', 'position', 'school', 'board', 'unfortunately', 'think', 'given', 'give', 'one', 'know', 'get', 'one', 'three', 'people', 'could', 'leaked', 'thanks', 'daniel', 'wrote', 'back', 'talking', 'worldwide', 'situation', 'nothing', 'going', 'school', 'district', 'however', 'whatever', 'school', 'district', 'likely', 'across', 'nation', 'need', 'mention', 'name', 'county', 'name', 'state', 'need', 'truth', 'important', 'said', 'plus', 'anything', 'know', 'level', 'likely', 'known', 'hundred', 'thousand', 'asleep', 'may', 'maybe', 'know', 'importance', 'matter', 'responded', 'yes', 'text', 'classified', 'information', 'smart', 'man', 'district', 'must', 'nationwide', 'also', 'information', 'choose', 'divulge', 'like', 'name', 'contractor', 'date', 'time', 'installs', 'location', 'etc', 'tell', 'nationwide', 'figure', 'access', 'u', 'department', 'education', 'web', 'server', 'district', 'crazy', 'reason', 'login', 'allows', 'venture', 'district', 'local', 'district', 'national', 'program', 'believe', 'many', 'school', 'going', 'roll', 'implement', 'five', 'implement', 'g', 'network', 'short', 'period', 'time', 'yes', 'truth', 'done', 'done', 'mid', 'april', 'hundred', 'thousand', 'though', 'may', 'know', 'may', 'know', 'beat', 'em', 'asleep', 'notified', 'g', 'safe', 'gotten', 'bad', 'press', 'conspiracy', 'theorist', 'therefore', 'ask', 'refrain', 'asking', 'acknowledging', 'public', 'upgrade', 'need', 'parent', 'false', 'fear', 'g', 'time', 'corona', 'virus', 'pandemic', 'say', 'say', 'verbatim', 'close', 'memory', 'let', 'read', 'rest', 'talk', 'little', 'bit', 'say', 'yes', 'please', 'mention', 'district', 'also', 'one', 'state', 'would', 'appreciate', 'anonymity', 'way', 'thanks', 'daniel', 'someone', 'position', 'people', 'within', 'state', 'access', 'knowledge', 'g', 'rollout', 'school', 'district', 'guise', 'cleaning', 'school', 'like', 'thought', 'confirmed', 'okay', 'shut', 'lockdown', 'go', 'place', 'school', 'installing', 'g', 'elementary', 'school', 'school', 'high', 'school', 'child', 'going', 'exposed', 'eight', 'hour', 'day', 'gigahertz', 'millimeter', 'wave', 'radiation', 'going', 'devastate', 'youth', 'country', 'world', 'something', 'going', 'worldwide', 'think', 'good', 'thing', 'sneaking', 'back', 'door', 'pretending', 'cleaning', 'crew', 'told', 'say', 'anything', 'okay', 'know', 'bad', 'simple', 'obvious', 'got', 'stopped', 'justice', 'forget', 'turn', 'sometimes', 'got', 'stopped', 'many', 'within', 'sound', 'voice', 'ability', 'something', 'many', 'ability', 'ability', 'spread', 'video', 'spread', 'video', 'spread', 'information', 'something', 'stop', 'going', 'try', 'shove', 'throat', 'going', 'child', 'see', 'told', 'felt', 'like', 'many', 'reason', 'feel', 'way', 'feeling', 'bet', 'talk', 'feeling', 'okay', 'based', 'knowledge', 'okay', 'gon', 'na', 'ramp', 'making', 'like', 'looking', 'really', 'bad', 'gon', 'na', 'install', 'school', 'hospital', 'everywhere', 'okay', 'got', 'planned', 'got', 'white', 'van', 'white', 'truck', 'stuff', 'ready', 'go', 'packed', 'full', 'equipment', 'next', 'day', 'gon', 'na', 'shove', 'throat', 'sitting', 'home', 'gon', 'na', 'say', 'okay', 'everything', 'right', 'guy', 'come', 'safe', 'like', 'whoo', 'hon', 'got', 'five', 'gene', 'know', 'back', 'december', 'got', 'sick', 'thank', 'god', 'g', 'millimeter', 'gigahertz', 'millimeter', 'wave', 'g', 'see', 'december', 'st', 'china', 'law', 'said', 'immunization', 'december', 'st', 'country', 'declared', 'wuhan', 'fully', 'installed', 'st', 'december', 'g', 'gigahertz', 'wave', 'g', 'come', 'thirty', 'sixty', 'day', 'going', 'boat', 'wuhan', 'see', 'g', 'coverage', 'right', 'sitting', 'home', 'putting', 'school', 'putting', 'hospital', 'putting', 'office', 'building', 'especially', 'government', 'one', 'putting', 'street', 'everywhere', 'guarantee', 'huge', 'crew', 'huge', 'crew', 'people', 'clueless', 'think', 'something', 'good', 'gon', 'na', 'help', 'fight', 'virus', 'installing', 'stuff', 'hour', 'day', 'seven', 'day', 'week', 'happening', 'yet', 'maybe', 'coming', 'soon', 'lockdown', 'coming', 'gon', 'na', 'lock', 'entire', 'united', 'state', 'covered', 'closed', 'border', 'already', 'know', 'fact', 'canadian', 'border', 'closed', 'man', 'life', 'literally', 'spitting', 'distance', 'border', 'closed', 'one', 'coming', 'one', 'going', 'last', 'message', 'person', 'sent', 'said', 'please', 'understand', 'misunderstand', 'daniel', 'speculating', 'first', 'hand', 'knowledge', 'fact', 'see', 'conspiracy', 'theory', 'conspiracy', 'coming', 'coming', 'child', 'coming', 'something', 'deserve', 'get', 'see', 'something', 'stop', 'deserve', 'see', 'moral', 'place', 'stand', 'smart', 'enough', 'willing', 'take', 'risk', 'anything', 'stop', 'deserve', 'moral', 'card', 'stand', 'done', 'part', 'beautiful', 'lady', 'done', 'part', 'guy', 'got', 'part', 'know', 'let', 'share', 'something', 'else', 'person', 'say', 'daniel', 'live', 'rosebud', 'suez', 'reservation', 'south', 'dakota', 'friend', 'mine', 'learned', 'last', 'week', 'thursday', 'friday', 'fema', 'unloaded', 'semi', 'truck', 'plastic', 'coffin', 'would', 'imagine', 'respecting', 'preparing', 'said', 'incinerator', 'coffin', 'likely', 'look', 'across', 'youtube', 'facebook', 'video', 'truck', 'loaded', 'coffin', 'find', 'find', 'need', 'guy', 'scour', 'internet', 'well', 'guy', 'lot', 'power', 'research', 'guy', 'find', 'tell', 'old', 'video', 'talking', 'stuff', 'new', 'last', 'day', 'let', 'say', 'let', 'say', 'since', 'st', 'january', 'ok', 'find', 'stuff', 'people', 'put', 'caching', 'photo', 'video', 'coffin', 'move', 'need', 'see', 'reason', 'know', 'thinking', 'reason', 'thinking', 'virus', 'exist', 'well', 'might', 'tell', 'something', 'exist', 'installed', 'right', 'get', 'matter', 'virus', 'real', 'killer', 'g', 'coming', 'installed', 'behind', 'back', 'right', 'fixing', 'go', 'full', 'blast', 'school', 'everywhere', 'else', 'locked', 'home', 'want', 'everybody', 'home', 'want', 'nobody', 'see', 'going', 'gon', 'na', 'rule', 'like', 'permission', 'leave', 'house', 'think', 'happen', 'watch', 'mark', 'word', 'gon', 'na', 'want', 'know', 'going', 'path', 'taking', 'making', 'sure', 'going', 'seeing', 'something', 'gon', 'na', 'everything', 'controlled', 'area', 'work', 'gon', 'na', 'cop', 'one', 'end', 'cop', 'blocking', 'road', 'nobody', 'go', 'think', 'shutting', 'world', 'man', 'shut', 'world', 'block', 'school', 'see', 'need', 'wake', 'need', 'wake', 'person', 'said', 'said', 'daniel', 'wife', 'europe', 'hearing', 'three', 'friend', 'asked', 'check', 'coffin', 'information', 'gon', 'na', 'check', 'okay', 'person', 'name', 'greta', 'florida', 'say', 'know', 'one', 'case', 'warren', 'ohio', 'something', 'recovering', 'said', 'know', 'person', 'personally', 'like', 'phone', 'number', 'could', 'give', 'call', 'want', 'said', 'covered', 'positive', 'said', 'family', 'member', 'video', 'facebook', 'page', 'hospital', 'bed', 'yes', 'positive', 'okay', 'day', 'ago', 'ask', 'people', 'let', 'know', 'people', 'knew', 'know', 'personally', 'positive', 'cova', 'sick', 'sick', 'died', 'okay', 'tania', 'southern', 'california', 'contact', 'said', 'hi', 'daniel', 'thank', 'courage', 'stand', 'watchman', 'answer', 'question', 'southern', 'california', 'orange', 'county', 'border', 'la', 'louie', 'border', 'motor', 'la', 'shelf', 'empty', 'costco', 'sold', 'paper', 'product', 'water', 'rice', 'could', 'go', 'hit', 'target', 'walmart', 'food', 'store', 'illness', 'stress', 'strongly', 'enough', 'quite', 'real', 'extremely', 'sensitive', 'frequency', 'foggy', 'yes', 'g', 'toxic', 'certainly', 'would', 'make', 'situation', 'worse', 'cause', 'said', 'virus', 'husband', 'joe', 'international', 'traveler', 'three', 'homeschooled', 'kid', 'unvaccinated', 'organic', 'used', 'alternative', 'medicine', 'january', 'th', 'joe', 'returned', 'conference', 'la', 'vega', 'bos', 'attended', 'conference', 'sick', 'return', 'flight', 'spreading', 'spending', 'week', 'brazil', 'everyone', 'company', 'attended', 'conference', 'got', 'sick', 'week', 'later', 'week', 'seventeenth', 'youngest', 'got', 'sick', 'three', 'week', 'later', 'oldest', 'son', 'got', 'sick', 'day', 'later', 'daughter', 'got', 'sick', 'symptom', 'three', 'phase', 'first', 'phase', 'mild', 'cold', 'like', 'headache', 'behind', 'eye', 'eye', 'discharge', 'mild', 'sore', 'throat', 'dry', 'cough', 'seem', 'get', 'better', 'second', 'week', 'later', 'really', 'tired', 'achy', 'fever', 'key', 'fever', 'mild', 'dry', 'cough', 'kid', 'bringing', 'alcohol', 'rub', 'degree', 'temperature', 'went', 'fever', 'start', 'fever', 'break', 'start', 'feel', 'better', 'energy', 'slowly', 'return', 'third', 'week', 'later', 'tightness', 'top', 'chest', 'breathing', 'labored', 'fever', 'pneumonia', 'like', 'husband', 'oldest', 'youngest', 'recovered', 'day', 'two', 'month', 'pneumonia', 'mild', 'worse', 'obviously', 'california', 'exploding', 'soon', 'heard', 'cough', 'shopper', 'week', 'one', 'joe', 'co', 'worker', 'passed', 'grandma', 'died', 'pneumonia', 'two', 'week', 'ago', 'joe', 'attended', 'aunt', 'funeral', 'almost', 'three', 'week', 'ago', 'arkansas', 'died', 'pneumonia', 'two', 'week', 'returning', 'cruise', 'ship', 'held', 'service', 'three', 'day', 'death', 'since', 'still', 'testing', 'think', 'number', 'would', 'showing', 'pneumonia', 'death', 'one', 'helping', 'best', 'last', 'stage', 'lip', 'osorno', 'purse', 'mille', 'like', 'see', 'person', 'see', 'nac', 'whatever', 'sure', 'pre', 'precursor', 'blue', 'tone', 'blue', 'blue', 'python', 'something', 'like', 'read', 'sitting', 'salt', 'salt', 'cave', 'room', 'sure', 'mean', 'task', 'also', 'listening', 'got', 'referring', 'certain', 'frequency', 'sound', 'refers', 'dr', 'paul', 'cottrell', 'recommends', 'go', 'recommended', 'recommendation', 'work', 'well', 'opinion', 'dr', 'paul', 'cottrell', 'controlled', 'controlled', 'shield', 'like', 'british', 'nurse', 'doctor', 'older', 'man', 'sits', 'glass', 'read', 'stuff', 'every', 'day', 'asleep', 'sheep', 'either', 'one', 'two', 'thing', 'shield', 'nbc', 'news', 'interviewed', 'either', 'shield', 'sleep', 'sheep', 'trying', 'help', 'understand', 'dynamic', 'evil', 'going', 'okay', 'time', 'time', 'child', 'shown', 'image', 'thing', 'come', 'planet', 'unimaginable', 'believe', 'entering', 'time', 'unfortunately', 'agree', 'would', 'eye', 'see', 'walt', 'firmly', 'spirit', 'see', 'harvest', 'soul', 'love', 'tanya', 'sent', 'picture', 'trader', 'joe', 'bunch', 'empty', 'shell', 'text', 'back', 'said', 'many', 'people', 'know', 'personally', 'one', 'pneumonia', 'two', 'died', 'last', 'sixty', 'day', 'text', 'back', 'said', 'death', 'two', 'hospital', 'one', 'person', 'one', 'home', 'five', 'pneumonia', 'okay', 'two', 'died', 'also', 'southern', 'cow', 'except', 'one', 'arizona', 'believe', 'callie', 'getting', 'ready', 'go', 'lockdown', 'believe', 'right', 'okay', 'let', 'look', 'back', 'second', 'hang', 'say', 'people', 'thinking', 'kind', 'way', 'thinking', 'way', 'okay', 'well', 'first', 'hand', 'account', 'guy', 'okay', 'believe', 'taking', 'opportunity', 'go', 'school', 'okay', 'school', 'g', 'push', 'beginning', 'summer', 'gon', 'na', 'say', 'well', 'thing', 'better', 'everybody', 'go', 'back', 'work', 'everybody', 'go', 'back', 'school', 'everybody', 'go', 'back', 'normal', 'life', 'gon', 'na', 'make', 'america', 'great', 'gon', 'na', 'hit', 'time', 'going', 'reinforced', 'five', 'g', 'sixty', 'millimeter', 'gigahertz', 'millimeter', 'wave', 'band', 'frequency', 'going', 'separate', 'blood', 'ability', 'hang', 'oxygen', 'gon', 'na', 'see', 'kind', 'thing', 'happened', 'wuhan', 'happened', 'spanish', 'flu', 'history', 'stop', 'make', 'something', 'happen', 'best', 'make', 'something', 'happen', 'going', 'end', 'lot', 'people', 'blood', 'blood', 'gon', 'na', 'hand'], tags=['transcript_4']),\n",
       " LabeledSentence(words=['five', 'technology', 'begin', 'get', 'implemented', 'around', 'world', 'lot', 'confusion', 'concern', 'work', 'even', 'safe', 'today', 'gon', 'na', 'go', 'aspect', 'five', 'g', 'friend', 'tech', 'expert', 'mkbhd', 'gon', 'na', 'explain', 'people', 'excited', 'technology', 'gon', 'na', 'take', 'science', 'angle', 'actually', 'work', 'body', 'importantly', 'science', 'say', 'whether', 'safe', 'looked', 'hundred', 'scientific', 'paper', 'journal', 'order', 'decipher', 'truth', 'five', 'yes', 'jumping', 'conspiracy', 'theory', 'claim', 'stick', 'around', 'end', 'video', 'cause', 'pretty', 'wild', 'first', 'gon', 'na', 'throw', 'friend', 'mkbhd', 'tell', 'u', 'going', 'five', 'tech', 'right', 'hey', 'guy', 'mkbhd', 'five', 'technology', 'fifth', 'generation', 'data', 'network', 'getting', 'lot', 'hype', 'talked', 'lot', 'slowly', 'rolled', 'past', 'year', 'two', 'getting', 'insane', 'speed', 'phone', 'wavelength', 'used', 'five', 'technology', 'split', 'three', 'different', 'section', 'low', 'band', 'five', 'g', 'frequency', 'one', 'gigahertz', 'call', 'mid', 'band', 'five', 'g', 'slight', 'faster', 'travel', 'shorter', 'distance', 'millimeter', 'wave', 'talked', 'give', 'fastest', 'speed', 'us', 'highest', 'frequency', 'travel', 'shortest', 'distance', 'five', 'talking', 'download', 'speed', 'anywhere', 'megabyte', 'per', 'second', 'way', 'crazy', 'millimeter', 'wave', 'speed', 'might', 'seen', 'like', 'two', 'gigabyte', 'per', 'second', 'insane', 'mean', 'talking', 'like', 'whole', 'tv', 'show', 'season', 'downloads', 'second', 'download', 'speed', 'nice', 'five', 'tech', 'useful', 'far', 'phone', 'high', 'end', 'speed', 'low', 'latency', 'future', 'essential', 'thing', 'like', 'fleet', 'driverless', 'car', 'driving', 'swarm', 'talking', 'communicating', 'never', 'crash', 'way', 'thing', 'like', 'robot', 'surgeon', 'two', 'different', 'state', 'surgery', 'performed', 'remotely', 'real', 'time', 'chance', 'use', 'early', 'five', 'g', 'millimeter', 'wave', 'really', 'impressive', 'could', 'tell', 'long', 'way', 'go', 'used', 'rolled', 'world', 'starter', 'travel', 'far', 'easily', 'blocked', 'obstacle', 'stuff', 'talked', 'video', 'would', 'take', 'lot', 'node', 'lot', 'antenna', 'cover', 'small', 'area', 'like', 'town', 'let', 'alone', 'country', 'entire', 'globe', 'would', 'expensive', 'time', 'consuming', 'even', 'low', 'mid', 'band', 'five', 'still', 'impressive', 'term', 'improvement', 'speed', 'lot', 'going', 'pretty', 'exciting', 'future', 'five', 'say', 'come', 'lot', 'fear', 'concern', 'potential', 'effect', 'new', 'frequency', 'biology', 'health', 'throw', 'back', 'greg', 'mitch', 'talk', 'science', 'five', 'work', 'order', 'fully', 'understand', 'five', 'actually', 'learn', 'one', 'favorite', 'thing', 'electromagnetic', 'spectrum', 'spectrum', 'radiation', 'yes', 'talking', 'today', 'radiation', 'sound', 'scary', 'important', 'know', 'radiation', 'transmission', 'energy', 'wave', 'particle', 'left', 'spectrum', 'really', 'long', 'wavelength', 'long', 'thousand', 'kilometer', 'move', 'right', 'get', 'shorter', 'shorter', 'even', 'fraction', 'size', 'atomic', 'nucleus', 'wavelength', 'size', 'measured', 'peak', 'peak', 'trough', 'trough', 'basically', 'distance', 'wave', 'shape', 'repeat', 'size', 'literal', 'tattoo', 'arm', 'yes', 'love', 'electromagnetic', 'spectrum', 'wavelength', 'become', 'shorter', 'shorter', 'higher', 'frequency', 'energy', 'frequency', 'describes', 'number', 'wave', 'pas', 'fixed', 'place', 'given', 'amount', 'time', 'usually', 'measured', 'hertz', 'set', 'low', 'frequency', 'fit', 'le', 'wavelength', 'high', 'frequency', 'take', 'gamma', 'ray', 'example', 'power', 'minus', 'meter', 'meter', 'hope', 'got', 'right', 'amount', 'zero', 'generated', 'radioactive', 'atom', 'nuclear', 'explosion', 'gamma', 'ray', 'along', 'x', 'ray', 'higher', 'energy', 'uv', 'radiation', 'damage', 'dna', 'destroy', 'cell', 'also', 'known', 'ionizing', 'yeah', 'scary', 'move', 'back', 'left', 'wavelength', 'get', 'longer', 'le', 'le', 'energy', 'longer', 'ionizing', 'part', 'spectrum', 'wavelength', 'size', 'cell', 'eye', 'evolved', 'see', 'otherwise', 'known', 'visible', 'light', 'every', 'single', 'wavelength', 'eye', 'pick', 'fall', 'within', 'nanometer', 'keep', 'moving', 'left', 'go', 'microwave', 'radio', 'wave', 'also', 'called', 'radio', 'frequency', 'radiation', 'low', 'energy', 'low', 'frequency', 'radiation', 'used', 'technology', 'like', 'radio', 'since', 'late', 'first', 'generation', 'cellular', 'technology', 'one', 'began', 'next', 'chart', 'nasa', 'ever', 'heard', 'famous', 'break', 'generation', 'cellular', 'technology', 'frequency', 'one', 'cellular', 'attack', 'talking', 'used', 'megahertz', 'aka', 'uhf', 'ultra', 'high', 'frequency', 'wave', 'two', 'using', 'around', 'megahertz', 'ultra', 'high', 'frequency', 'wave', 'three', 'allocated', 'frequency', 'megahertz', 'way', 'three', 'gigahertz', 'spectrum', 'known', 'super', 'high', 'frequency', 'four', 'allocated', 'similar', 'frequency', 'three', 'taking', 'advantage', 'higher', 'frequency', 'take', 'u', 'five', 'g', 'allocated', 'megahertz', 'high', 'gigahertz', 'also', 'using', 'super', 'high', 'frequency', 'section', 'first', 'time', 'cellular', 'network', 'technology', 'moved', 'extra', 'high', 'frequency', 'section', 'millimeter', 'wavelength', 'technology', 'leaving', 'radio', 'wave', 'section', 'graph', 'chart', 'saw', 'earlier', 'section', 'microwave', 'course', 'none', 'word', 'help', 'make', 'sound', 'radiation', 'super', 'high', 'frequency', 'extra', 'high', 'frequency', 'microwave', 'thankfully', 'electromagnetic', 'spectrum', 'regulated', 'keep', 'u', 'healthy', 'important', 'regulating', 'body', 'international', 'commission', 'non', 'ionizing', 'radiation', 'protection', 'essentially', 'conglomeration', 'epidemiologist', 'biologist', 'physicist', 'people', 'understand', 'technology', 'deeply', 'take', 'date', 'science', 'make', 'sure', 'understand', 'regulate', 'radiation', 'u', 'also', 'important', 'note', 'regulating', 'body', 'connected', 'one', 'government', 'country', 'commercial', 'corporation', 'lead', 'big', 'question', 'five', 'wave', 'affect', 'u', 'know', 'five', 'frequency', 'ionizing', 'radiation', 'worried', 'impacting', 'body', 'way', 'decade', 'research', 'health', 'effect', 'icnirp', 'found', 'substantiated', 'effect', 'radio', 'frequency', 'exposure', 'heating', 'exposed', 'tissue', 'wavelength', 'cause', 'vibration', 'charged', 'polar', 'molecule', 'inside', 'u', 'creates', 'friction', 'thus', 'heat', 'higher', 'frequency', 'lower', 'penetrative', 'depth', 'body', 'might', 'seem', 'little', 'unnerving', 'think', 'fair', 'concern', 'technically', 'thermal', 'threshold', 'pas', 'cause', 'adverse', 'health', 'effect', 'u', 'regulating', 'body', 'make', 'sure', 'exposure', 'never', 'go', 'threshold', 'fact', 'acute', 'long', 'term', 'effect', 'radio', 'frequency', 'exposure', 'thermal', 'threshold', 'studied', 'extensively', 'without', 'demonstrating', 'adverse', 'health', 'effect', 'research', 'even', 'done', 'headache', 'sleep', 'quality', 'cognitive', 'function', 'etc', 'shown', 'issue', 'one', 'thing', 'found', 'small', 'effect', 'brain', 'activity', 'measured', 'eeg', 'biological', 'implication', 'mean', 'pretty', 'small', 'actually', 'seen', 'negative', 'effect', 'associated', 'brain', 'activity', 'people', 'say', 'five', 'cause', 'cancer', 'study', 'often', 'get', 'quoted', 'one', 'lab', 'rat', 'mouse', 'exposed', 'radio', 'frequency', 'energy', 'used', 'cell', 'phone', 'nine', 'hour', 'day', 'starting', 'birth', 'two', 'year', 'found', 'increased', 'risk', 'type', 'tumor', 'male', 'rat', 'male', 'rat', 'exposed', 'radio', 'frequency', 'radiation', 'actually', 'ended', 'living', 'longer', 'rat', 'female', 'rat', 'mouse', 'experiment', 'increase', 'tumor', 'epidemiological', 'study', 'found', 'small', 'increase', 'brain', 'tumor', 'people', 'heavy', 'user', 'cell', 'phone', 'actually', 'found', 'reporting', 'bias', 'weakness', 'study', 'also', 'important', 'remember', 'study', 'cellphone', 'use', 'actually', 'talking', 'three', 'g', 'four', 'five', 'frequency', 'consensus', 'among', 'scientist', 'five', 'technology', 'cause', 'cancer', 'confusing', 'figure', 'information', 'looking', 'online', 'example', 'even', 'article', 'scientific', 'american', 'would', 'make', 'worried', 'cell', 'phone', 'five', 'could', 'cause', 'cancer', 'even', 'though', 'study', 'corroborated', 'claim', 'opposite', 'study', 'actually', 'say', 'happens', 'lot', 'scientific', 'information', 'get', 'cherry', 'picked', 'mislead', 'people', 'read', 'scientific', 'american', 'week', 'later', 'get', 'prior', 'article', 'information', 'debunked', 'article', 'seemingly', 'scientifically', 'accurate', 'source', 'confusing', 'shade', 'guess', 'scientific', 'american', 'end', 'day', 'come', 'scientist', 'looking', 'large', 'trial', 'large', 'sample', 'size', 'controlling', 'variable', 'one', 'large', 'countrywide', 'study', 'found', 'causal', 'relationship', 'brain', 'tumor', 'cell', 'phone', 'use', 'another', 'really', 'great', 'danish', 'study', 'large', 'study', 'sound', 'like', 'trump', 'right', 'great', 'huge', 'large', 'study', 'laugh', 'also', 'found', 'link', 'okay', 'let', 'talk', 'conspiracy', 'first', 'address', 'elephant', 'room', 'new', 'online', 'theory', 'five', 'cause', 'coronavirus', 'one', 'relatively', 'easy', 'debunk', 'five', 'technology', 'break', 'chemical', 'bond', 'common', 'claim', 'conspiracy', 'theorist', 'use', 'top', 'fact', 'virus', 'visible', 'literally', 'see', 'physically', 'exist', 'study', 'look', 'literal', 'dna', 'ultimately', 'know', 'five', 'cause', 'coronavirus', 'five', 'bad', 'bird', 'study', 'quoted', 'often', 'explain', 'electromagnetic', 'noise', 'five', 'disrupt', 'migration', 'bird', 'researcher', 'actually', 'found', 'longer', 'wavelength', 'like', 'similar', 'radio', 'type', 'wavelength', 'actually', 'affecting', 'migrating', 'bird', 'actually', 'come', 'tried', 'speak', 'openly', 'trying', 'explain', 'research', 'getting', 'cherry', 'picked', 'try', 'say', 'something', 'five', 'never', 'said', 'new', 'british', 'pound', 'note', 'show', 'coronavirus', 'five', 'g', 'conspiracy', 'theory', 'popping', 'stating', 'pound', 'note', 'five', 'tower', 'giving', 'radiation', 'coronavirus', 'actually', 'image', 'margate', 'lighthouse', 'behind', 'new', 'turner', 'contemporary', 'art', 'gallery', 'purple', 'foil', 'patch', 'based', 'staircase', 'tate', 'modern', 'science', 'territory', 'though', 'let', 'get', 'back', 'track', 'interested', 'conspiracy', 'theory', 'science', 'behind', 'work', 'well', 'actually', 'video', 'made', 'link', 'description', 'recap', 'one', 'five', 'technology', 'us', 'wavelength', 'within', 'super', 'high', 'extra', 'high', 'frequency', 'spectrum', 'two', 'fall', 'category', 'non', 'ionizing', 'radiation', 'meaning', 'damage', 'dna', 'destroy', 'cell', 'three', 'five', 'capacity', 'heat', 'exposed', 'tissue', 'due', 'regulation', 'remain', 'threshold', 'known', 'cause', 'damage', 'four', 'current', 'scientific', 'consensus', 'five', 'show', 'adverse', 'impact', 'health', 'like', 'headache', 'sleep', 'cognitive', 'function', 'cancer', 'five', 'five', 'nothing', 'coronavirus', 'newly', 'published', 'guideline', 'regulating', 'five', 'g', 'gon', 'na', 'link', 'description', 'read', 'mean', 'skeptical', 'technological', 'advance', 'mean', 'honestly', 'research', 'made', 'video', 'skeptical', 'think', 'important', 'continue', 'regulate', 'understand', 'technology', 'gon', 'na', 'used', 'around', 'u', 'work', 'end', 'day', 'also', 'need', 'listen', 'science', 'listen', 'scientific', 'consensus', 'order', 'guide', 'knowledge', 'talked', 'five', 'conspiracy', 'theory', 'newest', 'podcast', 'harvard', 'professor', 'study', 'disinformation', 'campaign', 'conspiracy', 'definitely', 'click', 'check', 'fascinating', 'really', 'good', 'way', 'understand', 'conspiracy', 'theory', 'spreading', 'subscribed', 'make', 'sure', 'done', 'right', 'else', 'use', 'subscribe', 'email', 'thread', 'yeah', 'got', 'mailing', 'list', 'yeah', 'year', 'old', 'call', 'email', 'thread', 'laugh', 'otherwise', 'thank', 'watching', 'like', 'subscribe', 'thing', 'like', 'science', 'video', 'see', 'next', 'time', 'mumble', 'okay', 'thanks', 'laugh'], tags=['transcript_5'])]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_X[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 313/313 [00:00<00:00, 1009859.35it/s]\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "\n",
    "model_d2v = gensim.models.Doc2Vec(dm=1, # dm = 1 for â€˜distributed memoryâ€™ model\n",
    "                                  dm_mean=1, # dm_mean = 1 for using mean of the context word vectors\n",
    "                                  vector_size=200, # no. of desired features\n",
    "                                  window=5, # width of the context window                                  \n",
    "                                  negative=7, # if > 0 then negative sampling will be used\n",
    "                                  min_count=5, # Ignores all words with total frequency lower than 5.                                  \n",
    "                                  workers=32, # no. of cores                                  \n",
    "                                  alpha=0.1, # learning rate                                  \n",
    "                                  seed = 23, # for reproducibility\n",
    "                                 ) \n",
    "\n",
    "model_d2v.build_vocab([i for i in tqdm(labeled_X)])\n",
    "\n",
    "model_d2v.train(labeled_X, total_examples= len(train_sentences), epochs=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing doc2vec Feature Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(313, 200)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docvec_arrays = np.zeros((len(train_sentences), 200)) \n",
    "for i in range(len(train_sentences)):\n",
    "    docvec_arrays[i,:] = model_d2v.docvecs[i].reshape((1,200))    \n",
    "\n",
    "docvec_df = pd.DataFrame(docvec_arrays) \n",
    "docvec_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn import datasets\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "forest = RandomForestClassifier(n_estimators=500,\n",
    "                              random_state=1,\n",
    "                             max_features=None,max_depth=None,min_samples_split=2)\n",
    "cv = cross_validate(forest, docvec_df, y, cv=10,scoring = ['precision','recall'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7653917216231381\n",
      "0.9673160173160174\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(cv['test_precision'].mean())\n",
    "print(cv['test_recall'].mean())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "result = pd.DataFrame(pd.np.column_stack([visual, X_oh]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.concat([visual, textual], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of            0            1            2           3            4      \\\n",
       "0     298.035544   256.526430   317.666638  176.226486   291.471955   \n",
       "1      14.562086    13.206167    14.473241   22.249816     3.087459   \n",
       "2    1397.200532  1812.288126  1125.290200  952.795220  3386.595470   \n",
       "3     800.175857   979.432379   765.202229  533.030459   899.264225   \n",
       "4     611.670255   710.533599   704.285521  565.782339   267.640542   \n",
       "..           ...          ...          ...         ...          ...   \n",
       "308   147.788425    83.104502   343.138525  287.133037   738.014925   \n",
       "309   499.048934   671.771055   464.885271  768.802809   362.948260   \n",
       "310    12.184924     9.988667     8.442325    7.628704     8.160141   \n",
       "311     3.100336    12.856796    13.246367    0.652040    23.776415   \n",
       "312    26.059390    20.160538    26.205856   37.262637     9.450165   \n",
       "\n",
       "          5            6           7            8           9      ...  10010  \\\n",
       "0    318.839186   249.684164   58.312728   273.094250  131.323126  ...    0.0   \n",
       "1     14.468497    13.461712    2.128646     6.360655    0.903765  ...    0.0   \n",
       "2    942.447595  1478.249667  160.366149  1102.429909  528.665700  ...    0.0   \n",
       "3    665.884765   850.382767  385.940453  2316.228370  115.950038  ...    0.0   \n",
       "4    616.471287   661.184079  185.405393    48.207604  226.281947  ...    0.0   \n",
       "..          ...          ...         ...          ...         ...  ...    ...   \n",
       "308  211.022546    73.414553  233.283992   762.744039  122.025988  ...    0.0   \n",
       "309  492.587090   554.760968   93.525503   564.382108   60.941841  ...    0.0   \n",
       "310   12.292979     9.858782    1.924338    13.182123    6.304640  ...    0.0   \n",
       "311    2.342890     9.398054    2.273838     0.001471    6.499906  ...    0.0   \n",
       "312   20.737421    21.035988   16.549036     6.226976    4.321690  ...    0.0   \n",
       "\n",
       "     10011  10012  10013  10014  10015  10016  10017  10018  10019  \n",
       "0      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "1      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "2      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "3      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "4      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "..     ...    ...    ...    ...    ...    ...    ...    ...    ...  \n",
       "308    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "309    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0  \n",
       "310    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "311    0.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "312    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "\n",
       "[313 rows x 10020 columns]>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate K-fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# inputs data samples: 313\n",
      "# targets data samples: 313\n",
      "Shape of train set: (281, 10020)\n",
      "Shape of y: (281, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Shape of validation set: (32, 10020)\n",
      "{'loss': [14.612687110900879, 112.26792907714844, 11.04271411895752, 22.205244064331055, 6.545848369598389, 10.392186164855957, 12.305441856384277, 3.1799399852752686, 7.627873420715332, 9.307175636291504, 2.0185112953186035, 5.807286739349365, 8.04775619506836, 1.7864655256271362, 4.3010735511779785, 7.815014362335205, 1.342038631439209, 3.948058843612671, 6.801834583282471, 1.2309454679489136, 3.518735885620117, 6.582371711730957, 1.053055763244629, 3.535033702850342, 5.768925666809082, 0.5020555853843689, 0.9378923773765564, 5.056182861328125, 0.7957579493522644, 2.749514102935791, 2.596181869506836, 7.4888105392456055, 1.158350944519043, 3.417651414871216, 5.8859148025512695, 0.46127617359161377, 1.3266457319259644, 4.875954627990723, 0.7336472868919373, 0.6965383887290955, 3.714428424835205, 0.777716875076294, 1.7395023107528687, 3.419144630432129, 7.238190650939941, 1.4075311422348022, 2.541917324066162, 4.802671909332275, 0.5301170349121094, 1.877925992012024], 'accuracy': [0.6832740306854248, 0.3131672739982605, 0.3416370153427124, 0.6868327260017395, 0.7010676264762878, 0.33096083998680115, 0.6868327260017395, 0.7437722682952881, 0.4519572854042053, 0.690391480922699, 0.7580071091651917, 0.5409252643585205, 0.7117437720298767, 0.7935943007469177, 0.6120996475219727, 0.7330960631370544, 0.8149465918540955, 0.5943060517311096, 0.7330960631370544, 0.8256227970123291, 0.6441280841827393, 0.7437722682952881, 0.8327401876449585, 0.6476868391036987, 0.7473309636116028, 0.8576512336730957, 0.8042704463005066, 0.7686832547187805, 0.790035605430603, 0.7935943007469177, 0.6441280841827393, 0.7473309636116028, 0.8327401876449585, 0.608540952205658, 0.754448413848877, 0.8754448294639587, 0.77224200963974, 0.7793594598770142, 0.8612099885940552, 0.836298942565918, 0.8007117509841919, 0.8256227970123291, 0.8256227970123291, 0.6192170977592468, 0.7508896589279175, 0.8078292012214661, 0.6975088715553284, 0.7864768505096436, 0.8825622797012329, 0.7188612222671509], 'precision_32': [0.6832740306854248, 0.3131672739982605, 0.3416370153427124, 0.6868327260017395, 0.7010676264762878, 0.33096083998680115, 0.6868327260017395, 0.7437722682952881, 0.4519572854042053, 0.690391480922699, 0.7580071091651917, 0.5409252643585205, 0.7117437720298767, 0.7935943007469177, 0.6120996475219727, 0.7330960631370544, 0.8149465918540955, 0.5943060517311096, 0.7330960631370544, 0.8256227970123291, 0.6441280841827393, 0.7437722682952881, 0.8327401876449585, 0.6476868391036987, 0.7473309636116028, 0.8576512336730957, 0.8042704463005066, 0.7686832547187805, 0.790035605430603, 0.7935943007469177, 0.6441280841827393, 0.7473309636116028, 0.8327401876449585, 0.608540952205658, 0.754448413848877, 0.8754448294639587, 0.77224200963974, 0.7793594598770142, 0.8612099885940552, 0.836298942565918, 0.8007117509841919, 0.8256227970123291, 0.8256227970123291, 0.6192170977592468, 0.7508896589279175, 0.8078292012214661, 0.6975088715553284, 0.7864768505096436, 0.8825622797012329, 0.7188612222671509], 'recall_32': [0.6832740306854248, 0.3131672739982605, 0.3416370153427124, 0.6868327260017395, 0.7010676264762878, 0.33096083998680115, 0.6868327260017395, 0.7437722682952881, 0.4519572854042053, 0.690391480922699, 0.7580071091651917, 0.5409252643585205, 0.7117437720298767, 0.7935943007469177, 0.6120996475219727, 0.7330960631370544, 0.8149465918540955, 0.5943060517311096, 0.7330960631370544, 0.8256227970123291, 0.6441280841827393, 0.7437722682952881, 0.8327401876449585, 0.6476868391036987, 0.7473309636116028, 0.8576512336730957, 0.8042704463005066, 0.7686832547187805, 0.790035605430603, 0.7935943007469177, 0.6441280841827393, 0.7473309636116028, 0.8327401876449585, 0.608540952205658, 0.754448413848877, 0.8754448294639587, 0.77224200963974, 0.7793594598770142, 0.8612099885940552, 0.836298942565918, 0.8007117509841919, 0.8256227970123291, 0.8256227970123291, 0.6192170977592468, 0.7508896589279175, 0.8078292012214661, 0.6975088715553284, 0.7864768505096436, 0.8825622797012329, 0.7188612222671509]}\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f889cb33050> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 1 - Precison: 0.679788961038961 - Recall: 0.8636363636363636%\n",
      "Shape of train set: (281, 10020)\n",
      "Shape of y: (281, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "Shape of validation set: (32, 10020)\n",
      "{'loss': [12.85079288482666, 60.1048698425293, 7.313065528869629, 55.94164276123047, 13.180625915527344, 11.51456069946289, 17.902616500854492, 3.428316116333008, 12.710392951965332, 9.789180755615234, 1.2268717288970947, 1.2368799448013306, 4.666477680206299, 8.888895988464355, 1.1419105529785156, 4.443930625915527, 8.04837417602539, 1.2358250617980957, 3.1345512866973877, 5.731544494628906, 0.8254855871200562, 1.6872128248214722, 4.512801647186279, 0.6391445994377136, 1.694576621055603, 3.7633607387542725, 6.037046909332275, 1.1565278768539429, 0.6297668814659119, 0.9995376467704773, 7.465222358703613, 6.061345100402832, 1.3555586338043213, 4.015980243682861, 0.46849629282951355, 0.8147639036178589, 3.8903326988220215, 5.144746780395508, 1.567095398902893, 1.2627222537994385, 3.2979471683502197, 3.7208335399627686, 3.920991897583008, 0.6750710010528564, 0.6177618503570557, 0.9253926873207092, 2.450495719909668, 5.803940296173096, 0.8604762554168701, 0.4656669497489929], 'accuracy': [0.46975088119506836, 0.6975088715553284, 0.5907473564147949, 0.30604982376098633, 0.6975088715553284, 0.47330960631370544, 0.6975088715553284, 0.7651245594024658, 0.38790035247802734, 0.6975088715553284, 0.7473309636116028, 0.790035605430603, 0.5800711512565613, 0.7437722682952881, 0.7864768505096436, 0.5978647470474243, 0.7508896589279175, 0.8007117509841919, 0.6761565804481506, 0.7651245594024658, 0.8398576378822327, 0.6939501762390137, 0.7686832547187805, 0.836298942565918, 0.7935943007469177, 0.608540952205658, 0.7580071091651917, 0.77224200963974, 0.8256227970123291, 0.8291814923286438, 0.5231316685676575, 0.7473309636116028, 0.754448413848877, 0.7793594598770142, 0.8790035843849182, 0.854092538356781, 0.6192170977592468, 0.7793594598770142, 0.8220640420913696, 0.7437722682952881, 0.7758007049560547, 0.6868327260017395, 0.7971529960632324, 0.754448413848877, 0.8647686839103699, 0.8505337834358215, 0.6583629846572876, 0.7615658640861511, 0.8398576378822327, 0.8647686839103699], 'precision_33': [0.46975088119506836, 0.6975088715553284, 0.5907473564147949, 0.30604982376098633, 0.6975088715553284, 0.47330960631370544, 0.6975088715553284, 0.7651245594024658, 0.38790035247802734, 0.6975088715553284, 0.7473309636116028, 0.790035605430603, 0.5800711512565613, 0.7437722682952881, 0.7864768505096436, 0.5978647470474243, 0.7508896589279175, 0.8007117509841919, 0.6761565804481506, 0.7651245594024658, 0.8398576378822327, 0.6939501762390137, 0.7686832547187805, 0.836298942565918, 0.7935943007469177, 0.608540952205658, 0.7580071091651917, 0.77224200963974, 0.8256227970123291, 0.8291814923286438, 0.5231316685676575, 0.7473309636116028, 0.754448413848877, 0.7793594598770142, 0.8790035843849182, 0.854092538356781, 0.6192170977592468, 0.7793594598770142, 0.8220640420913696, 0.7437722682952881, 0.7758007049560547, 0.6868327260017395, 0.7971529960632324, 0.754448413848877, 0.8647686839103699, 0.8505337834358215, 0.6583629846572876, 0.7615658640861511, 0.8398576378822327, 0.8647686839103699], 'recall_33': [0.46975088119506836, 0.6975088715553284, 0.5907473564147949, 0.30604982376098633, 0.6975088715553284, 0.47330960631370544, 0.6975088715553284, 0.7651245594024658, 0.38790035247802734, 0.6975088715553284, 0.7473309636116028, 0.790035605430603, 0.5800711512565613, 0.7437722682952881, 0.7864768505096436, 0.5978647470474243, 0.7508896589279175, 0.8007117509841919, 0.6761565804481506, 0.7651245594024658, 0.8398576378822327, 0.6939501762390137, 0.7686832547187805, 0.836298942565918, 0.7935943007469177, 0.608540952205658, 0.7580071091651917, 0.77224200963974, 0.8256227970123291, 0.8291814923286438, 0.5231316685676575, 0.7473309636116028, 0.754448413848877, 0.7793594598770142, 0.8790035843849182, 0.854092538356781, 0.6192170977592468, 0.7793594598770142, 0.8220640420913696, 0.7437722682952881, 0.7758007049560547, 0.6868327260017395, 0.7971529960632324, 0.754448413848877, 0.8647686839103699, 0.8505337834358215, 0.6583629846572876, 0.7615658640861511, 0.8398576378822327, 0.8647686839103699]}\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f88acf294d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Fold 2 - Precison: 0.5996710526315789 - Recall: 0.9473684210526315%\n",
      "Shape of train set: (281, 10020)\n",
      "Shape of y: (281, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "Shape of validation set: (32, 10020)\n",
      "{'loss': [38.87637710571289, 39.095333099365234, 10.807106971740723, 13.52180290222168, 17.20587730407715, 5.658076286315918, 6.6843671798706055, 12.40434741973877, 4.046075820922852, 5.233001708984375, 11.479544639587402, 3.801405429840088, 4.777150630950928, 9.12358570098877, 2.576449394226074, 4.159852981567383, 9.514265060424805, 2.8420162200927734, 3.612731456756592, 8.081618309020996, 1.7938988208770752, 5.306344985961914, 7.231159687042236, 1.7717946767807007, 3.519242286682129, 6.300229549407959, 1.2859834432601929, 2.8618297576904297, 6.285096168518066, 1.1270300149917603, 3.32780122756958, 5.701518535614014, 1.0145001411437988, 1.873701810836792, 5.361833572387695, 0.6023902893066406, 1.216110110282898, 4.6845879554748535, 0.42566657066345215, 0.41904494166374207, 1.7826629877090454, 3.2029948234558105, 6.397936820983887, 1.1816610097885132, 2.635164499282837, 4.900461196899414, 1.0060524940490723, 0.6486642956733704, 1.9610114097595215, 2.044621706008911], 'accuracy': [0.3167259693145752, 0.6832740306854248, 0.6797152757644653, 0.35587188601493835, 0.6832740306854248, 0.7402135133743286, 0.4911032021045685, 0.6975088715553284, 0.7188612222671509, 0.4875444769859314, 0.690391480922699, 0.7580071091651917, 0.5693950057029724, 0.7473309636116028, 0.790035605430603, 0.5480427145957947, 0.7295373678207397, 0.790035605430603, 0.5231316685676575, 0.7188612222671509, 0.7971529960632324, 0.5871886014938354, 0.7615658640861511, 0.8078292012214661, 0.6049821972846985, 0.7615658640861511, 0.836298942565918, 0.6334519386291504, 0.754448413848877, 0.8469750881195068, 0.6298932433128357, 0.7793594598770142, 0.8398576378822327, 0.7153024673461914, 0.7686832547187805, 0.8932384252548218, 0.77224200963974, 0.7935943007469177, 0.8896797299385071, 0.8825622797012329, 0.8327401876449585, 0.5943060517311096, 0.7437722682952881, 0.790035605430603, 0.6298932433128357, 0.790035605430603, 0.8683273792266846, 0.836298942565918, 0.8220640420913696, 0.7330960631370544], 'precision_34': [0.3167259693145752, 0.6832740306854248, 0.6797152757644653, 0.35587188601493835, 0.6832740306854248, 0.7402135133743286, 0.4911032021045685, 0.6975088715553284, 0.7188612222671509, 0.4875444769859314, 0.690391480922699, 0.7580071091651917, 0.5693950057029724, 0.7473309636116028, 0.790035605430603, 0.5480427145957947, 0.7295373678207397, 0.790035605430603, 0.5231316685676575, 0.7188612222671509, 0.7971529960632324, 0.5871886014938354, 0.7615658640861511, 0.8078292012214661, 0.6049821972846985, 0.7615658640861511, 0.836298942565918, 0.6334519386291504, 0.754448413848877, 0.8469750881195068, 0.6298932433128357, 0.7793594598770142, 0.8398576378822327, 0.7153024673461914, 0.7686832547187805, 0.8932384252548218, 0.77224200963974, 0.7935943007469177, 0.8896797299385071, 0.8825622797012329, 0.8327401876449585, 0.5943060517311096, 0.7437722682952881, 0.790035605430603, 0.6298932433128357, 0.790035605430603, 0.8683273792266846, 0.836298942565918, 0.8220640420913696, 0.7330960631370544], 'recall_34': [0.3167259693145752, 0.6832740306854248, 0.6797152757644653, 0.35587188601493835, 0.6832740306854248, 0.7402135133743286, 0.4911032021045685, 0.6975088715553284, 0.7188612222671509, 0.4875444769859314, 0.690391480922699, 0.7580071091651917, 0.5693950057029724, 0.7473309636116028, 0.790035605430603, 0.5480427145957947, 0.7295373678207397, 0.790035605430603, 0.5231316685676575, 0.7188612222671509, 0.7971529960632324, 0.5871886014938354, 0.7615658640861511, 0.8078292012214661, 0.6049821972846985, 0.7615658640861511, 0.836298942565918, 0.6334519386291504, 0.754448413848877, 0.8469750881195068, 0.6298932433128357, 0.7793594598770142, 0.8398576378822327, 0.7153024673461914, 0.7686832547187805, 0.8932384252548218, 0.77224200963974, 0.7935943007469177, 0.8896797299385071, 0.8825622797012329, 0.8327401876449585, 0.5943060517311096, 0.7437722682952881, 0.790035605430603, 0.6298932433128357, 0.790035605430603, 0.8683273792266846, 0.836298942565918, 0.8220640420913696, 0.7330960631370544]}\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f88b2c1f680> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 3 - Precison: 0.71875 - Recall: 1.0%\n",
      "Shape of train set: (282, 10020)\n",
      "Shape of y: (282, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "Shape of validation set: (31, 10020)\n",
      "{'loss': [4.864107131958008, 64.80400085449219, 5.588998794555664, 21.11333656311035, 4.30918025970459, 15.554287910461426, 2.80183482170105, 16.497360229492188, 6.822903156280518, 1.2639237642288208, 3.0843658447265625, 2.9913787841796875, 6.379672050476074, 1.5726484060287476, 2.670891523361206, 4.238208293914795, 0.9487523436546326, 1.8832755088806152, 4.122702121734619, 0.8241010904312134, 2.5437161922454834, 3.9734344482421875, 0.8482087850570679, 2.0850205421447754, 3.3606295585632324, 0.552568256855011, 1.5635906457901, 3.5417985916137695, 0.6165111064910889, 1.8884121179580688, 2.986436605453491, 1.1525813341140747, 2.8766961097717285, 0.8905888795852661, 2.5062577724456787, 0.7667016386985779, 2.4468140602111816, 0.23794980347156525, 0.2765026092529297, 1.1502394676208496, 3.1427478790283203, 0.4758231043815613, 0.7497978806495667, 2.1529078483581543, 1.1538265943527222, 2.186189651489258, 1.3009912967681885, 3.6401891708374023, 0.6474858522415161, 1.5081056356430054], 'accuracy': [0.6382978558540344, 0.3510638177394867, 0.588652491569519, 0.6808510422706604, 0.44680851697921753, 0.6879432797431946, 0.741134762763977, 0.39007091522216797, 0.6879432797431946, 0.7198581695556641, 0.758865237236023, 0.5709219574928284, 0.7198581695556641, 0.783687949180603, 0.6134752035140991, 0.76241135597229, 0.7907801270484924, 0.6773049831390381, 0.7553191781044006, 0.7907801270484924, 0.6276595592498779, 0.7553191781044006, 0.8156028389930725, 0.673758864402771, 0.7730496525764465, 0.8439716100692749, 0.7056737542152405, 0.7730496525764465, 0.8439716100692749, 0.7021276354789734, 0.7765957713127136, 0.7482269406318665, 0.7695035338401794, 0.76241135597229, 0.7730496525764465, 0.8014184236526489, 0.8014184236526489, 0.9007092118263245, 0.914893627166748, 0.741134762763977, 0.7943262457847595, 0.8617021441459656, 0.826241135597229, 0.8120567202568054, 0.76241135597229, 0.7907801270484924, 0.6985815763473511, 0.783687949180603, 0.868794322013855, 0.7695035338401794], 'precision_35': [0.6382978558540344, 0.3510638177394867, 0.588652491569519, 0.6808510422706604, 0.44680851697921753, 0.6879432797431946, 0.741134762763977, 0.39007091522216797, 0.6879432797431946, 0.7198581695556641, 0.758865237236023, 0.5709219574928284, 0.7198581695556641, 0.783687949180603, 0.6134752035140991, 0.76241135597229, 0.7907801270484924, 0.6773049831390381, 0.7553191781044006, 0.7907801270484924, 0.6276595592498779, 0.7553191781044006, 0.8156028389930725, 0.673758864402771, 0.7730496525764465, 0.8439716100692749, 0.7056737542152405, 0.7730496525764465, 0.8439716100692749, 0.7021276354789734, 0.7765957713127136, 0.7482269406318665, 0.7695035338401794, 0.76241135597229, 0.7730496525764465, 0.8014184236526489, 0.8014184236526489, 0.9007092118263245, 0.914893627166748, 0.741134762763977, 0.7943262457847595, 0.8617021441459656, 0.826241135597229, 0.8120567202568054, 0.76241135597229, 0.7907801270484924, 0.6985815763473511, 0.783687949180603, 0.868794322013855, 0.7695035338401794], 'recall_35': [0.6382978558540344, 0.3510638177394867, 0.588652491569519, 0.6808510422706604, 0.44680851697921753, 0.6879432797431946, 0.741134762763977, 0.39007091522216797, 0.6879432797431946, 0.7198581695556641, 0.758865237236023, 0.5709219574928284, 0.7198581695556641, 0.783687949180603, 0.6134752035140991, 0.76241135597229, 0.7907801270484924, 0.6773049831390381, 0.7553191781044006, 0.7907801270484924, 0.6276595592498779, 0.7553191781044006, 0.8156028389930725, 0.673758864402771, 0.7730496525764465, 0.8439716100692749, 0.7056737542152405, 0.7730496525764465, 0.8439716100692749, 0.7021276354789734, 0.7765957713127136, 0.7482269406318665, 0.7695035338401794, 0.76241135597229, 0.7730496525764465, 0.8014184236526489, 0.8014184236526489, 0.9007092118263245, 0.914893627166748, 0.741134762763977, 0.7943262457847595, 0.8617021441459656, 0.826241135597229, 0.8120567202568054, 0.76241135597229, 0.7907801270484924, 0.6985815763473511, 0.783687949180603, 0.868794322013855, 0.7695035338401794]}\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f88c6f6f9e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Fold 4 - Precison: 0.7337073398784478 - Recall: 0.9565217391304348%\n",
      "Shape of train set: (282, 10020)\n",
      "Shape of y: (282, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "Shape of validation set: (31, 10020)\n",
      "{'loss': [5.301913738250732, 29.386518478393555, 66.49966430664062, 20.949359893798828, 6.635838985443115, 17.312469482421875, 3.5040087699890137, 15.619009017944336, 13.456180572509766, 3.8122315406799316, 8.13048267364502, 11.187124252319336, 3.615729570388794, 4.999382495880127, 9.755850791931152, 3.184000015258789, 3.880000591278076, 8.798354148864746, 2.706212043762207, 3.1887478828430176, 7.9768524169921875, 2.2919461727142334, 3.0652925968170166, 7.2681756019592285, 1.7199349403381348, 3.5702314376831055, 6.637542724609375, 1.7971735000610352, 3.5120561122894287, 6.425045490264893, 1.3273895978927612, 3.0316708087921143, 4.931371212005615, 0.5698677897453308, 2.201477527618408, 4.81189489364624, 0.4105856418609619, 2.204218864440918, 4.763605117797852, 0.27724573016166687, 1.3179500102996826, 3.684070348739624, 0.34832286834716797, 0.9696892499923706, 3.0400211811065674, 5.266724109649658, 0.48471230268478394, 1.9997409582138062, 4.6225810050964355, 0.26797059178352356], 'accuracy': [0.6560283899307251, 0.5496453642845154, 0.3085106313228607, 0.695035457611084, 0.4964539110660553, 0.695035457611084, 0.7446808218955994, 0.40780141949653625, 0.695035457611084, 0.7695035338401794, 0.4893617033958435, 0.73758864402771, 0.7695035338401794, 0.5567376017570496, 0.7517730593681335, 0.7943262457847595, 0.5957446694374084, 0.7517730593681335, 0.8191489577293396, 0.6241135001182556, 0.76241135597229, 0.8297872543334961, 0.6241135001182556, 0.758865237236023, 0.8404255509376526, 0.6418439745903015, 0.7695035338401794, 0.8404255509376526, 0.6347517967224121, 0.7659574747085571, 0.8439716100692749, 0.673758864402771, 0.7872340679168701, 0.890070915222168, 0.7021276354789734, 0.7907801270484924, 0.9042553305625916, 0.7269503474235535, 0.8014184236526489, 0.9184397459030151, 0.7872340679168701, 0.804964542388916, 0.9042553305625916, 0.8581560254096985, 0.6595744490623474, 0.7872340679168701, 0.9078013896942139, 0.7021276354789734, 0.7907801270484924, 0.9290780425071716], 'precision_36': [0.6560283899307251, 0.5496453642845154, 0.3085106313228607, 0.695035457611084, 0.4964539110660553, 0.695035457611084, 0.7446808218955994, 0.40780141949653625, 0.695035457611084, 0.7695035338401794, 0.4893617033958435, 0.73758864402771, 0.7695035338401794, 0.5567376017570496, 0.7517730593681335, 0.7943262457847595, 0.5957446694374084, 0.7517730593681335, 0.8191489577293396, 0.6241135001182556, 0.76241135597229, 0.8297872543334961, 0.6241135001182556, 0.758865237236023, 0.8404255509376526, 0.6418439745903015, 0.7695035338401794, 0.8404255509376526, 0.6347517967224121, 0.7659574747085571, 0.8439716100692749, 0.673758864402771, 0.7872340679168701, 0.890070915222168, 0.7021276354789734, 0.7907801270484924, 0.9042553305625916, 0.7269503474235535, 0.8014184236526489, 0.9184397459030151, 0.7872340679168701, 0.804964542388916, 0.9042553305625916, 0.8581560254096985, 0.6595744490623474, 0.7872340679168701, 0.9078013896942139, 0.7021276354789734, 0.7907801270484924, 0.9290780425071716], 'recall_36': [0.6560283899307251, 0.5496453642845154, 0.3085106313228607, 0.695035457611084, 0.4964539110660553, 0.695035457611084, 0.7446808218955994, 0.40780141949653625, 0.695035457611084, 0.7695035338401794, 0.4893617033958435, 0.73758864402771, 0.7695035338401794, 0.5567376017570496, 0.7517730593681335, 0.7943262457847595, 0.5957446694374084, 0.7517730593681335, 0.8191489577293396, 0.6241135001182556, 0.76241135597229, 0.8297872543334961, 0.6241135001182556, 0.758865237236023, 0.8404255509376526, 0.6418439745903015, 0.7695035338401794, 0.8404255509376526, 0.6347517967224121, 0.7659574747085571, 0.8439716100692749, 0.673758864402771, 0.7872340679168701, 0.890070915222168, 0.7021276354789734, 0.7907801270484924, 0.9042553305625916, 0.7269503474235535, 0.8014184236526489, 0.9184397459030151, 0.7872340679168701, 0.804964542388916, 0.9042553305625916, 0.8581560254096985, 0.6595744490623474, 0.7872340679168701, 0.9078013896942139, 0.7021276354789734, 0.7907801270484924, 0.9290780425071716]}\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f88b2cabef0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 5 - Precison: 0.6171072843398819 - Recall: 0.6842105263157895%\n",
      "Shape of train set: (282, 10020)\n",
      "Shape of y: (282, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 6 ...\n",
      "Shape of validation set: (31, 10020)\n",
      "{'loss': [9.177539825439453, 90.14254760742188, 4.313948154449463, 11.573719024658203, 3.3259193897247314, 9.762743949890137, 3.5576813220977783, 3.6904168128967285, 6.186521053314209, 2.6690146923065186, 0.7528555393218994, 1.243870496749878, 3.4823062419891357, 4.503049373626709, 1.499423623085022, 1.3889906406402588, 3.0899147987365723, 0.812991201877594, 1.5587522983551025, 3.3498356342315674, 0.9152586460113525, 1.2607368230819702, 2.7474141120910645, 0.5761404633522034, 1.8234446048736572, 3.4911577701568604, 0.7777765393257141, 1.4505672454833984, 3.2059476375579834, 0.9764569997787476, 0.9884828329086304, 2.639887809753418, 0.5422102212905884, 0.892590343952179, 2.3258988857269287, 0.7742834091186523, 1.0209157466888428, 3.1957833766937256, 0.6793197989463806, 1.1673173904418945, 2.6341376304626465, 0.6024134755134583, 1.0804126262664795, 2.3213040828704834, 0.44571036100387573, 0.762153685092926, 1.820683240890503, 0.25392988324165344, 0.2971261143684387, 0.9578549265861511], 'accuracy': [0.6276595592498779, 0.3617021143436432, 0.5390070676803589, 0.6843971610069275, 0.41134750843048096, 0.6843971610069275, 0.7517730593681335, 0.5390070676803589, 0.741134762763977, 0.7517730593681335, 0.73758864402771, 0.7695035338401794, 0.5106382966041565, 0.7198581695556641, 0.783687949180603, 0.6453900933265686, 0.7695035338401794, 0.8333333134651184, 0.6489361524581909, 0.7695035338401794, 0.8226950168609619, 0.6843971610069275, 0.7801418304443359, 0.8368794322013855, 0.609929084777832, 0.76241135597229, 0.8333333134651184, 0.6560283899307251, 0.783687949180603, 0.8191489577293396, 0.6808510422706604, 0.7695035338401794, 0.8368794322013855, 0.7659574747085571, 0.7943262457847595, 0.8333333134651184, 0.7234042286872864, 0.783687949180603, 0.8404255509376526, 0.7092198729515076, 0.8085106611251831, 0.8510638475418091, 0.6879432797431946, 0.804964542388916, 0.8758864998817444, 0.7765957713127136, 0.8191489577293396, 0.9007092118263245, 0.8723404407501221, 0.8368794322013855], 'precision_37': [0.6276595592498779, 0.3617021143436432, 0.5390070676803589, 0.6843971610069275, 0.41134750843048096, 0.6843971610069275, 0.7517730593681335, 0.5390070676803589, 0.741134762763977, 0.7517730593681335, 0.73758864402771, 0.7695035338401794, 0.5106382966041565, 0.7198581695556641, 0.783687949180603, 0.6453900933265686, 0.7695035338401794, 0.8333333134651184, 0.6489361524581909, 0.7695035338401794, 0.8226950168609619, 0.6843971610069275, 0.7801418304443359, 0.8368794322013855, 0.609929084777832, 0.76241135597229, 0.8333333134651184, 0.6560283899307251, 0.783687949180603, 0.8191489577293396, 0.6808510422706604, 0.7695035338401794, 0.8368794322013855, 0.7659574747085571, 0.7943262457847595, 0.8333333134651184, 0.7234042286872864, 0.783687949180603, 0.8404255509376526, 0.7092198729515076, 0.8085106611251831, 0.8510638475418091, 0.6879432797431946, 0.804964542388916, 0.8758864998817444, 0.7765957713127136, 0.8191489577293396, 0.9007092118263245, 0.8723404407501221, 0.8368794322013855], 'recall_37': [0.6276595592498779, 0.3617021143436432, 0.5390070676803589, 0.6843971610069275, 0.41134750843048096, 0.6843971610069275, 0.7517730593681335, 0.5390070676803589, 0.741134762763977, 0.7517730593681335, 0.73758864402771, 0.7695035338401794, 0.5106382966041565, 0.7198581695556641, 0.783687949180603, 0.6453900933265686, 0.7695035338401794, 0.8333333134651184, 0.6489361524581909, 0.7695035338401794, 0.8226950168609619, 0.6843971610069275, 0.7801418304443359, 0.8368794322013855, 0.609929084777832, 0.76241135597229, 0.8333333134651184, 0.6560283899307251, 0.783687949180603, 0.8191489577293396, 0.6808510422706604, 0.7695035338401794, 0.8368794322013855, 0.7659574747085571, 0.7943262457847595, 0.8333333134651184, 0.7234042286872864, 0.783687949180603, 0.8404255509376526, 0.7092198729515076, 0.8085106611251831, 0.8510638475418091, 0.6879432797431946, 0.804964542388916, 0.8758864998817444, 0.7765957713127136, 0.8191489577293396, 0.9007092118263245, 0.8723404407501221, 0.8368794322013855]}\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f88acb2c440> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Fold 6 - Precison: 0.7875366568914957 - Recall: 0.4090909090909091%\n",
      "Shape of train set: (282, 10020)\n",
      "Shape of y: (282, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 7 ...\n",
      "Shape of validation set: (31, 10020)\n",
      "{'loss': [22.24107551574707, 131.91973876953125, 4.652421474456787, 11.526435852050781, 27.715890884399414, 6.828553199768066, 18.615102767944336, 17.28653335571289, 5.859803199768066, 5.395294189453125, 11.655725479125977, 3.8463871479034424, 4.993592739105225, 10.190401077270508, 3.6003053188323975, 3.1780638694763184, 8.579179763793945, 2.635603666305542, 3.4198601245880127, 7.922551155090332, 2.3801212310791016, 2.834646463394165, 6.857501983642578, 1.7628735303878784, 3.338780164718628, 6.916040420532227, 1.798554539680481, 2.640835762023926, 6.231626033782959, 1.434790015220642, 2.6826720237731934, 5.972437858581543, 1.4894193410873413, 2.3481814861297607, 5.104970455169678, 1.0159809589385986, 2.499634265899658, 5.4971923828125, 0.9668499827384949, 3.4064207077026367, 6.120072841644287, 1.1618105173110962, 1.8163127899169922, 4.385706424713135, 0.5305056571960449, 2.750011444091797, 5.077458381652832, 0.9627787470817566, 2.2813570499420166, 4.06866455078125], 'accuracy': [0.6631205677986145, 0.3191489279270172, 0.5815602540969849, 0.4893617033958435, 0.6808510422706604, 0.609929084777832, 0.43617022037506104, 0.6808510422706604, 0.7517730593681335, 0.5141844153404236, 0.716312050819397, 0.76241135597229, 0.5177304744720459, 0.7340425252914429, 0.7765957713127136, 0.5815602540969849, 0.7482269406318665, 0.7943262457847595, 0.588652491569519, 0.7482269406318665, 0.8120567202568054, 0.6205673813819885, 0.7659574747085571, 0.8333333134651184, 0.6241135001182556, 0.7695035338401794, 0.8333333134651184, 0.6241135001182556, 0.7695035338401794, 0.847517728805542, 0.6276595592498779, 0.7730496525764465, 0.8439716100692749, 0.6631205677986145, 0.7801418304443359, 0.8546099066734314, 0.652482271194458, 0.7730496525764465, 0.8404255509376526, 0.6418439745903015, 0.7517730593681335, 0.8723404407501221, 0.6914893388748169, 0.783687949180603, 0.8865247964859009, 0.6560283899307251, 0.7801418304443359, 0.8546099066734314, 0.7304964661598206, 0.8085106611251831], 'precision_38': [0.6631205677986145, 0.3191489279270172, 0.5815602540969849, 0.4893617033958435, 0.6808510422706604, 0.609929084777832, 0.43617022037506104, 0.6808510422706604, 0.7517730593681335, 0.5141844153404236, 0.716312050819397, 0.76241135597229, 0.5177304744720459, 0.7340425252914429, 0.7765957713127136, 0.5815602540969849, 0.7482269406318665, 0.7943262457847595, 0.588652491569519, 0.7482269406318665, 0.8120567202568054, 0.6205673813819885, 0.7659574747085571, 0.8333333134651184, 0.6241135001182556, 0.7695035338401794, 0.8333333134651184, 0.6241135001182556, 0.7695035338401794, 0.847517728805542, 0.6276595592498779, 0.7730496525764465, 0.8439716100692749, 0.6631205677986145, 0.7801418304443359, 0.8546099066734314, 0.652482271194458, 0.7730496525764465, 0.8404255509376526, 0.6418439745903015, 0.7517730593681335, 0.8723404407501221, 0.6914893388748169, 0.783687949180603, 0.8865247964859009, 0.6560283899307251, 0.7801418304443359, 0.8546099066734314, 0.7304964661598206, 0.8085106611251831], 'recall_38': [0.6631205677986145, 0.3191489279270172, 0.5815602540969849, 0.4893617033958435, 0.6808510422706604, 0.609929084777832, 0.43617022037506104, 0.6808510422706604, 0.7517730593681335, 0.5141844153404236, 0.716312050819397, 0.76241135597229, 0.5177304744720459, 0.7340425252914429, 0.7765957713127136, 0.5815602540969849, 0.7482269406318665, 0.7943262457847595, 0.588652491569519, 0.7482269406318665, 0.8120567202568054, 0.6205673813819885, 0.7659574747085571, 0.8333333134651184, 0.6241135001182556, 0.7695035338401794, 0.8333333134651184, 0.6241135001182556, 0.7695035338401794, 0.847517728805542, 0.6276595592498779, 0.7730496525764465, 0.8439716100692749, 0.6631205677986145, 0.7801418304443359, 0.8546099066734314, 0.652482271194458, 0.7730496525764465, 0.8404255509376526, 0.6418439745903015, 0.7517730593681335, 0.8723404407501221, 0.6914893388748169, 0.783687949180603, 0.8865247964859009, 0.6560283899307251, 0.7801418304443359, 0.8546099066734314, 0.7304964661598206, 0.8085106611251831]}\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f88ad38fb00> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 7 - Precison: 0.7578952459254243 - Recall: 0.9565217391304348%\n",
      "Shape of train set: (282, 10020)\n",
      "Shape of y: (282, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 8 ...\n",
      "Shape of validation set: (31, 10020)\n",
      "{'loss': [17.178993225097656, 53.363304138183594, 22.38347816467285, 7.860077857971191, 18.601268768310547, 17.766311645507812, 8.692391395568848, 2.435920238494873, 8.014320373535156, 1.5901269912719727, 7.063347339630127, 10.80043888092041, 4.359669208526611, 2.883441686630249, 6.878572940826416, 1.4069846868515015, 3.6723196506500244, 8.779068946838379, 2.3028950691223145, 4.280395984649658, 7.217123031616211, 2.3222386837005615, 2.6367528438568115, 5.216519355773926, 1.0613425970077515, 2.6704204082489014, 5.5314741134643555, 1.4370871782302856, 2.292494297027588, 4.598260402679443, 0.7863770127296448, 1.9138257503509521, 3.9621949195861816, 0.4776645004749298, 1.26643967628479, 3.560000419616699, 0.31329989433288574, 0.249910369515419, 1.0796318054199219, 3.221281051635742, 5.802637577056885, 1.5563467741012573, 1.4005484580993652, 3.1209511756896973, 0.33542600274086, 0.2670876383781433, 0.5070453882217407, 1.7740213871002197, 5.115293025970459, 0.6673920154571533], 'accuracy': [0.3333333432674408, 0.6843971610069275, 0.6843971610069275, 0.5780141949653625, 0.3794326186180115, 0.6843971610069275, 0.7304964661598206, 0.6134752035140991, 0.7446808218955994, 0.6808510422706604, 0.5106382966041565, 0.7198581695556641, 0.758865237236023, 0.6170212626457214, 0.73758864402771, 0.76241135597229, 0.585106372833252, 0.7234042286872864, 0.7730496525764465, 0.5602836608886719, 0.7304964661598206, 0.7907801270484924, 0.6347517967224121, 0.76241135597229, 0.8226950168609619, 0.6418439745903015, 0.76241135597229, 0.8191489577293396, 0.6489361524581909, 0.7730496525764465, 0.8546099066734314, 0.6914893388748169, 0.7801418304443359, 0.8865247964859009, 0.7659574747085571, 0.783687949180603, 0.911347508430481, 0.9007092118263245, 0.8333333134651184, 0.563829779624939, 0.741134762763977, 0.8014184236526489, 0.741134762763977, 0.8014184236526489, 0.911347508430481, 0.9042553305625916, 0.8936170339584351, 0.7198581695556641, 0.7730496525764465, 0.8723404407501221], 'precision_39': [0.3333333432674408, 0.6843971610069275, 0.6843971610069275, 0.5780141949653625, 0.3794326186180115, 0.6843971610069275, 0.7304964661598206, 0.6134752035140991, 0.7446808218955994, 0.6808510422706604, 0.5106382966041565, 0.7198581695556641, 0.758865237236023, 0.6170212626457214, 0.73758864402771, 0.76241135597229, 0.585106372833252, 0.7234042286872864, 0.7730496525764465, 0.5602836608886719, 0.7304964661598206, 0.7907801270484924, 0.6347517967224121, 0.76241135597229, 0.8226950168609619, 0.6418439745903015, 0.76241135597229, 0.8191489577293396, 0.6489361524581909, 0.7730496525764465, 0.8546099066734314, 0.6914893388748169, 0.7801418304443359, 0.8865247964859009, 0.7659574747085571, 0.783687949180603, 0.911347508430481, 0.9007092118263245, 0.8333333134651184, 0.563829779624939, 0.741134762763977, 0.8014184236526489, 0.741134762763977, 0.8014184236526489, 0.911347508430481, 0.9042553305625916, 0.8936170339584351, 0.7198581695556641, 0.7730496525764465, 0.8723404407501221], 'recall_39': [0.3333333432674408, 0.6843971610069275, 0.6843971610069275, 0.5780141949653625, 0.3794326186180115, 0.6843971610069275, 0.7304964661598206, 0.6134752035140991, 0.7446808218955994, 0.6808510422706604, 0.5106382966041565, 0.7198581695556641, 0.758865237236023, 0.6170212626457214, 0.73758864402771, 0.76241135597229, 0.585106372833252, 0.7234042286872864, 0.7730496525764465, 0.5602836608886719, 0.7304964661598206, 0.7907801270484924, 0.6347517967224121, 0.76241135597229, 0.8226950168609619, 0.6418439745903015, 0.76241135597229, 0.8191489577293396, 0.6489361524581909, 0.7730496525764465, 0.8546099066734314, 0.6914893388748169, 0.7801418304443359, 0.8865247964859009, 0.7659574747085571, 0.783687949180603, 0.911347508430481, 0.9007092118263245, 0.8333333134651184, 0.563829779624939, 0.741134762763977, 0.8014184236526489, 0.741134762763977, 0.8014184236526489, 0.911347508430481, 0.9042553305625916, 0.8936170339584351, 0.7198581695556641, 0.7730496525764465, 0.8723404407501221]}\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f887c6274d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Fold 8 - Precison: 0.7622800586510264 - Recall: 0.3181818181818182%\n",
      "Shape of train set: (282, 10020)\n",
      "Shape of y: (282, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 9 ...\n",
      "Shape of validation set: (31, 10020)\n",
      "{'loss': [22.503007888793945, 117.48268127441406, 5.481495380401611, 30.58106803894043, 3.653019905090332, 18.48642349243164, 13.722098350524902, 2.2851946353912354, 9.671390533447266, 11.073265075683594, 2.553772449493408, 7.373686790466309, 8.97211742401123, 2.2478179931640625, 5.3828125, 7.551213264465332, 1.6559593677520752, 4.232172012329102, 6.939353942871094, 1.388141393661499, 4.116809844970703, 6.613546371459961, 1.2446094751358032, 3.5375850200653076, 6.681276798248291, 1.2686142921447754, 2.603816032409668, 5.619369029998779, 0.7248944640159607, 1.2940436601638794, 3.927027940750122, 0.6960406303405762, 2.432223320007324, 2.9065537452697754, 6.407992839813232, 0.9499929547309875, 3.763368844985962, 5.803196907043457, 1.2217406034469604, 2.713165283203125, 4.81079626083374, 0.7706507444381714, 1.4193506240844727, 3.5593035221099854, 0.559281587600708, 1.264766812324524, 2.3065459728240967, 4.400817394256592, 0.47760170698165894, 0.8218995332717896], 'accuracy': [0.6808510422706604, 0.3191489279270172, 0.4609929025173187, 0.6808510422706604, 0.6382978558540344, 0.3758865296840668, 0.6808510422706604, 0.695035457611084, 0.478723406791687, 0.695035457611084, 0.7695035338401794, 0.5460993051528931, 0.7234042286872864, 0.7695035338401794, 0.585106372833252, 0.73758864402771, 0.7907801270484924, 0.631205677986145, 0.7553191781044006, 0.804964542388916, 0.6241135001182556, 0.76241135597229, 0.8120567202568054, 0.6595744490623474, 0.76241135597229, 0.8226950168609619, 0.6843971610069275, 0.7765957713127136, 0.8510638475418091, 0.7801418304443359, 0.7907801270484924, 0.8510638475418091, 0.8191489577293396, 0.6418439745903015, 0.7482269406318665, 0.8156028389930725, 0.631205677986145, 0.783687949180603, 0.8510638475418091, 0.6666666865348816, 0.7872340679168701, 0.8758864998817444, 0.76241135597229, 0.8014184236526489, 0.8546099066734314, 0.8617021441459656, 0.695035457611084, 0.7872340679168701, 0.9042553305625916, 0.8156028389930725], 'precision_40': [0.6808510422706604, 0.3191489279270172, 0.4609929025173187, 0.6808510422706604, 0.6382978558540344, 0.3758865296840668, 0.6808510422706604, 0.695035457611084, 0.478723406791687, 0.695035457611084, 0.7695035338401794, 0.5460993051528931, 0.7234042286872864, 0.7695035338401794, 0.585106372833252, 0.73758864402771, 0.7907801270484924, 0.631205677986145, 0.7553191781044006, 0.804964542388916, 0.6241135001182556, 0.76241135597229, 0.8120567202568054, 0.6595744490623474, 0.76241135597229, 0.8226950168609619, 0.6843971610069275, 0.7765957713127136, 0.8510638475418091, 0.7801418304443359, 0.7907801270484924, 0.8510638475418091, 0.8191489577293396, 0.6418439745903015, 0.7482269406318665, 0.8156028389930725, 0.631205677986145, 0.783687949180603, 0.8510638475418091, 0.6666666865348816, 0.7872340679168701, 0.8758864998817444, 0.76241135597229, 0.8014184236526489, 0.8546099066734314, 0.8617021441459656, 0.695035457611084, 0.7872340679168701, 0.9042553305625916, 0.8156028389930725], 'recall_40': [0.6808510422706604, 0.3191489279270172, 0.4609929025173187, 0.6808510422706604, 0.6382978558540344, 0.3758865296840668, 0.6808510422706604, 0.695035457611084, 0.478723406791687, 0.695035457611084, 0.7695035338401794, 0.5460993051528931, 0.7234042286872864, 0.7695035338401794, 0.585106372833252, 0.73758864402771, 0.7907801270484924, 0.631205677986145, 0.7553191781044006, 0.804964542388916, 0.6241135001182556, 0.76241135597229, 0.8120567202568054, 0.6595744490623474, 0.76241135597229, 0.8226950168609619, 0.6843971610069275, 0.7765957713127136, 0.8510638475418091, 0.7801418304443359, 0.7907801270484924, 0.8510638475418091, 0.8191489577293396, 0.6418439745903015, 0.7482269406318665, 0.8156028389930725, 0.631205677986145, 0.783687949180603, 0.8510638475418091, 0.6666666865348816, 0.7872340679168701, 0.8758864998817444, 0.76241135597229, 0.8014184236526489, 0.8546099066734314, 0.8617021441459656, 0.695035457611084, 0.7872340679168701, 0.9042553305625916, 0.8156028389930725]}\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f88873cd9e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 9 - Precison: 0.7256855443246119 - Recall: 0.9130434782608695%\n",
      "Shape of train set: (282, 10020)\n",
      "Shape of y: (282, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 10 ...\n",
      "Shape of validation set: (31, 10020)\n",
      "{'loss': [24.309913635253906, 196.88929748535156, 5.8822479248046875, 17.597639083862305, 12.265581130981445, 25.322694778442383, 10.84796142578125, 8.059218406677246, 19.93463134765625, 10.332364082336426, 2.3293087482452393, 4.155832290649414, 12.60787296295166, 3.9978978633880615, 7.772399425506592, 14.777726173400879, 6.427188396453857, 2.5190634727478027, 7.769146919250488, 1.263776421546936, 2.445807933807373, 10.024689674377441, 13.08029842376709, 4.999500274658203, 2.7374119758605957, 7.583362102508545, 1.069534182548523, 4.294061183929443, 11.19492244720459, 3.930692672729492, 3.148618459701538, 8.532306671142578, 2.0474660396575928, 4.9690117835998535, 10.982182502746582, 4.172586917877197, 1.6776001453399658, 5.502190113067627, 0.6401140689849854, 1.0555633306503296, 4.997995853424072, 10.026390075683594, 3.183279037475586, 2.492591142654419, 6.951760768890381, 1.1351242065429688, 4.868071556091309, 9.181330680847168, 3.055206775665283, 1.405832052230835], 'accuracy': [0.6879432797431946, 0.304964542388916, 0.563829779624939, 0.695035457611084, 0.3191489279270172, 0.695035457611084, 0.7340425252914429, 0.40780141949653625, 0.695035457611084, 0.758865237236023, 0.7340425252914429, 0.6170212626457214, 0.7269503474235535, 0.783687949180603, 0.4751773178577423, 0.7021276354789734, 0.7872340679168701, 0.631205677986145, 0.7553191781044006, 0.7553191781044006, 0.8120567202568054, 0.4716311991214752, 0.716312050819397, 0.7943262457847595, 0.7198581695556641, 0.7765957713127136, 0.847517728805542, 0.6063829660415649, 0.7553191781044006, 0.8191489577293396, 0.6843971610069275, 0.7765957713127136, 0.847517728805542, 0.5531914830207825, 0.7482269406318665, 0.8226950168609619, 0.7907801270484924, 0.8191489577293396, 0.8581560254096985, 0.8794326186180115, 0.588652491569519, 0.76241135597229, 0.8368794322013855, 0.716312050819397, 0.7872340679168701, 0.8723404407501221, 0.5921986103057861, 0.7695035338401794, 0.8404255509376526, 0.8226950168609619], 'precision_41': [0.6879432797431946, 0.304964542388916, 0.563829779624939, 0.695035457611084, 0.3191489279270172, 0.695035457611084, 0.7340425252914429, 0.40780141949653625, 0.695035457611084, 0.758865237236023, 0.7340425252914429, 0.6170212626457214, 0.7269503474235535, 0.783687949180603, 0.4751773178577423, 0.7021276354789734, 0.7872340679168701, 0.631205677986145, 0.7553191781044006, 0.7553191781044006, 0.8120567202568054, 0.4716311991214752, 0.716312050819397, 0.7943262457847595, 0.7198581695556641, 0.7765957713127136, 0.847517728805542, 0.6063829660415649, 0.7553191781044006, 0.8191489577293396, 0.6843971610069275, 0.7765957713127136, 0.847517728805542, 0.5531914830207825, 0.7482269406318665, 0.8226950168609619, 0.7907801270484924, 0.8191489577293396, 0.8581560254096985, 0.8794326186180115, 0.588652491569519, 0.76241135597229, 0.8368794322013855, 0.716312050819397, 0.7872340679168701, 0.8723404407501221, 0.5921986103057861, 0.7695035338401794, 0.8404255509376526, 0.8226950168609619], 'recall_41': [0.6879432797431946, 0.304964542388916, 0.563829779624939, 0.695035457611084, 0.3191489279270172, 0.695035457611084, 0.7340425252914429, 0.40780141949653625, 0.695035457611084, 0.758865237236023, 0.7340425252914429, 0.6170212626457214, 0.7269503474235535, 0.783687949180603, 0.4751773178577423, 0.7021276354789734, 0.7872340679168701, 0.631205677986145, 0.7553191781044006, 0.7553191781044006, 0.8120567202568054, 0.4716311991214752, 0.716312050819397, 0.7943262457847595, 0.7198581695556641, 0.7765957713127136, 0.847517728805542, 0.6063829660415649, 0.7553191781044006, 0.8191489577293396, 0.6843971610069275, 0.7765957713127136, 0.847517728805542, 0.5531914830207825, 0.7482269406318665, 0.8226950168609619, 0.7907801270484924, 0.8191489577293396, 0.8581560254096985, 0.8794326186180115, 0.588652491569519, 0.76241135597229, 0.8368794322013855, 0.716312050819397, 0.7872340679168701, 0.8723404407501221, 0.5921986103057861, 0.7695035338401794, 0.8404255509376526, 0.8226950168609619]}\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f88da653cb0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Fold 10 - Precison: 0.6412806209071066 - Recall: 0.9473684210526315%\n",
      "------------------------------------------------------------------------\n",
      "> Precison: 0.7023702764588535 (+- 0.06146396945902786)\n",
      "> Recall: 0.7995943415851883\n",
      "------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "num_folds = 10\n",
    "# Define per-fold score containers <-- these are new\n",
    "acc_per_fold = []\n",
    "loss_per_fold = []\n",
    "\n",
    "# Define the K-fold Cross Validator\n",
    "kfold = KFold(n_splits=num_folds, shuffle=True)\n",
    "\n",
    "inputs = result\n",
    "targets = y\n",
    "\n",
    "print('# inputs data samples:', inputs.shape[0])\n",
    "print('# targets data samples:', targets.shape[0])\n",
    "\n",
    "# K-fold Cross Validation model evaluation\n",
    "fold_no = 1\n",
    "for train, test in kfold.split(inputs, targets):\n",
    "    \n",
    "#     tk = Tokenizer(num_words=NB_WORDS,\n",
    "#                filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
    "#                lower=True,\n",
    "#                split=\" \")\n",
    "#     tk.fit_on_texts(inputs.iloc[train])\n",
    "    \n",
    "#     X_train_seq = tk.texts_to_sequences(inputs.iloc[train])\n",
    "#     X_test_seq = tk.texts_to_sequences(inputs.iloc[test])\n",
    "    \n",
    "    \n",
    "    X_train_oh = inputs.iloc[train]\n",
    "    X_test_oh = inputs.iloc[test]\n",
    "    \n",
    "    print('Shape of train set:',X_train_oh.shape)\n",
    "    \n",
    "    \n",
    "    y_train_le = targets.iloc[train]\n",
    "    y_train_oh = to_categorical(y_train_le)\n",
    "    \n",
    "    \n",
    "    y_test_le = targets.iloc[test]\n",
    "    y_test_oh = to_categorical(y_test_le)\n",
    "\n",
    "\n",
    "    \n",
    "    print('Shape of y:',y_train_oh.shape)\n",
    "\n",
    "    # Define the model architecture\n",
    "    base_model = models.Sequential()\n",
    "    base_model.add(layers.Dense(128, activation='relu', input_shape=(10020,)))\n",
    "    base_model.add(layers.Dense(64, activation='relu'))\n",
    "    base_model.add(layers.Dense(2, activation='softmax'))\n",
    "\n",
    "    # Compile the model\n",
    "    base_model.compile(optimizer='rmsprop'\n",
    "                  , loss='categorical_crossentropy'\n",
    "                  , metrics=['accuracy',tf.keras.metrics.Precision(),tf.keras.metrics.Recall()])\n",
    "    \n",
    "\n",
    "    # Generate a print\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'Training for fold {fold_no} ...')\n",
    "    print('Shape of validation set:',X_test_oh.shape)\n",
    "    \n",
    "    # Fit data to model\n",
    "    history = base_model.fit(X_train_oh\n",
    "                       ,y_train_oh\n",
    "                       , epochs=50\n",
    "                       , batch_size=BATCH_SIZE\n",
    "                       , verbose=0)\n",
    "    print(history.history)\n",
    "    \n",
    "\n",
    "    # Generate generalization metrics\n",
    "    from sklearn.metrics import classification_report\n",
    "    y_pred = base_model.predict_classes(X_test_oh)\n",
    "    \n",
    "    average_recall = recall_score(y_test_le, y_pred)\n",
    "    average_precision = average_precision_score(y_test_le, y_pred)\n",
    "    print(f'> Fold {fold_no} - Precison: {average_precision} - Recall: {average_recall}%')\n",
    "    \n",
    "    acc_per_fold.append(average_precision)\n",
    "    loss_per_fold.append(average_recall)\n",
    "\n",
    "    # Increase fold number\n",
    "    fold_no = fold_no + 1\n",
    "\n",
    "# == Provide average scores ==\n",
    "print('------------------------------------------------------------------------')\n",
    "\n",
    "print(f'> Precison: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "print(f'> Recall: {np.mean(loss_per_fold)}')\n",
    "print('------------------------------------------------------------------------')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier, KerasRegressor\n",
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "\n",
    "base_model = models.Sequential()\n",
    "base_model.add(layers.Dense(128, activation='relu', input_shape=(10020,)))\n",
    "base_model.add(layers.Dense(64, activation='relu'))\n",
    "base_model.add(layers.Dense(2, activation='softmax'))\n",
    "\n",
    "X = result\n",
    "y = y\n",
    "\n",
    "my_model = KerasRegressor(build_fn=basemodel, **sk_params)    \n",
    "my_model.fit(X,y)\n",
    "\n",
    "perm = PermutationImportance(my_model, random_state=1).fit(X,y)\n",
    "eli5.show_weights(perm, feature_names = X.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_metric(history, metric_name):\n",
    "    metric = history.history[metric_name]\n",
    "    val_metric = history.history['val_' + metric_name+'_24']\n",
    "\n",
    "    e = range(1, NB_START_EPOCHS + 1)\n",
    "\n",
    "    plt.plot(e, metric, 'bo', label='Train ' + metric_name)\n",
    "    plt.plot(e, val_metric, 'b', label='Validation ' + metric_name)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.save(\"visual_mlp.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31, 10020)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_oh.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31,)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_le.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31, 10020)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_oh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shape mismatch: objects cannot be broadcast to a single shape",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-117-f54014f284ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Random Forest feature importance via permutation importance w. std. dev.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m plt.bar(range(X.shape[1]), imp_vals[indices],\n\u001b[0;32m---> 18\u001b[0;31m         yerr=std[indices])\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mbar\u001b[0;34m(x, height, width, bottom, align, data, **kwargs)\u001b[0m\n\u001b[1;32m   2455\u001b[0m     return gca().bar(\n\u001b[1;32m   2456\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbottom\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbottom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malign\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malign\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2457\u001b[0;31m         **({\"data\": data} if data is not None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1808\u001b[0m                         \u001b[0;34m\"the Matplotlib list!)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabel_namer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                         RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1810\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1812\u001b[0m         inner.__doc__ = _add_data_doc(inner.__doc__,\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mbar\u001b[0;34m(self, x, height, width, bottom, align, **kwargs)\u001b[0m\n\u001b[1;32m   2249\u001b[0m         x, height, width, y, linewidth = np.broadcast_arrays(\n\u001b[1;32m   2250\u001b[0m             \u001b[0;31m# Make args iterable too.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2251\u001b[0;31m             np.atleast_1d(x), height, width, y, linewidth)\n\u001b[0m\u001b[1;32m   2252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2253\u001b[0m         \u001b[0;31m# Now that units have been converted, set the tick locations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mbroadcast_arrays\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/numpy/lib/stride_tricks.py\u001b[0m in \u001b[0;36mbroadcast_arrays\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_m\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubok\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_m\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m     \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_broadcast_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/numpy/lib/stride_tricks.py\u001b[0m in \u001b[0;36m_broadcast_shape\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0;31m# use the old-iterator because np.nditer does not handle size 0 arrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m     \u001b[0;31m# consistently\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m     \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m     \u001b[0;31m# unfortunately, it cannot handle 32 or more arguments directly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mpos\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m31\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shape mismatch: objects cannot be broadcast to a single shape"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from mlxtend.evaluate import feature_importance_permutation\n",
    "from sklearn.metrics import f1_score\n",
    "imp_vals, imp_all = feature_importance_permutation(\n",
    "    predict_method= base_model.predict_classes, \n",
    "    X=X_test_oh.values,\n",
    "    y=y_test_le,\n",
    "    metric=f1_score,\n",
    "    num_rounds=10,\n",
    "    seed=1)\n",
    "\n",
    "\n",
    "std = np.std(imp_all, axis=1)\n",
    "indices = np.argsort(imp_vals)[::-1]\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Random Forest feature importance via permutation importance w. std. dev.\")\n",
    "plt.bar(range(X.shape[1]), imp_vals[indices],\n",
    "        yerr=std[indices])\n",
    "plt.xticks(range(X.shape[1]), indices)\n",
    "plt.xlim([-1, X.shape[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15     0\n",
       "23     0\n",
       "25     0\n",
       "27     0\n",
       "36     1\n",
       "39     0\n",
       "47     1\n",
       "51     1\n",
       "79     1\n",
       "107    1\n",
       "128    1\n",
       "130    1\n",
       "154    0\n",
       "165    1\n",
       "178    1\n",
       "183    1\n",
       "190    1\n",
       "195    0\n",
       "210    1\n",
       "214    0\n",
       "225    1\n",
       "235    1\n",
       "252    0\n",
       "271    0\n",
       "273    1\n",
       "293    0\n",
       "329    1\n",
       "337    0\n",
       "370    1\n",
       "384    1\n",
       "392    1\n",
       "Name: attitude, dtype: int64"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_le"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Train data samples: 509\n",
      "# Test data samples: 57\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.video_description, df.Relevancy, test_size=0.1, random_state=37)\n",
    "print('# Train data samples:', X_train.shape[0])\n",
    "print('# Test data samples:', X_test.shape[0])\n",
    "assert X_train.shape[0] == y_train.shape[0]\n",
    "assert X_test.shape[0] == y_test.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting words to numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use the text as input for a model, we first need to convert the tweet's words into tokens, which simply means converting the words to integers that refer to an index in a dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will only keep the most frequent words in the train set.\n",
    "\n",
    "We clean up the text by applying filters and putting the words to lowercase. Words are separated by spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitted tokenizer on 509 documents\n",
      "10000 words in dictionary\n",
      "Top 5 most common words are: [('coronavirus', 624), ('news', 521), ('us', 271), ('follow', 260), ('subscribe', 255), ('channel', 255), ('virus', 239), ('watch', 230), ('5g', 215), ('dr', 215), ('covid', 214), ('twitter', 214), ('video', 211), ('not', 206), ('like', 205), ('facebook', 204), ('19', 201), ('this', 184), ('people', 183), ('playlist', 181)]\n"
     ]
    }
   ],
   "source": [
    "tk = Tokenizer(num_words=NB_WORDS,\n",
    "               filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
    "               lower=True,\n",
    "               split=\" \")\n",
    "tk.fit_on_texts(X_train)\n",
    "\n",
    "print('Fitted tokenizer on {} documents'.format(tk.document_count))\n",
    "print('{} words in dictionary'.format(tk.num_words))\n",
    "print('Top 5 most common words are:', collections.Counter(tk.word_counts).most_common(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After having created the dictionary we can convert the text to a list of integer indexes. This is done with the text_to_sequences method of the Tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"With theories circulating online 5G technology blame COVID-19 pandemic, experts present facts behind claims. Subscribe 7NEWS latest video Â¬Âª  Connect 7NEWS online Visit Â¬Âª  Facebook Â¬Âª  Twitter Â¬Âª  Instagram Â¬Âª  #BreakingNews #coronavirus #COVID19 #7NEWS\" is converted into [2045, 2546, 2547, 3245, 1761, 2548, 1039, 4683, 33, 124, 582, 83, 111, 818, 1, 220, 221, 115, 3246, 32, 120, 1762, 236, 486, 765, 1, 263, 660]\n"
     ]
    }
   ],
   "source": [
    "X_train_seq = tk.texts_to_sequences(X_train)\n",
    "X_test_seq = tk.texts_to_sequences(X_test)\n",
    "\n",
    "print('\"{}\" is converted into {}'.format(X_train[0], X_train_seq[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These integers should now be converted into a one-hot encoded features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_seq(seqs, nb_features = NB_WORDS):\n",
    "    ohs = np.zeros((len(seqs), nb_features))\n",
    "    for i, s in enumerate(seqs):\n",
    "        ohs[i, s] = 1.\n",
    "    return ohs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting the target classes to numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"1\" is converted into 1\n",
      "\"1\" is converted into [0. 1.]\n"
     ]
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "y_train_le = le.fit_transform(y_train)\n",
    "y_test_le = le.transform(y_test)\n",
    "y_train_oh = to_categorical(y_train_le)\n",
    "y_test_oh = to_categorical(y_test_le)\n",
    "\n",
    "print('\"{}\" is converted into {}'.format(y_train[0], y_train_le[0]))\n",
    "print('\"{}\" is converted into {}'.format(y_train_le[0], y_train_oh[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting of a validation set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of validation set: (51, 10000)\n"
     ]
    }
   ],
   "source": [
    "X_train_rest, X_valid, y_train_rest, y_valid = train_test_split(X_train_oh, y_train_oh, test_size=0.1, random_state=37)\n",
    "\n",
    "assert X_valid.shape[0] == y_valid.shape[0]\n",
    "assert X_train_rest.shape[0] == y_train_rest.shape[0]\n",
    "\n",
    "print('Shape of validation set:',X_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Implementation\n",
    "## Baseline model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start with a model with 2 densely connected layers of 64 hidden elements. The input_shape for the first layer is equal to the number of words we allowed in the dictionary and for which we created one-hot-encoded features.\n",
    "\n",
    " The softmax activation function makes sure the three probabilities sum up to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 64)                640064    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 644,354\n",
      "Trainable params: 644,354\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model = models.Sequential()\n",
    "base_model.add(layers.Dense(64, activation='relu', input_shape=(NB_WORDS,)))\n",
    "base_model.add(layers.Dense(64, activation='relu'))\n",
    "base_model.add(layers.Dense(2, activation='softmax'))\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because this project is a multi-class, single-label prediction, we use categorical_crossentropy as the loss function and softmax as the final activation function. We fit the model on the remaining train data and validate on the validation set. We run for a predetermined number of epochs and will see when the model starts to overfit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_model(model):\n",
    "    model.compile(optimizer='rmsprop'\n",
    "                  , loss='categorical_crossentropy'\n",
    "                  , metrics=['accuracy',tf.keras.metrics.Precision(),tf.keras.metrics.Recall()])\n",
    "    \n",
    "    history = model.fit(X_train_rest\n",
    "                       , y_train_rest\n",
    "                       , epochs=NB_START_EPOCHS\n",
    "                       , batch_size=BATCH_SIZE\n",
    "                       , validation_data=(X_valid, y_valid)\n",
    "                       , verbose=0)\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.7070090174674988,\n",
       "  0.5174614787101746,\n",
       "  0.3788684904575348,\n",
       "  0.3041400909423828,\n",
       "  0.25723156332969666,\n",
       "  0.22602522373199463,\n",
       "  0.2032897025346756,\n",
       "  0.1780741959810257,\n",
       "  0.1627146452665329,\n",
       "  0.1489810198545456,\n",
       "  0.13913194835186005,\n",
       "  0.12844568490982056,\n",
       "  0.11971041560173035,\n",
       "  0.11082577705383301,\n",
       "  0.10460763424634933,\n",
       "  0.09958921372890472,\n",
       "  0.09780213981866837,\n",
       "  0.09410517662763596,\n",
       "  0.089164137840271,\n",
       "  0.08444852381944656],\n",
       " 'accuracy': [0.3995633125305176,\n",
       "  0.8253275156021118,\n",
       "  0.8668122291564941,\n",
       "  0.9017467498779297,\n",
       "  0.9366812109947205,\n",
       "  0.9344978332519531,\n",
       "  0.9410480260848999,\n",
       "  0.9454148411750793,\n",
       "  0.9563318490982056,\n",
       "  0.9541484713554382,\n",
       "  0.9563318490982056,\n",
       "  0.9563318490982056,\n",
       "  0.960698664188385,\n",
       "  0.960698664188385,\n",
       "  0.960698664188385,\n",
       "  0.960698664188385,\n",
       "  0.9628821015357971,\n",
       "  0.9628821015357971,\n",
       "  0.9628821015357971,\n",
       "  0.9628821015357971],\n",
       " 'precision': [0.39427313208580017,\n",
       "  0.8253275156021118,\n",
       "  0.8668122291564941,\n",
       "  0.9017467498779297,\n",
       "  0.9366812109947205,\n",
       "  0.9344978332519531,\n",
       "  0.9410480260848999,\n",
       "  0.9454148411750793,\n",
       "  0.9563318490982056,\n",
       "  0.9541484713554382,\n",
       "  0.9563318490982056,\n",
       "  0.9563318490982056,\n",
       "  0.960698664188385,\n",
       "  0.960698664188385,\n",
       "  0.960698664188385,\n",
       "  0.960698664188385,\n",
       "  0.9628821015357971,\n",
       "  0.9628821015357971,\n",
       "  0.9628821015357971,\n",
       "  0.9628821015357971],\n",
       " 'recall': [0.3908296823501587,\n",
       "  0.8253275156021118,\n",
       "  0.8668122291564941,\n",
       "  0.9017467498779297,\n",
       "  0.9366812109947205,\n",
       "  0.9344978332519531,\n",
       "  0.9410480260848999,\n",
       "  0.9454148411750793,\n",
       "  0.9563318490982056,\n",
       "  0.9541484713554382,\n",
       "  0.9563318490982056,\n",
       "  0.9563318490982056,\n",
       "  0.960698664188385,\n",
       "  0.960698664188385,\n",
       "  0.960698664188385,\n",
       "  0.960698664188385,\n",
       "  0.9628821015357971,\n",
       "  0.9628821015357971,\n",
       "  0.9628821015357971,\n",
       "  0.9628821015357971],\n",
       " 'val_loss': [0.5335533022880554,\n",
       "  0.43902894854545593,\n",
       "  0.3966190814971924,\n",
       "  0.36304351687431335,\n",
       "  0.36193162202835083,\n",
       "  0.3229401409626007,\n",
       "  0.33019882440567017,\n",
       "  0.3119520843029022,\n",
       "  0.3339370787143707,\n",
       "  0.302752822637558,\n",
       "  0.33394140005111694,\n",
       "  0.2985526919364929,\n",
       "  0.32714682817459106,\n",
       "  0.30503079295158386,\n",
       "  0.3339540362358093,\n",
       "  0.29546359181404114,\n",
       "  0.3473667800426483,\n",
       "  0.3011917769908905,\n",
       "  0.33582183718681335,\n",
       "  0.30534660816192627],\n",
       " 'val_accuracy': [0.9019607901573181,\n",
       "  0.9019607901573181,\n",
       "  0.9019607901573181,\n",
       "  0.9019607901573181,\n",
       "  0.9019607901573181,\n",
       "  0.8823529481887817,\n",
       "  0.9019607901573181,\n",
       "  0.9019607901573181,\n",
       "  0.9019607901573181,\n",
       "  0.9019607901573181,\n",
       "  0.9019607901573181,\n",
       "  0.9019607901573181,\n",
       "  0.8823529481887817,\n",
       "  0.9019607901573181,\n",
       "  0.9019607901573181,\n",
       "  0.9019607901573181,\n",
       "  0.9019607901573181,\n",
       "  0.9019607901573181,\n",
       "  0.9019607901573181,\n",
       "  0.9019607901573181],\n",
       " 'val_precision': [0.9019607901573181,\n",
       "  0.9019607901573181,\n",
       "  0.9019607901573181,\n",
       "  0.9019607901573181,\n",
       "  0.9019607901573181,\n",
       "  0.8823529481887817,\n",
       "  0.9019607901573181,\n",
       "  0.9019607901573181,\n",
       "  0.9019607901573181,\n",
       "  0.9019607901573181,\n",
       "  0.9019607901573181,\n",
       "  0.9019607901573181,\n",
       "  0.8823529481887817,\n",
       "  0.9019607901573181,\n",
       "  0.9019607901573181,\n",
       "  0.9019607901573181,\n",
       "  0.9019607901573181,\n",
       "  0.9019607901573181,\n",
       "  0.9019607901573181,\n",
       "  0.9019607901573181],\n",
       " 'val_recall': [0.9019607901573181,\n",
       "  0.9019607901573181,\n",
       "  0.9019607901573181,\n",
       "  0.9019607901573181,\n",
       "  0.9019607901573181,\n",
       "  0.8823529481887817,\n",
       "  0.9019607901573181,\n",
       "  0.9019607901573181,\n",
       "  0.9019607901573181,\n",
       "  0.9019607901573181,\n",
       "  0.9019607901573181,\n",
       "  0.9019607901573181,\n",
       "  0.8823529481887817,\n",
       "  0.9019607901573181,\n",
       "  0.9019607901573181,\n",
       "  0.9019607901573181,\n",
       "  0.9019607901573181,\n",
       "  0.9019607901573181,\n",
       "  0.9019607901573181,\n",
       "  0.9019607901573181]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_history = first_model(base_model)\n",
    "base_history.history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate the model performance, we will look at the training and validation loss and accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Validation\n",
    "\n",
    "lets check the model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, epoch_stop):\n",
    "    model.fit(X_train_oh\n",
    "              , y_train_oh\n",
    "              , epochs=epoch_stop\n",
    "              , batch_size=BATCH_SIZE\n",
    "              , verbose=0)\n",
    "    results = model.evaluate(X_test_oh, y_test_oh)\n",
    "    \n",
    "    return results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 1ms/step - loss: 0.8903 - accuracy: 0.8947 - precision_1: 0.8947 - recall_1: 0.8947\n",
      "[0.8902625441551208, 0.8947368264198303, 0.8947368264198303, 0.8947368264198303]\n",
      "Test accuracy of baseline model: 89.47%\n"
     ]
    }
   ],
   "source": [
    "test_results = test_model(base_model,30)\n",
    "print(test_results)\n",
    "print('Test accuracy of baseline model: {0:.2f}%'.format(test_results[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 0 1 1 1 1 1 1 1 0 0 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 0 1 0 0 1 1\n",
      " 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "y_score = base_model.predict_classes(X_test_oh)\n",
    "print(y_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.75      0.75        12\n",
      "           1       0.93      0.93      0.93        45\n",
      "\n",
      "    accuracy                           0.89        57\n",
      "   macro avg       0.84      0.84      0.84        57\n",
      "weighted avg       0.89      0.89      0.89        57\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = base_model.predict_classes(X_test_oh)\n",
    "print(y_test.ndim)\n",
    "print(classification_report(y_test_le, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9237426900584795\n",
      "0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "\n",
    "average_precision = average_precision_score(y_test_le, y_pred)\n",
    "print(average_precision)\n",
    "average_recall = recall_score(y_test_le, y_pred)\n",
    "print(average_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_arr = np.column_stack((y_test_le, y_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [0, 0]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
