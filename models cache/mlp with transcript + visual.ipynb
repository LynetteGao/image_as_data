{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set-up of the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/lynette/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Basic packages\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import re\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "# Packages for data preparation\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Packages for modeling\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import regularizers\n",
    "\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import recall_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set some parameters that will be used throughout the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We read in the csv with the tweets data and perform a random shuffle. It's a good practice to shuffle the data before splitting between a train and test set. We'll only keep the video decription column as input and the Relvancy column as the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'video_id', 'channel_title', 'channel_id',\n",
       "       'video_publish_date', 'video_title', 'video_description',\n",
       "       'video_category', 'video_view_count', 'video_comment_count',\n",
       "       'video_like_count', 'video_dislike_count', 'video_thumbnail',\n",
       "       'video_tags', 'collection_date', 'science.topic', 'Relevancy',\n",
       "       'attitude', 'Text/video', 'search.term', 'cld2', 'transcript',\n",
       "       'transcript_nchar', 'videoid', 'conspiracy', 'var_r', 'var_g', 'var_b',\n",
       "       'var_h', 'var_s', 'var_v', 'var_bright', 'var_bright_sd',\n",
       "       'var_contrast', 'var_colorful', 'median_r', 'median_g', 'median_b',\n",
       "       'median_h', 'median_s', 'median_v', 'median_bright', 'median_bright_sd',\n",
       "       'median_contrast', 'median_colorful', 'r_mean', 'g_mean', 'b_mean',\n",
       "       'h_mean', 's_mean', 'v_mean', 'bright_mean', 'lightning_mean',\n",
       "       'contrast_mean', 'colorful_mean', 'color_lag'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('handlabel_feature.csv')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['transcript']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>with coronavirus completely changing our way o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>you all know I'm a big fan of conspiracy theor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>how do you handle an epidemic in the age of fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CaptionUnavailable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>what's up guys Stephen here and welcome back t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>so the government work for us we don't work fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>but even if 5g has nothing to do with this cor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>um some people believe that 5g like like for c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>this is a podcast from the South China Morning...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>we're all catching the wires because of the fi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>407 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            transcript\n",
       "0    with coronavirus completely changing our way o...\n",
       "1    you all know I'm a big fan of conspiracy theor...\n",
       "2    how do you handle an epidemic in the age of fa...\n",
       "3                                   CaptionUnavailable\n",
       "4    what's up guys Stephen here and welcome back t...\n",
       "..                                                 ...\n",
       "402  so the government work for us we don't work fo...\n",
       "403  but even if 5g has nothing to do with this cor...\n",
       "404  um some people believe that 5g like like for c...\n",
       "405  this is a podcast from the South China Morning...\n",
       "406  we're all catching the wires because of the fi...\n",
       "\n",
       "[407 rows x 1 columns]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X[(X[\"transcript\"] != 'CaptionUnavailable') & (X[\"transcript\"] != 'VideoUnavailable')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(313, 1)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "df['attitude'] = le.fit_transform(df['attitude'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      0\n",
       "2      0\n",
       "4      0\n",
       "5      1\n",
       "      ..\n",
       "402    1\n",
       "403    0\n",
       "404    0\n",
       "405    0\n",
       "406    0\n",
       "Name: attitude, Length: 313, dtype: int64"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df['attitude'][(df[\"transcript\"] != 'CaptionUnavailable') & (df[\"transcript\"] != 'VideoUnavailable')]\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing we'll do is removing stopwords. These words do not have any value for predicting the sentiment.Also, we remove the http link in the texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visual = ...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "result = pd.DataFrame(pd.np.column_stack([visual, X_oh]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.concat([visual, textual], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of            0            1            2           3            4      \\\n",
       "0     298.035544   256.526430   317.666638  176.226486   291.471955   \n",
       "1      14.562086    13.206167    14.473241   22.249816     3.087459   \n",
       "2    1397.200532  1812.288126  1125.290200  952.795220  3386.595470   \n",
       "3     800.175857   979.432379   765.202229  533.030459   899.264225   \n",
       "4     611.670255   710.533599   704.285521  565.782339   267.640542   \n",
       "..           ...          ...          ...         ...          ...   \n",
       "308   147.788425    83.104502   343.138525  287.133037   738.014925   \n",
       "309   499.048934   671.771055   464.885271  768.802809   362.948260   \n",
       "310    12.184924     9.988667     8.442325    7.628704     8.160141   \n",
       "311     3.100336    12.856796    13.246367    0.652040    23.776415   \n",
       "312    26.059390    20.160538    26.205856   37.262637     9.450165   \n",
       "\n",
       "          5            6           7            8           9      ...  10010  \\\n",
       "0    318.839186   249.684164   58.312728   273.094250  131.323126  ...    0.0   \n",
       "1     14.468497    13.461712    2.128646     6.360655    0.903765  ...    0.0   \n",
       "2    942.447595  1478.249667  160.366149  1102.429909  528.665700  ...    0.0   \n",
       "3    665.884765   850.382767  385.940453  2316.228370  115.950038  ...    0.0   \n",
       "4    616.471287   661.184079  185.405393    48.207604  226.281947  ...    0.0   \n",
       "..          ...          ...         ...          ...         ...  ...    ...   \n",
       "308  211.022546    73.414553  233.283992   762.744039  122.025988  ...    0.0   \n",
       "309  492.587090   554.760968   93.525503   564.382108   60.941841  ...    0.0   \n",
       "310   12.292979     9.858782    1.924338    13.182123    6.304640  ...    0.0   \n",
       "311    2.342890     9.398054    2.273838     0.001471    6.499906  ...    0.0   \n",
       "312   20.737421    21.035988   16.549036     6.226976    4.321690  ...    0.0   \n",
       "\n",
       "     10011  10012  10013  10014  10015  10016  10017  10018  10019  \n",
       "0      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "1      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "2      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "3      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "4      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "..     ...    ...    ...    ...    ...    ...    ...    ...    ...  \n",
       "308    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "309    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0  \n",
       "310    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "311    0.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "312    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "\n",
       "[313 rows x 10020 columns]>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate K-fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# inputs data samples: 313\n",
      "# targets data samples: 313\n",
      "Shape of train set: (281, 10020)\n",
      "Shape of y: (281, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Shape of validation set: (32, 10020)\n",
      "{'loss': [14.612687110900879, 112.26792907714844, 11.04271411895752, 22.205244064331055, 6.545848369598389, 10.392186164855957, 12.305441856384277, 3.1799399852752686, 7.627873420715332, 9.307175636291504, 2.0185112953186035, 5.807286739349365, 8.04775619506836, 1.7864655256271362, 4.3010735511779785, 7.815014362335205, 1.342038631439209, 3.948058843612671, 6.801834583282471, 1.2309454679489136, 3.518735885620117, 6.582371711730957, 1.053055763244629, 3.535033702850342, 5.768925666809082, 0.5020555853843689, 0.9378923773765564, 5.056182861328125, 0.7957579493522644, 2.749514102935791, 2.596181869506836, 7.4888105392456055, 1.158350944519043, 3.417651414871216, 5.8859148025512695, 0.46127617359161377, 1.3266457319259644, 4.875954627990723, 0.7336472868919373, 0.6965383887290955, 3.714428424835205, 0.777716875076294, 1.7395023107528687, 3.419144630432129, 7.238190650939941, 1.4075311422348022, 2.541917324066162, 4.802671909332275, 0.5301170349121094, 1.877925992012024], 'accuracy': [0.6832740306854248, 0.3131672739982605, 0.3416370153427124, 0.6868327260017395, 0.7010676264762878, 0.33096083998680115, 0.6868327260017395, 0.7437722682952881, 0.4519572854042053, 0.690391480922699, 0.7580071091651917, 0.5409252643585205, 0.7117437720298767, 0.7935943007469177, 0.6120996475219727, 0.7330960631370544, 0.8149465918540955, 0.5943060517311096, 0.7330960631370544, 0.8256227970123291, 0.6441280841827393, 0.7437722682952881, 0.8327401876449585, 0.6476868391036987, 0.7473309636116028, 0.8576512336730957, 0.8042704463005066, 0.7686832547187805, 0.790035605430603, 0.7935943007469177, 0.6441280841827393, 0.7473309636116028, 0.8327401876449585, 0.608540952205658, 0.754448413848877, 0.8754448294639587, 0.77224200963974, 0.7793594598770142, 0.8612099885940552, 0.836298942565918, 0.8007117509841919, 0.8256227970123291, 0.8256227970123291, 0.6192170977592468, 0.7508896589279175, 0.8078292012214661, 0.6975088715553284, 0.7864768505096436, 0.8825622797012329, 0.7188612222671509], 'precision_32': [0.6832740306854248, 0.3131672739982605, 0.3416370153427124, 0.6868327260017395, 0.7010676264762878, 0.33096083998680115, 0.6868327260017395, 0.7437722682952881, 0.4519572854042053, 0.690391480922699, 0.7580071091651917, 0.5409252643585205, 0.7117437720298767, 0.7935943007469177, 0.6120996475219727, 0.7330960631370544, 0.8149465918540955, 0.5943060517311096, 0.7330960631370544, 0.8256227970123291, 0.6441280841827393, 0.7437722682952881, 0.8327401876449585, 0.6476868391036987, 0.7473309636116028, 0.8576512336730957, 0.8042704463005066, 0.7686832547187805, 0.790035605430603, 0.7935943007469177, 0.6441280841827393, 0.7473309636116028, 0.8327401876449585, 0.608540952205658, 0.754448413848877, 0.8754448294639587, 0.77224200963974, 0.7793594598770142, 0.8612099885940552, 0.836298942565918, 0.8007117509841919, 0.8256227970123291, 0.8256227970123291, 0.6192170977592468, 0.7508896589279175, 0.8078292012214661, 0.6975088715553284, 0.7864768505096436, 0.8825622797012329, 0.7188612222671509], 'recall_32': [0.6832740306854248, 0.3131672739982605, 0.3416370153427124, 0.6868327260017395, 0.7010676264762878, 0.33096083998680115, 0.6868327260017395, 0.7437722682952881, 0.4519572854042053, 0.690391480922699, 0.7580071091651917, 0.5409252643585205, 0.7117437720298767, 0.7935943007469177, 0.6120996475219727, 0.7330960631370544, 0.8149465918540955, 0.5943060517311096, 0.7330960631370544, 0.8256227970123291, 0.6441280841827393, 0.7437722682952881, 0.8327401876449585, 0.6476868391036987, 0.7473309636116028, 0.8576512336730957, 0.8042704463005066, 0.7686832547187805, 0.790035605430603, 0.7935943007469177, 0.6441280841827393, 0.7473309636116028, 0.8327401876449585, 0.608540952205658, 0.754448413848877, 0.8754448294639587, 0.77224200963974, 0.7793594598770142, 0.8612099885940552, 0.836298942565918, 0.8007117509841919, 0.8256227970123291, 0.8256227970123291, 0.6192170977592468, 0.7508896589279175, 0.8078292012214661, 0.6975088715553284, 0.7864768505096436, 0.8825622797012329, 0.7188612222671509]}\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f889cb33050> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 1 - Precison: 0.679788961038961 - Recall: 0.8636363636363636%\n",
      "Shape of train set: (281, 10020)\n",
      "Shape of y: (281, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "Shape of validation set: (32, 10020)\n",
      "{'loss': [12.85079288482666, 60.1048698425293, 7.313065528869629, 55.94164276123047, 13.180625915527344, 11.51456069946289, 17.902616500854492, 3.428316116333008, 12.710392951965332, 9.789180755615234, 1.2268717288970947, 1.2368799448013306, 4.666477680206299, 8.888895988464355, 1.1419105529785156, 4.443930625915527, 8.04837417602539, 1.2358250617980957, 3.1345512866973877, 5.731544494628906, 0.8254855871200562, 1.6872128248214722, 4.512801647186279, 0.6391445994377136, 1.694576621055603, 3.7633607387542725, 6.037046909332275, 1.1565278768539429, 0.6297668814659119, 0.9995376467704773, 7.465222358703613, 6.061345100402832, 1.3555586338043213, 4.015980243682861, 0.46849629282951355, 0.8147639036178589, 3.8903326988220215, 5.144746780395508, 1.567095398902893, 1.2627222537994385, 3.2979471683502197, 3.7208335399627686, 3.920991897583008, 0.6750710010528564, 0.6177618503570557, 0.9253926873207092, 2.450495719909668, 5.803940296173096, 0.8604762554168701, 0.4656669497489929], 'accuracy': [0.46975088119506836, 0.6975088715553284, 0.5907473564147949, 0.30604982376098633, 0.6975088715553284, 0.47330960631370544, 0.6975088715553284, 0.7651245594024658, 0.38790035247802734, 0.6975088715553284, 0.7473309636116028, 0.790035605430603, 0.5800711512565613, 0.7437722682952881, 0.7864768505096436, 0.5978647470474243, 0.7508896589279175, 0.8007117509841919, 0.6761565804481506, 0.7651245594024658, 0.8398576378822327, 0.6939501762390137, 0.7686832547187805, 0.836298942565918, 0.7935943007469177, 0.608540952205658, 0.7580071091651917, 0.77224200963974, 0.8256227970123291, 0.8291814923286438, 0.5231316685676575, 0.7473309636116028, 0.754448413848877, 0.7793594598770142, 0.8790035843849182, 0.854092538356781, 0.6192170977592468, 0.7793594598770142, 0.8220640420913696, 0.7437722682952881, 0.7758007049560547, 0.6868327260017395, 0.7971529960632324, 0.754448413848877, 0.8647686839103699, 0.8505337834358215, 0.6583629846572876, 0.7615658640861511, 0.8398576378822327, 0.8647686839103699], 'precision_33': [0.46975088119506836, 0.6975088715553284, 0.5907473564147949, 0.30604982376098633, 0.6975088715553284, 0.47330960631370544, 0.6975088715553284, 0.7651245594024658, 0.38790035247802734, 0.6975088715553284, 0.7473309636116028, 0.790035605430603, 0.5800711512565613, 0.7437722682952881, 0.7864768505096436, 0.5978647470474243, 0.7508896589279175, 0.8007117509841919, 0.6761565804481506, 0.7651245594024658, 0.8398576378822327, 0.6939501762390137, 0.7686832547187805, 0.836298942565918, 0.7935943007469177, 0.608540952205658, 0.7580071091651917, 0.77224200963974, 0.8256227970123291, 0.8291814923286438, 0.5231316685676575, 0.7473309636116028, 0.754448413848877, 0.7793594598770142, 0.8790035843849182, 0.854092538356781, 0.6192170977592468, 0.7793594598770142, 0.8220640420913696, 0.7437722682952881, 0.7758007049560547, 0.6868327260017395, 0.7971529960632324, 0.754448413848877, 0.8647686839103699, 0.8505337834358215, 0.6583629846572876, 0.7615658640861511, 0.8398576378822327, 0.8647686839103699], 'recall_33': [0.46975088119506836, 0.6975088715553284, 0.5907473564147949, 0.30604982376098633, 0.6975088715553284, 0.47330960631370544, 0.6975088715553284, 0.7651245594024658, 0.38790035247802734, 0.6975088715553284, 0.7473309636116028, 0.790035605430603, 0.5800711512565613, 0.7437722682952881, 0.7864768505096436, 0.5978647470474243, 0.7508896589279175, 0.8007117509841919, 0.6761565804481506, 0.7651245594024658, 0.8398576378822327, 0.6939501762390137, 0.7686832547187805, 0.836298942565918, 0.7935943007469177, 0.608540952205658, 0.7580071091651917, 0.77224200963974, 0.8256227970123291, 0.8291814923286438, 0.5231316685676575, 0.7473309636116028, 0.754448413848877, 0.7793594598770142, 0.8790035843849182, 0.854092538356781, 0.6192170977592468, 0.7793594598770142, 0.8220640420913696, 0.7437722682952881, 0.7758007049560547, 0.6868327260017395, 0.7971529960632324, 0.754448413848877, 0.8647686839103699, 0.8505337834358215, 0.6583629846572876, 0.7615658640861511, 0.8398576378822327, 0.8647686839103699]}\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f88acf294d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Fold 2 - Precison: 0.5996710526315789 - Recall: 0.9473684210526315%\n",
      "Shape of train set: (281, 10020)\n",
      "Shape of y: (281, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "Shape of validation set: (32, 10020)\n",
      "{'loss': [38.87637710571289, 39.095333099365234, 10.807106971740723, 13.52180290222168, 17.20587730407715, 5.658076286315918, 6.6843671798706055, 12.40434741973877, 4.046075820922852, 5.233001708984375, 11.479544639587402, 3.801405429840088, 4.777150630950928, 9.12358570098877, 2.576449394226074, 4.159852981567383, 9.514265060424805, 2.8420162200927734, 3.612731456756592, 8.081618309020996, 1.7938988208770752, 5.306344985961914, 7.231159687042236, 1.7717946767807007, 3.519242286682129, 6.300229549407959, 1.2859834432601929, 2.8618297576904297, 6.285096168518066, 1.1270300149917603, 3.32780122756958, 5.701518535614014, 1.0145001411437988, 1.873701810836792, 5.361833572387695, 0.6023902893066406, 1.216110110282898, 4.6845879554748535, 0.42566657066345215, 0.41904494166374207, 1.7826629877090454, 3.2029948234558105, 6.397936820983887, 1.1816610097885132, 2.635164499282837, 4.900461196899414, 1.0060524940490723, 0.6486642956733704, 1.9610114097595215, 2.044621706008911], 'accuracy': [0.3167259693145752, 0.6832740306854248, 0.6797152757644653, 0.35587188601493835, 0.6832740306854248, 0.7402135133743286, 0.4911032021045685, 0.6975088715553284, 0.7188612222671509, 0.4875444769859314, 0.690391480922699, 0.7580071091651917, 0.5693950057029724, 0.7473309636116028, 0.790035605430603, 0.5480427145957947, 0.7295373678207397, 0.790035605430603, 0.5231316685676575, 0.7188612222671509, 0.7971529960632324, 0.5871886014938354, 0.7615658640861511, 0.8078292012214661, 0.6049821972846985, 0.7615658640861511, 0.836298942565918, 0.6334519386291504, 0.754448413848877, 0.8469750881195068, 0.6298932433128357, 0.7793594598770142, 0.8398576378822327, 0.7153024673461914, 0.7686832547187805, 0.8932384252548218, 0.77224200963974, 0.7935943007469177, 0.8896797299385071, 0.8825622797012329, 0.8327401876449585, 0.5943060517311096, 0.7437722682952881, 0.790035605430603, 0.6298932433128357, 0.790035605430603, 0.8683273792266846, 0.836298942565918, 0.8220640420913696, 0.7330960631370544], 'precision_34': [0.3167259693145752, 0.6832740306854248, 0.6797152757644653, 0.35587188601493835, 0.6832740306854248, 0.7402135133743286, 0.4911032021045685, 0.6975088715553284, 0.7188612222671509, 0.4875444769859314, 0.690391480922699, 0.7580071091651917, 0.5693950057029724, 0.7473309636116028, 0.790035605430603, 0.5480427145957947, 0.7295373678207397, 0.790035605430603, 0.5231316685676575, 0.7188612222671509, 0.7971529960632324, 0.5871886014938354, 0.7615658640861511, 0.8078292012214661, 0.6049821972846985, 0.7615658640861511, 0.836298942565918, 0.6334519386291504, 0.754448413848877, 0.8469750881195068, 0.6298932433128357, 0.7793594598770142, 0.8398576378822327, 0.7153024673461914, 0.7686832547187805, 0.8932384252548218, 0.77224200963974, 0.7935943007469177, 0.8896797299385071, 0.8825622797012329, 0.8327401876449585, 0.5943060517311096, 0.7437722682952881, 0.790035605430603, 0.6298932433128357, 0.790035605430603, 0.8683273792266846, 0.836298942565918, 0.8220640420913696, 0.7330960631370544], 'recall_34': [0.3167259693145752, 0.6832740306854248, 0.6797152757644653, 0.35587188601493835, 0.6832740306854248, 0.7402135133743286, 0.4911032021045685, 0.6975088715553284, 0.7188612222671509, 0.4875444769859314, 0.690391480922699, 0.7580071091651917, 0.5693950057029724, 0.7473309636116028, 0.790035605430603, 0.5480427145957947, 0.7295373678207397, 0.790035605430603, 0.5231316685676575, 0.7188612222671509, 0.7971529960632324, 0.5871886014938354, 0.7615658640861511, 0.8078292012214661, 0.6049821972846985, 0.7615658640861511, 0.836298942565918, 0.6334519386291504, 0.754448413848877, 0.8469750881195068, 0.6298932433128357, 0.7793594598770142, 0.8398576378822327, 0.7153024673461914, 0.7686832547187805, 0.8932384252548218, 0.77224200963974, 0.7935943007469177, 0.8896797299385071, 0.8825622797012329, 0.8327401876449585, 0.5943060517311096, 0.7437722682952881, 0.790035605430603, 0.6298932433128357, 0.790035605430603, 0.8683273792266846, 0.836298942565918, 0.8220640420913696, 0.7330960631370544]}\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f88b2c1f680> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 3 - Precison: 0.71875 - Recall: 1.0%\n",
      "Shape of train set: (282, 10020)\n",
      "Shape of y: (282, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "Shape of validation set: (31, 10020)\n",
      "{'loss': [4.864107131958008, 64.80400085449219, 5.588998794555664, 21.11333656311035, 4.30918025970459, 15.554287910461426, 2.80183482170105, 16.497360229492188, 6.822903156280518, 1.2639237642288208, 3.0843658447265625, 2.9913787841796875, 6.379672050476074, 1.5726484060287476, 2.670891523361206, 4.238208293914795, 0.9487523436546326, 1.8832755088806152, 4.122702121734619, 0.8241010904312134, 2.5437161922454834, 3.9734344482421875, 0.8482087850570679, 2.0850205421447754, 3.3606295585632324, 0.552568256855011, 1.5635906457901, 3.5417985916137695, 0.6165111064910889, 1.8884121179580688, 2.986436605453491, 1.1525813341140747, 2.8766961097717285, 0.8905888795852661, 2.5062577724456787, 0.7667016386985779, 2.4468140602111816, 0.23794980347156525, 0.2765026092529297, 1.1502394676208496, 3.1427478790283203, 0.4758231043815613, 0.7497978806495667, 2.1529078483581543, 1.1538265943527222, 2.186189651489258, 1.3009912967681885, 3.6401891708374023, 0.6474858522415161, 1.5081056356430054], 'accuracy': [0.6382978558540344, 0.3510638177394867, 0.588652491569519, 0.6808510422706604, 0.44680851697921753, 0.6879432797431946, 0.741134762763977, 0.39007091522216797, 0.6879432797431946, 0.7198581695556641, 0.758865237236023, 0.5709219574928284, 0.7198581695556641, 0.783687949180603, 0.6134752035140991, 0.76241135597229, 0.7907801270484924, 0.6773049831390381, 0.7553191781044006, 0.7907801270484924, 0.6276595592498779, 0.7553191781044006, 0.8156028389930725, 0.673758864402771, 0.7730496525764465, 0.8439716100692749, 0.7056737542152405, 0.7730496525764465, 0.8439716100692749, 0.7021276354789734, 0.7765957713127136, 0.7482269406318665, 0.7695035338401794, 0.76241135597229, 0.7730496525764465, 0.8014184236526489, 0.8014184236526489, 0.9007092118263245, 0.914893627166748, 0.741134762763977, 0.7943262457847595, 0.8617021441459656, 0.826241135597229, 0.8120567202568054, 0.76241135597229, 0.7907801270484924, 0.6985815763473511, 0.783687949180603, 0.868794322013855, 0.7695035338401794], 'precision_35': [0.6382978558540344, 0.3510638177394867, 0.588652491569519, 0.6808510422706604, 0.44680851697921753, 0.6879432797431946, 0.741134762763977, 0.39007091522216797, 0.6879432797431946, 0.7198581695556641, 0.758865237236023, 0.5709219574928284, 0.7198581695556641, 0.783687949180603, 0.6134752035140991, 0.76241135597229, 0.7907801270484924, 0.6773049831390381, 0.7553191781044006, 0.7907801270484924, 0.6276595592498779, 0.7553191781044006, 0.8156028389930725, 0.673758864402771, 0.7730496525764465, 0.8439716100692749, 0.7056737542152405, 0.7730496525764465, 0.8439716100692749, 0.7021276354789734, 0.7765957713127136, 0.7482269406318665, 0.7695035338401794, 0.76241135597229, 0.7730496525764465, 0.8014184236526489, 0.8014184236526489, 0.9007092118263245, 0.914893627166748, 0.741134762763977, 0.7943262457847595, 0.8617021441459656, 0.826241135597229, 0.8120567202568054, 0.76241135597229, 0.7907801270484924, 0.6985815763473511, 0.783687949180603, 0.868794322013855, 0.7695035338401794], 'recall_35': [0.6382978558540344, 0.3510638177394867, 0.588652491569519, 0.6808510422706604, 0.44680851697921753, 0.6879432797431946, 0.741134762763977, 0.39007091522216797, 0.6879432797431946, 0.7198581695556641, 0.758865237236023, 0.5709219574928284, 0.7198581695556641, 0.783687949180603, 0.6134752035140991, 0.76241135597229, 0.7907801270484924, 0.6773049831390381, 0.7553191781044006, 0.7907801270484924, 0.6276595592498779, 0.7553191781044006, 0.8156028389930725, 0.673758864402771, 0.7730496525764465, 0.8439716100692749, 0.7056737542152405, 0.7730496525764465, 0.8439716100692749, 0.7021276354789734, 0.7765957713127136, 0.7482269406318665, 0.7695035338401794, 0.76241135597229, 0.7730496525764465, 0.8014184236526489, 0.8014184236526489, 0.9007092118263245, 0.914893627166748, 0.741134762763977, 0.7943262457847595, 0.8617021441459656, 0.826241135597229, 0.8120567202568054, 0.76241135597229, 0.7907801270484924, 0.6985815763473511, 0.783687949180603, 0.868794322013855, 0.7695035338401794]}\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f88c6f6f9e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Fold 4 - Precison: 0.7337073398784478 - Recall: 0.9565217391304348%\n",
      "Shape of train set: (282, 10020)\n",
      "Shape of y: (282, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "Shape of validation set: (31, 10020)\n",
      "{'loss': [5.301913738250732, 29.386518478393555, 66.49966430664062, 20.949359893798828, 6.635838985443115, 17.312469482421875, 3.5040087699890137, 15.619009017944336, 13.456180572509766, 3.8122315406799316, 8.13048267364502, 11.187124252319336, 3.615729570388794, 4.999382495880127, 9.755850791931152, 3.184000015258789, 3.880000591278076, 8.798354148864746, 2.706212043762207, 3.1887478828430176, 7.9768524169921875, 2.2919461727142334, 3.0652925968170166, 7.2681756019592285, 1.7199349403381348, 3.5702314376831055, 6.637542724609375, 1.7971735000610352, 3.5120561122894287, 6.425045490264893, 1.3273895978927612, 3.0316708087921143, 4.931371212005615, 0.5698677897453308, 2.201477527618408, 4.81189489364624, 0.4105856418609619, 2.204218864440918, 4.763605117797852, 0.27724573016166687, 1.3179500102996826, 3.684070348739624, 0.34832286834716797, 0.9696892499923706, 3.0400211811065674, 5.266724109649658, 0.48471230268478394, 1.9997409582138062, 4.6225810050964355, 0.26797059178352356], 'accuracy': [0.6560283899307251, 0.5496453642845154, 0.3085106313228607, 0.695035457611084, 0.4964539110660553, 0.695035457611084, 0.7446808218955994, 0.40780141949653625, 0.695035457611084, 0.7695035338401794, 0.4893617033958435, 0.73758864402771, 0.7695035338401794, 0.5567376017570496, 0.7517730593681335, 0.7943262457847595, 0.5957446694374084, 0.7517730593681335, 0.8191489577293396, 0.6241135001182556, 0.76241135597229, 0.8297872543334961, 0.6241135001182556, 0.758865237236023, 0.8404255509376526, 0.6418439745903015, 0.7695035338401794, 0.8404255509376526, 0.6347517967224121, 0.7659574747085571, 0.8439716100692749, 0.673758864402771, 0.7872340679168701, 0.890070915222168, 0.7021276354789734, 0.7907801270484924, 0.9042553305625916, 0.7269503474235535, 0.8014184236526489, 0.9184397459030151, 0.7872340679168701, 0.804964542388916, 0.9042553305625916, 0.8581560254096985, 0.6595744490623474, 0.7872340679168701, 0.9078013896942139, 0.7021276354789734, 0.7907801270484924, 0.9290780425071716], 'precision_36': [0.6560283899307251, 0.5496453642845154, 0.3085106313228607, 0.695035457611084, 0.4964539110660553, 0.695035457611084, 0.7446808218955994, 0.40780141949653625, 0.695035457611084, 0.7695035338401794, 0.4893617033958435, 0.73758864402771, 0.7695035338401794, 0.5567376017570496, 0.7517730593681335, 0.7943262457847595, 0.5957446694374084, 0.7517730593681335, 0.8191489577293396, 0.6241135001182556, 0.76241135597229, 0.8297872543334961, 0.6241135001182556, 0.758865237236023, 0.8404255509376526, 0.6418439745903015, 0.7695035338401794, 0.8404255509376526, 0.6347517967224121, 0.7659574747085571, 0.8439716100692749, 0.673758864402771, 0.7872340679168701, 0.890070915222168, 0.7021276354789734, 0.7907801270484924, 0.9042553305625916, 0.7269503474235535, 0.8014184236526489, 0.9184397459030151, 0.7872340679168701, 0.804964542388916, 0.9042553305625916, 0.8581560254096985, 0.6595744490623474, 0.7872340679168701, 0.9078013896942139, 0.7021276354789734, 0.7907801270484924, 0.9290780425071716], 'recall_36': [0.6560283899307251, 0.5496453642845154, 0.3085106313228607, 0.695035457611084, 0.4964539110660553, 0.695035457611084, 0.7446808218955994, 0.40780141949653625, 0.695035457611084, 0.7695035338401794, 0.4893617033958435, 0.73758864402771, 0.7695035338401794, 0.5567376017570496, 0.7517730593681335, 0.7943262457847595, 0.5957446694374084, 0.7517730593681335, 0.8191489577293396, 0.6241135001182556, 0.76241135597229, 0.8297872543334961, 0.6241135001182556, 0.758865237236023, 0.8404255509376526, 0.6418439745903015, 0.7695035338401794, 0.8404255509376526, 0.6347517967224121, 0.7659574747085571, 0.8439716100692749, 0.673758864402771, 0.7872340679168701, 0.890070915222168, 0.7021276354789734, 0.7907801270484924, 0.9042553305625916, 0.7269503474235535, 0.8014184236526489, 0.9184397459030151, 0.7872340679168701, 0.804964542388916, 0.9042553305625916, 0.8581560254096985, 0.6595744490623474, 0.7872340679168701, 0.9078013896942139, 0.7021276354789734, 0.7907801270484924, 0.9290780425071716]}\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f88b2cabef0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 5 - Precison: 0.6171072843398819 - Recall: 0.6842105263157895%\n",
      "Shape of train set: (282, 10020)\n",
      "Shape of y: (282, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 6 ...\n",
      "Shape of validation set: (31, 10020)\n",
      "{'loss': [9.177539825439453, 90.14254760742188, 4.313948154449463, 11.573719024658203, 3.3259193897247314, 9.762743949890137, 3.5576813220977783, 3.6904168128967285, 6.186521053314209, 2.6690146923065186, 0.7528555393218994, 1.243870496749878, 3.4823062419891357, 4.503049373626709, 1.499423623085022, 1.3889906406402588, 3.0899147987365723, 0.812991201877594, 1.5587522983551025, 3.3498356342315674, 0.9152586460113525, 1.2607368230819702, 2.7474141120910645, 0.5761404633522034, 1.8234446048736572, 3.4911577701568604, 0.7777765393257141, 1.4505672454833984, 3.2059476375579834, 0.9764569997787476, 0.9884828329086304, 2.639887809753418, 0.5422102212905884, 0.892590343952179, 2.3258988857269287, 0.7742834091186523, 1.0209157466888428, 3.1957833766937256, 0.6793197989463806, 1.1673173904418945, 2.6341376304626465, 0.6024134755134583, 1.0804126262664795, 2.3213040828704834, 0.44571036100387573, 0.762153685092926, 1.820683240890503, 0.25392988324165344, 0.2971261143684387, 0.9578549265861511], 'accuracy': [0.6276595592498779, 0.3617021143436432, 0.5390070676803589, 0.6843971610069275, 0.41134750843048096, 0.6843971610069275, 0.7517730593681335, 0.5390070676803589, 0.741134762763977, 0.7517730593681335, 0.73758864402771, 0.7695035338401794, 0.5106382966041565, 0.7198581695556641, 0.783687949180603, 0.6453900933265686, 0.7695035338401794, 0.8333333134651184, 0.6489361524581909, 0.7695035338401794, 0.8226950168609619, 0.6843971610069275, 0.7801418304443359, 0.8368794322013855, 0.609929084777832, 0.76241135597229, 0.8333333134651184, 0.6560283899307251, 0.783687949180603, 0.8191489577293396, 0.6808510422706604, 0.7695035338401794, 0.8368794322013855, 0.7659574747085571, 0.7943262457847595, 0.8333333134651184, 0.7234042286872864, 0.783687949180603, 0.8404255509376526, 0.7092198729515076, 0.8085106611251831, 0.8510638475418091, 0.6879432797431946, 0.804964542388916, 0.8758864998817444, 0.7765957713127136, 0.8191489577293396, 0.9007092118263245, 0.8723404407501221, 0.8368794322013855], 'precision_37': [0.6276595592498779, 0.3617021143436432, 0.5390070676803589, 0.6843971610069275, 0.41134750843048096, 0.6843971610069275, 0.7517730593681335, 0.5390070676803589, 0.741134762763977, 0.7517730593681335, 0.73758864402771, 0.7695035338401794, 0.5106382966041565, 0.7198581695556641, 0.783687949180603, 0.6453900933265686, 0.7695035338401794, 0.8333333134651184, 0.6489361524581909, 0.7695035338401794, 0.8226950168609619, 0.6843971610069275, 0.7801418304443359, 0.8368794322013855, 0.609929084777832, 0.76241135597229, 0.8333333134651184, 0.6560283899307251, 0.783687949180603, 0.8191489577293396, 0.6808510422706604, 0.7695035338401794, 0.8368794322013855, 0.7659574747085571, 0.7943262457847595, 0.8333333134651184, 0.7234042286872864, 0.783687949180603, 0.8404255509376526, 0.7092198729515076, 0.8085106611251831, 0.8510638475418091, 0.6879432797431946, 0.804964542388916, 0.8758864998817444, 0.7765957713127136, 0.8191489577293396, 0.9007092118263245, 0.8723404407501221, 0.8368794322013855], 'recall_37': [0.6276595592498779, 0.3617021143436432, 0.5390070676803589, 0.6843971610069275, 0.41134750843048096, 0.6843971610069275, 0.7517730593681335, 0.5390070676803589, 0.741134762763977, 0.7517730593681335, 0.73758864402771, 0.7695035338401794, 0.5106382966041565, 0.7198581695556641, 0.783687949180603, 0.6453900933265686, 0.7695035338401794, 0.8333333134651184, 0.6489361524581909, 0.7695035338401794, 0.8226950168609619, 0.6843971610069275, 0.7801418304443359, 0.8368794322013855, 0.609929084777832, 0.76241135597229, 0.8333333134651184, 0.6560283899307251, 0.783687949180603, 0.8191489577293396, 0.6808510422706604, 0.7695035338401794, 0.8368794322013855, 0.7659574747085571, 0.7943262457847595, 0.8333333134651184, 0.7234042286872864, 0.783687949180603, 0.8404255509376526, 0.7092198729515076, 0.8085106611251831, 0.8510638475418091, 0.6879432797431946, 0.804964542388916, 0.8758864998817444, 0.7765957713127136, 0.8191489577293396, 0.9007092118263245, 0.8723404407501221, 0.8368794322013855]}\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f88acb2c440> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Fold 6 - Precison: 0.7875366568914957 - Recall: 0.4090909090909091%\n",
      "Shape of train set: (282, 10020)\n",
      "Shape of y: (282, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 7 ...\n",
      "Shape of validation set: (31, 10020)\n",
      "{'loss': [22.24107551574707, 131.91973876953125, 4.652421474456787, 11.526435852050781, 27.715890884399414, 6.828553199768066, 18.615102767944336, 17.28653335571289, 5.859803199768066, 5.395294189453125, 11.655725479125977, 3.8463871479034424, 4.993592739105225, 10.190401077270508, 3.6003053188323975, 3.1780638694763184, 8.579179763793945, 2.635603666305542, 3.4198601245880127, 7.922551155090332, 2.3801212310791016, 2.834646463394165, 6.857501983642578, 1.7628735303878784, 3.338780164718628, 6.916040420532227, 1.798554539680481, 2.640835762023926, 6.231626033782959, 1.434790015220642, 2.6826720237731934, 5.972437858581543, 1.4894193410873413, 2.3481814861297607, 5.104970455169678, 1.0159809589385986, 2.499634265899658, 5.4971923828125, 0.9668499827384949, 3.4064207077026367, 6.120072841644287, 1.1618105173110962, 1.8163127899169922, 4.385706424713135, 0.5305056571960449, 2.750011444091797, 5.077458381652832, 0.9627787470817566, 2.2813570499420166, 4.06866455078125], 'accuracy': [0.6631205677986145, 0.3191489279270172, 0.5815602540969849, 0.4893617033958435, 0.6808510422706604, 0.609929084777832, 0.43617022037506104, 0.6808510422706604, 0.7517730593681335, 0.5141844153404236, 0.716312050819397, 0.76241135597229, 0.5177304744720459, 0.7340425252914429, 0.7765957713127136, 0.5815602540969849, 0.7482269406318665, 0.7943262457847595, 0.588652491569519, 0.7482269406318665, 0.8120567202568054, 0.6205673813819885, 0.7659574747085571, 0.8333333134651184, 0.6241135001182556, 0.7695035338401794, 0.8333333134651184, 0.6241135001182556, 0.7695035338401794, 0.847517728805542, 0.6276595592498779, 0.7730496525764465, 0.8439716100692749, 0.6631205677986145, 0.7801418304443359, 0.8546099066734314, 0.652482271194458, 0.7730496525764465, 0.8404255509376526, 0.6418439745903015, 0.7517730593681335, 0.8723404407501221, 0.6914893388748169, 0.783687949180603, 0.8865247964859009, 0.6560283899307251, 0.7801418304443359, 0.8546099066734314, 0.7304964661598206, 0.8085106611251831], 'precision_38': [0.6631205677986145, 0.3191489279270172, 0.5815602540969849, 0.4893617033958435, 0.6808510422706604, 0.609929084777832, 0.43617022037506104, 0.6808510422706604, 0.7517730593681335, 0.5141844153404236, 0.716312050819397, 0.76241135597229, 0.5177304744720459, 0.7340425252914429, 0.7765957713127136, 0.5815602540969849, 0.7482269406318665, 0.7943262457847595, 0.588652491569519, 0.7482269406318665, 0.8120567202568054, 0.6205673813819885, 0.7659574747085571, 0.8333333134651184, 0.6241135001182556, 0.7695035338401794, 0.8333333134651184, 0.6241135001182556, 0.7695035338401794, 0.847517728805542, 0.6276595592498779, 0.7730496525764465, 0.8439716100692749, 0.6631205677986145, 0.7801418304443359, 0.8546099066734314, 0.652482271194458, 0.7730496525764465, 0.8404255509376526, 0.6418439745903015, 0.7517730593681335, 0.8723404407501221, 0.6914893388748169, 0.783687949180603, 0.8865247964859009, 0.6560283899307251, 0.7801418304443359, 0.8546099066734314, 0.7304964661598206, 0.8085106611251831], 'recall_38': [0.6631205677986145, 0.3191489279270172, 0.5815602540969849, 0.4893617033958435, 0.6808510422706604, 0.609929084777832, 0.43617022037506104, 0.6808510422706604, 0.7517730593681335, 0.5141844153404236, 0.716312050819397, 0.76241135597229, 0.5177304744720459, 0.7340425252914429, 0.7765957713127136, 0.5815602540969849, 0.7482269406318665, 0.7943262457847595, 0.588652491569519, 0.7482269406318665, 0.8120567202568054, 0.6205673813819885, 0.7659574747085571, 0.8333333134651184, 0.6241135001182556, 0.7695035338401794, 0.8333333134651184, 0.6241135001182556, 0.7695035338401794, 0.847517728805542, 0.6276595592498779, 0.7730496525764465, 0.8439716100692749, 0.6631205677986145, 0.7801418304443359, 0.8546099066734314, 0.652482271194458, 0.7730496525764465, 0.8404255509376526, 0.6418439745903015, 0.7517730593681335, 0.8723404407501221, 0.6914893388748169, 0.783687949180603, 0.8865247964859009, 0.6560283899307251, 0.7801418304443359, 0.8546099066734314, 0.7304964661598206, 0.8085106611251831]}\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f88ad38fb00> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 7 - Precison: 0.7578952459254243 - Recall: 0.9565217391304348%\n",
      "Shape of train set: (282, 10020)\n",
      "Shape of y: (282, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 8 ...\n",
      "Shape of validation set: (31, 10020)\n",
      "{'loss': [17.178993225097656, 53.363304138183594, 22.38347816467285, 7.860077857971191, 18.601268768310547, 17.766311645507812, 8.692391395568848, 2.435920238494873, 8.014320373535156, 1.5901269912719727, 7.063347339630127, 10.80043888092041, 4.359669208526611, 2.883441686630249, 6.878572940826416, 1.4069846868515015, 3.6723196506500244, 8.779068946838379, 2.3028950691223145, 4.280395984649658, 7.217123031616211, 2.3222386837005615, 2.6367528438568115, 5.216519355773926, 1.0613425970077515, 2.6704204082489014, 5.5314741134643555, 1.4370871782302856, 2.292494297027588, 4.598260402679443, 0.7863770127296448, 1.9138257503509521, 3.9621949195861816, 0.4776645004749298, 1.26643967628479, 3.560000419616699, 0.31329989433288574, 0.249910369515419, 1.0796318054199219, 3.221281051635742, 5.802637577056885, 1.5563467741012573, 1.4005484580993652, 3.1209511756896973, 0.33542600274086, 0.2670876383781433, 0.5070453882217407, 1.7740213871002197, 5.115293025970459, 0.6673920154571533], 'accuracy': [0.3333333432674408, 0.6843971610069275, 0.6843971610069275, 0.5780141949653625, 0.3794326186180115, 0.6843971610069275, 0.7304964661598206, 0.6134752035140991, 0.7446808218955994, 0.6808510422706604, 0.5106382966041565, 0.7198581695556641, 0.758865237236023, 0.6170212626457214, 0.73758864402771, 0.76241135597229, 0.585106372833252, 0.7234042286872864, 0.7730496525764465, 0.5602836608886719, 0.7304964661598206, 0.7907801270484924, 0.6347517967224121, 0.76241135597229, 0.8226950168609619, 0.6418439745903015, 0.76241135597229, 0.8191489577293396, 0.6489361524581909, 0.7730496525764465, 0.8546099066734314, 0.6914893388748169, 0.7801418304443359, 0.8865247964859009, 0.7659574747085571, 0.783687949180603, 0.911347508430481, 0.9007092118263245, 0.8333333134651184, 0.563829779624939, 0.741134762763977, 0.8014184236526489, 0.741134762763977, 0.8014184236526489, 0.911347508430481, 0.9042553305625916, 0.8936170339584351, 0.7198581695556641, 0.7730496525764465, 0.8723404407501221], 'precision_39': [0.3333333432674408, 0.6843971610069275, 0.6843971610069275, 0.5780141949653625, 0.3794326186180115, 0.6843971610069275, 0.7304964661598206, 0.6134752035140991, 0.7446808218955994, 0.6808510422706604, 0.5106382966041565, 0.7198581695556641, 0.758865237236023, 0.6170212626457214, 0.73758864402771, 0.76241135597229, 0.585106372833252, 0.7234042286872864, 0.7730496525764465, 0.5602836608886719, 0.7304964661598206, 0.7907801270484924, 0.6347517967224121, 0.76241135597229, 0.8226950168609619, 0.6418439745903015, 0.76241135597229, 0.8191489577293396, 0.6489361524581909, 0.7730496525764465, 0.8546099066734314, 0.6914893388748169, 0.7801418304443359, 0.8865247964859009, 0.7659574747085571, 0.783687949180603, 0.911347508430481, 0.9007092118263245, 0.8333333134651184, 0.563829779624939, 0.741134762763977, 0.8014184236526489, 0.741134762763977, 0.8014184236526489, 0.911347508430481, 0.9042553305625916, 0.8936170339584351, 0.7198581695556641, 0.7730496525764465, 0.8723404407501221], 'recall_39': [0.3333333432674408, 0.6843971610069275, 0.6843971610069275, 0.5780141949653625, 0.3794326186180115, 0.6843971610069275, 0.7304964661598206, 0.6134752035140991, 0.7446808218955994, 0.6808510422706604, 0.5106382966041565, 0.7198581695556641, 0.758865237236023, 0.6170212626457214, 0.73758864402771, 0.76241135597229, 0.585106372833252, 0.7234042286872864, 0.7730496525764465, 0.5602836608886719, 0.7304964661598206, 0.7907801270484924, 0.6347517967224121, 0.76241135597229, 0.8226950168609619, 0.6418439745903015, 0.76241135597229, 0.8191489577293396, 0.6489361524581909, 0.7730496525764465, 0.8546099066734314, 0.6914893388748169, 0.7801418304443359, 0.8865247964859009, 0.7659574747085571, 0.783687949180603, 0.911347508430481, 0.9007092118263245, 0.8333333134651184, 0.563829779624939, 0.741134762763977, 0.8014184236526489, 0.741134762763977, 0.8014184236526489, 0.911347508430481, 0.9042553305625916, 0.8936170339584351, 0.7198581695556641, 0.7730496525764465, 0.8723404407501221]}\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f887c6274d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Fold 8 - Precison: 0.7622800586510264 - Recall: 0.3181818181818182%\n",
      "Shape of train set: (282, 10020)\n",
      "Shape of y: (282, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 9 ...\n",
      "Shape of validation set: (31, 10020)\n",
      "{'loss': [22.503007888793945, 117.48268127441406, 5.481495380401611, 30.58106803894043, 3.653019905090332, 18.48642349243164, 13.722098350524902, 2.2851946353912354, 9.671390533447266, 11.073265075683594, 2.553772449493408, 7.373686790466309, 8.97211742401123, 2.2478179931640625, 5.3828125, 7.551213264465332, 1.6559593677520752, 4.232172012329102, 6.939353942871094, 1.388141393661499, 4.116809844970703, 6.613546371459961, 1.2446094751358032, 3.5375850200653076, 6.681276798248291, 1.2686142921447754, 2.603816032409668, 5.619369029998779, 0.7248944640159607, 1.2940436601638794, 3.927027940750122, 0.6960406303405762, 2.432223320007324, 2.9065537452697754, 6.407992839813232, 0.9499929547309875, 3.763368844985962, 5.803196907043457, 1.2217406034469604, 2.713165283203125, 4.81079626083374, 0.7706507444381714, 1.4193506240844727, 3.5593035221099854, 0.559281587600708, 1.264766812324524, 2.3065459728240967, 4.400817394256592, 0.47760170698165894, 0.8218995332717896], 'accuracy': [0.6808510422706604, 0.3191489279270172, 0.4609929025173187, 0.6808510422706604, 0.6382978558540344, 0.3758865296840668, 0.6808510422706604, 0.695035457611084, 0.478723406791687, 0.695035457611084, 0.7695035338401794, 0.5460993051528931, 0.7234042286872864, 0.7695035338401794, 0.585106372833252, 0.73758864402771, 0.7907801270484924, 0.631205677986145, 0.7553191781044006, 0.804964542388916, 0.6241135001182556, 0.76241135597229, 0.8120567202568054, 0.6595744490623474, 0.76241135597229, 0.8226950168609619, 0.6843971610069275, 0.7765957713127136, 0.8510638475418091, 0.7801418304443359, 0.7907801270484924, 0.8510638475418091, 0.8191489577293396, 0.6418439745903015, 0.7482269406318665, 0.8156028389930725, 0.631205677986145, 0.783687949180603, 0.8510638475418091, 0.6666666865348816, 0.7872340679168701, 0.8758864998817444, 0.76241135597229, 0.8014184236526489, 0.8546099066734314, 0.8617021441459656, 0.695035457611084, 0.7872340679168701, 0.9042553305625916, 0.8156028389930725], 'precision_40': [0.6808510422706604, 0.3191489279270172, 0.4609929025173187, 0.6808510422706604, 0.6382978558540344, 0.3758865296840668, 0.6808510422706604, 0.695035457611084, 0.478723406791687, 0.695035457611084, 0.7695035338401794, 0.5460993051528931, 0.7234042286872864, 0.7695035338401794, 0.585106372833252, 0.73758864402771, 0.7907801270484924, 0.631205677986145, 0.7553191781044006, 0.804964542388916, 0.6241135001182556, 0.76241135597229, 0.8120567202568054, 0.6595744490623474, 0.76241135597229, 0.8226950168609619, 0.6843971610069275, 0.7765957713127136, 0.8510638475418091, 0.7801418304443359, 0.7907801270484924, 0.8510638475418091, 0.8191489577293396, 0.6418439745903015, 0.7482269406318665, 0.8156028389930725, 0.631205677986145, 0.783687949180603, 0.8510638475418091, 0.6666666865348816, 0.7872340679168701, 0.8758864998817444, 0.76241135597229, 0.8014184236526489, 0.8546099066734314, 0.8617021441459656, 0.695035457611084, 0.7872340679168701, 0.9042553305625916, 0.8156028389930725], 'recall_40': [0.6808510422706604, 0.3191489279270172, 0.4609929025173187, 0.6808510422706604, 0.6382978558540344, 0.3758865296840668, 0.6808510422706604, 0.695035457611084, 0.478723406791687, 0.695035457611084, 0.7695035338401794, 0.5460993051528931, 0.7234042286872864, 0.7695035338401794, 0.585106372833252, 0.73758864402771, 0.7907801270484924, 0.631205677986145, 0.7553191781044006, 0.804964542388916, 0.6241135001182556, 0.76241135597229, 0.8120567202568054, 0.6595744490623474, 0.76241135597229, 0.8226950168609619, 0.6843971610069275, 0.7765957713127136, 0.8510638475418091, 0.7801418304443359, 0.7907801270484924, 0.8510638475418091, 0.8191489577293396, 0.6418439745903015, 0.7482269406318665, 0.8156028389930725, 0.631205677986145, 0.783687949180603, 0.8510638475418091, 0.6666666865348816, 0.7872340679168701, 0.8758864998817444, 0.76241135597229, 0.8014184236526489, 0.8546099066734314, 0.8617021441459656, 0.695035457611084, 0.7872340679168701, 0.9042553305625916, 0.8156028389930725]}\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f88873cd9e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "> Fold 9 - Precison: 0.7256855443246119 - Recall: 0.9130434782608695%\n",
      "Shape of train set: (282, 10020)\n",
      "Shape of y: (282, 2)\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 10 ...\n",
      "Shape of validation set: (31, 10020)\n",
      "{'loss': [24.309913635253906, 196.88929748535156, 5.8822479248046875, 17.597639083862305, 12.265581130981445, 25.322694778442383, 10.84796142578125, 8.059218406677246, 19.93463134765625, 10.332364082336426, 2.3293087482452393, 4.155832290649414, 12.60787296295166, 3.9978978633880615, 7.772399425506592, 14.777726173400879, 6.427188396453857, 2.5190634727478027, 7.769146919250488, 1.263776421546936, 2.445807933807373, 10.024689674377441, 13.08029842376709, 4.999500274658203, 2.7374119758605957, 7.583362102508545, 1.069534182548523, 4.294061183929443, 11.19492244720459, 3.930692672729492, 3.148618459701538, 8.532306671142578, 2.0474660396575928, 4.9690117835998535, 10.982182502746582, 4.172586917877197, 1.6776001453399658, 5.502190113067627, 0.6401140689849854, 1.0555633306503296, 4.997995853424072, 10.026390075683594, 3.183279037475586, 2.492591142654419, 6.951760768890381, 1.1351242065429688, 4.868071556091309, 9.181330680847168, 3.055206775665283, 1.405832052230835], 'accuracy': [0.6879432797431946, 0.304964542388916, 0.563829779624939, 0.695035457611084, 0.3191489279270172, 0.695035457611084, 0.7340425252914429, 0.40780141949653625, 0.695035457611084, 0.758865237236023, 0.7340425252914429, 0.6170212626457214, 0.7269503474235535, 0.783687949180603, 0.4751773178577423, 0.7021276354789734, 0.7872340679168701, 0.631205677986145, 0.7553191781044006, 0.7553191781044006, 0.8120567202568054, 0.4716311991214752, 0.716312050819397, 0.7943262457847595, 0.7198581695556641, 0.7765957713127136, 0.847517728805542, 0.6063829660415649, 0.7553191781044006, 0.8191489577293396, 0.6843971610069275, 0.7765957713127136, 0.847517728805542, 0.5531914830207825, 0.7482269406318665, 0.8226950168609619, 0.7907801270484924, 0.8191489577293396, 0.8581560254096985, 0.8794326186180115, 0.588652491569519, 0.76241135597229, 0.8368794322013855, 0.716312050819397, 0.7872340679168701, 0.8723404407501221, 0.5921986103057861, 0.7695035338401794, 0.8404255509376526, 0.8226950168609619], 'precision_41': [0.6879432797431946, 0.304964542388916, 0.563829779624939, 0.695035457611084, 0.3191489279270172, 0.695035457611084, 0.7340425252914429, 0.40780141949653625, 0.695035457611084, 0.758865237236023, 0.7340425252914429, 0.6170212626457214, 0.7269503474235535, 0.783687949180603, 0.4751773178577423, 0.7021276354789734, 0.7872340679168701, 0.631205677986145, 0.7553191781044006, 0.7553191781044006, 0.8120567202568054, 0.4716311991214752, 0.716312050819397, 0.7943262457847595, 0.7198581695556641, 0.7765957713127136, 0.847517728805542, 0.6063829660415649, 0.7553191781044006, 0.8191489577293396, 0.6843971610069275, 0.7765957713127136, 0.847517728805542, 0.5531914830207825, 0.7482269406318665, 0.8226950168609619, 0.7907801270484924, 0.8191489577293396, 0.8581560254096985, 0.8794326186180115, 0.588652491569519, 0.76241135597229, 0.8368794322013855, 0.716312050819397, 0.7872340679168701, 0.8723404407501221, 0.5921986103057861, 0.7695035338401794, 0.8404255509376526, 0.8226950168609619], 'recall_41': [0.6879432797431946, 0.304964542388916, 0.563829779624939, 0.695035457611084, 0.3191489279270172, 0.695035457611084, 0.7340425252914429, 0.40780141949653625, 0.695035457611084, 0.758865237236023, 0.7340425252914429, 0.6170212626457214, 0.7269503474235535, 0.783687949180603, 0.4751773178577423, 0.7021276354789734, 0.7872340679168701, 0.631205677986145, 0.7553191781044006, 0.7553191781044006, 0.8120567202568054, 0.4716311991214752, 0.716312050819397, 0.7943262457847595, 0.7198581695556641, 0.7765957713127136, 0.847517728805542, 0.6063829660415649, 0.7553191781044006, 0.8191489577293396, 0.6843971610069275, 0.7765957713127136, 0.847517728805542, 0.5531914830207825, 0.7482269406318665, 0.8226950168609619, 0.7907801270484924, 0.8191489577293396, 0.8581560254096985, 0.8794326186180115, 0.588652491569519, 0.76241135597229, 0.8368794322013855, 0.716312050819397, 0.7872340679168701, 0.8723404407501221, 0.5921986103057861, 0.7695035338401794, 0.8404255509376526, 0.8226950168609619]}\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f88da653cb0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Fold 10 - Precison: 0.6412806209071066 - Recall: 0.9473684210526315%\n",
      "------------------------------------------------------------------------\n",
      "> Precison: 0.7023702764588535 (+- 0.06146396945902786)\n",
      "> Recall: 0.7995943415851883\n",
      "------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "num_folds = 10\n",
    "# Define per-fold score containers <-- these are new\n",
    "acc_per_fold = []\n",
    "loss_per_fold = []\n",
    "\n",
    "# Define the K-fold Cross Validator\n",
    "kfold = KFold(n_splits=num_folds, shuffle=True)\n",
    "\n",
    "inputs = result\n",
    "targets = y\n",
    "\n",
    "print('# inputs data samples:', inputs.shape[0])\n",
    "print('# targets data samples:', targets.shape[0])\n",
    "\n",
    "# K-fold Cross Validation model evaluation\n",
    "fold_no = 1\n",
    "for train, test in kfold.split(inputs, targets):\n",
    "    \n",
    "#     tk = Tokenizer(num_words=NB_WORDS,\n",
    "#                filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
    "#                lower=True,\n",
    "#                split=\" \")\n",
    "#     tk.fit_on_texts(inputs.iloc[train])\n",
    "    \n",
    "#     X_train_seq = tk.texts_to_sequences(inputs.iloc[train])\n",
    "#     X_test_seq = tk.texts_to_sequences(inputs.iloc[test])\n",
    "    \n",
    "    \n",
    "    X_train_oh = inputs.iloc[train]\n",
    "    X_test_oh = inputs.iloc[test]\n",
    "    \n",
    "    print('Shape of train set:',X_train_oh.shape)\n",
    "    \n",
    "    \n",
    "    y_train_le = targets.iloc[train]\n",
    "    y_train_oh = to_categorical(y_train_le)\n",
    "    \n",
    "    \n",
    "    y_test_le = targets.iloc[test]\n",
    "    y_test_oh = to_categorical(y_test_le)\n",
    "\n",
    "\n",
    "    \n",
    "    print('Shape of y:',y_train_oh.shape)\n",
    "\n",
    "    # Define the model architecture\n",
    "    base_model = models.Sequential()\n",
    "    base_model.add(layers.Dense(128, activation='relu', input_shape=(10020,)))\n",
    "    base_model.add(layers.Dense(64, activation='relu'))\n",
    "    base_model.add(layers.Dense(2, activation='softmax'))\n",
    "\n",
    "    # Compile the model\n",
    "    base_model.compile(optimizer='rmsprop'\n",
    "                  , loss='categorical_crossentropy'\n",
    "                  , metrics=['accuracy',tf.keras.metrics.Precision(),tf.keras.metrics.Recall()])\n",
    "    \n",
    "\n",
    "    # Generate a print\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'Training for fold {fold_no} ...')\n",
    "    print('Shape of validation set:',X_test_oh.shape)\n",
    "    \n",
    "    # Fit data to model\n",
    "    history = base_model.fit(X_train_oh\n",
    "                       ,y_train_oh\n",
    "                       , epochs=50\n",
    "                       , batch_size=BATCH_SIZE\n",
    "                       , verbose=0)\n",
    "    print(history.history)\n",
    "    \n",
    "\n",
    "    # Generate generalization metrics\n",
    "    from sklearn.metrics import classification_report\n",
    "    y_pred = base_model.predict_classes(X_test_oh)\n",
    "    \n",
    "    average_recall = recall_score(y_test_le, y_pred)\n",
    "    average_precision = average_precision_score(y_test_le, y_pred)\n",
    "    print(f'> Fold {fold_no} - Precison: {average_precision} - Recall: {average_recall}%')\n",
    "    \n",
    "    acc_per_fold.append(average_precision)\n",
    "    loss_per_fold.append(average_recall)\n",
    "\n",
    "    # Increase fold number\n",
    "    fold_no = fold_no + 1\n",
    "\n",
    "# == Provide average scores ==\n",
    "print('------------------------------------------------------------------------')\n",
    "\n",
    "print(f'> Precison: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "print(f'> Recall: {np.mean(loss_per_fold)}')\n",
    "print('------------------------------------------------------------------------')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier, KerasRegressor\n",
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "\n",
    "base_model = models.Sequential()\n",
    "base_model.add(layers.Dense(128, activation='relu', input_shape=(10020,)))\n",
    "base_model.add(layers.Dense(64, activation='relu'))\n",
    "base_model.add(layers.Dense(2, activation='softmax'))\n",
    "\n",
    "X = result\n",
    "y = y\n",
    "\n",
    "my_model = KerasRegressor(build_fn=basemodel, **sk_params)    \n",
    "my_model.fit(X,y)\n",
    "\n",
    "perm = PermutationImportance(my_model, random_state=1).fit(X,y)\n",
    "eli5.show_weights(perm, feature_names = X.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_metric(history, metric_name):\n",
    "    metric = history.history[metric_name]\n",
    "    val_metric = history.history['val_' + metric_name+'_24']\n",
    "\n",
    "    e = range(1, NB_START_EPOCHS + 1)\n",
    "\n",
    "    plt.plot(e, metric, 'bo', label='Train ' + metric_name)\n",
    "    plt.plot(e, val_metric, 'b', label='Validation ' + metric_name)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.save(\"visual_mlp.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31, 10020)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_oh.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31,)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_le.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31, 10020)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_oh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shape mismatch: objects cannot be broadcast to a single shape",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-117-f54014f284ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Random Forest feature importance via permutation importance w. std. dev.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m plt.bar(range(X.shape[1]), imp_vals[indices],\n\u001b[0;32m---> 18\u001b[0;31m         yerr=std[indices])\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mbar\u001b[0;34m(x, height, width, bottom, align, data, **kwargs)\u001b[0m\n\u001b[1;32m   2455\u001b[0m     return gca().bar(\n\u001b[1;32m   2456\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbottom\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbottom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malign\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malign\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2457\u001b[0;31m         **({\"data\": data} if data is not None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1808\u001b[0m                         \u001b[0;34m\"the Matplotlib list!)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabel_namer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                         RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1810\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1812\u001b[0m         inner.__doc__ = _add_data_doc(inner.__doc__,\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mbar\u001b[0;34m(self, x, height, width, bottom, align, **kwargs)\u001b[0m\n\u001b[1;32m   2249\u001b[0m         x, height, width, y, linewidth = np.broadcast_arrays(\n\u001b[1;32m   2250\u001b[0m             \u001b[0;31m# Make args iterable too.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2251\u001b[0;31m             np.atleast_1d(x), height, width, y, linewidth)\n\u001b[0m\u001b[1;32m   2252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2253\u001b[0m         \u001b[0;31m# Now that units have been converted, set the tick locations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mbroadcast_arrays\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/numpy/lib/stride_tricks.py\u001b[0m in \u001b[0;36mbroadcast_arrays\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_m\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubok\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_m\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m     \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_broadcast_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/numpy/lib/stride_tricks.py\u001b[0m in \u001b[0;36m_broadcast_shape\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0;31m# use the old-iterator because np.nditer does not handle size 0 arrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m     \u001b[0;31m# consistently\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m     \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m     \u001b[0;31m# unfortunately, it cannot handle 32 or more arguments directly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mpos\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m31\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shape mismatch: objects cannot be broadcast to a single shape"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from mlxtend.evaluate import feature_importance_permutation\n",
    "from sklearn.metrics import f1_score\n",
    "imp_vals, imp_all = feature_importance_permutation(\n",
    "    predict_method= base_model.predict_classes, \n",
    "    X=X_test_oh.values,\n",
    "    y=y_test_le,\n",
    "    metric=f1_score,\n",
    "    num_rounds=10,\n",
    "    seed=1)\n",
    "\n",
    "\n",
    "std = np.std(imp_all, axis=1)\n",
    "indices = np.argsort(imp_vals)[::-1]\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Random Forest feature importance via permutation importance w. std. dev.\")\n",
    "plt.bar(range(X.shape[1]), imp_vals[indices],\n",
    "        yerr=std[indices])\n",
    "plt.xticks(range(X.shape[1]), indices)\n",
    "plt.xlim([-1, X.shape[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15     0\n",
       "23     0\n",
       "25     0\n",
       "27     0\n",
       "36     1\n",
       "39     0\n",
       "47     1\n",
       "51     1\n",
       "79     1\n",
       "107    1\n",
       "128    1\n",
       "130    1\n",
       "154    0\n",
       "165    1\n",
       "178    1\n",
       "183    1\n",
       "190    1\n",
       "195    0\n",
       "210    1\n",
       "214    0\n",
       "225    1\n",
       "235    1\n",
       "252    0\n",
       "271    0\n",
       "273    1\n",
       "293    0\n",
       "329    1\n",
       "337    0\n",
       "370    1\n",
       "384    1\n",
       "392    1\n",
       "Name: attitude, dtype: int64"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_le"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Train data samples: 509\n",
      "# Test data samples: 57\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.video_description, df.Relevancy, test_size=0.1, random_state=37)\n",
    "print('# Train data samples:', X_train.shape[0])\n",
    "print('# Test data samples:', X_test.shape[0])\n",
    "assert X_train.shape[0] == y_train.shape[0]\n",
    "assert X_test.shape[0] == y_test.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting words to numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use the text as input for a model, we first need to convert the tweet's words into tokens, which simply means converting the words to integers that refer to an index in a dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will only keep the most frequent words in the train set.\n",
    "\n",
    "We clean up the text by applying filters and putting the words to lowercase. Words are separated by spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitted tokenizer on 509 documents\n",
      "10000 words in dictionary\n",
      "Top 5 most common words are: [('coronavirus', 624), ('news', 521), ('us', 271), ('follow', 260), ('subscribe', 255), ('channel', 255), ('virus', 239), ('watch', 230), ('5g', 215), ('dr', 215), ('covid', 214), ('twitter', 214), ('video', 211), ('not', 206), ('like', 205), ('facebook', 204), ('19', 201), ('this', 184), ('people', 183), ('playlist', 181)]\n"
     ]
    }
   ],
   "source": [
    "tk = Tokenizer(num_words=NB_WORDS,\n",
    "               filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
    "               lower=True,\n",
    "               split=\" \")\n",
    "tk.fit_on_texts(X_train)\n",
    "\n",
    "print('Fitted tokenizer on {} documents'.format(tk.document_count))\n",
    "print('{} words in dictionary'.format(tk.num_words))\n",
    "print('Top 5 most common words are:', collections.Counter(tk.word_counts).most_common(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After having created the dictionary we can convert the text to a list of integer indexes. This is done with the text_to_sequences method of the Tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"With theories circulating online 5G technology blame COVID-19 pandemic, experts present facts behind claims. Subscribe 7NEWS latest video Â¬Âª  Connect 7NEWS online Visit Â¬Âª  Facebook Â¬Âª  Twitter Â¬Âª  Instagram Â¬Âª  #BreakingNews #coronavirus #COVID19 #7NEWS\" is converted into [2045, 2546, 2547, 3245, 1761, 2548, 1039, 4683, 33, 124, 582, 83, 111, 818, 1, 220, 221, 115, 3246, 32, 120, 1762, 236, 486, 765, 1, 263, 660]\n"
     ]
    }
   ],
   "source": [
    "X_train_seq = tk.texts_to_sequences(X_train)\n",
    "X_test_seq = tk.texts_to_sequences(X_test)\n",
    "\n",
    "print('\"{}\" is converted into {}'.format(X_train[0], X_train_seq[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These integers should now be converted into a one-hot encoded features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_seq(seqs, nb_features = NB_WORDS):\n",
    "    ohs = np.zeros((len(seqs), nb_features))\n",
    "    for i, s in enumerate(seqs):\n",
    "        ohs[i, s] = 1.\n",
    "    return ohs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting the target classes to numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"1\" is converted into 1\n",
      "\"1\" is converted into [0. 1.]\n"
     ]
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "y_train_le = le.fit_transform(y_train)\n",
    "y_test_le = le.transform(y_test)\n",
    "y_train_oh = to_categorical(y_train_le)\n",
    "y_test_oh = to_categorical(y_test_le)\n",
    "\n",
    "print('\"{}\" is converted into {}'.format(y_train[0], y_train_le[0]))\n",
    "print('\"{}\" is converted into {}'.format(y_train_le[0], y_train_oh[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting of a validation set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of validation set: (51, 10000)\n"
     ]
    }
   ],
   "source": [
    "X_train_rest, X_valid, y_train_rest, y_valid = train_test_split(X_train_oh, y_train_oh, test_size=0.1, random_state=37)\n",
    "\n",
    "assert X_valid.shape[0] == y_valid.shape[0]\n",
    "assert X_train_rest.shape[0] == y_train_rest.shape[0]\n",
    "\n",
    "print('Shape of validation set:',X_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Implementation\n",
    "## Baseline model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start with a model with 2 densely connected layers of 64 hidden elements. The input_shape for the first layer is equal to the number of words we allowed in the dictionary and for which we created one-hot-encoded features.\n",
    "\n",
    " The softmax activation function makes sure the three probabilities sum up to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 64)                640064    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 644,354\n",
      "Trainable params: 644,354\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model = models.Sequential()\n",
    "base_model.add(layers.Dense(64, activation='relu', input_shape=(NB_WORDS,)))\n",
    "base_model.add(layers.Dense(64, activation='relu'))\n",
    "base_model.add(layers.Dense(2, activation='softmax'))\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because this project is a multi-class, single-label prediction, we use categorical_crossentropy as the loss function and softmax as the final activation function. We fit the model on the remaining train data and validate on the validation set. We run for a predetermined number of epochs and will see when the model starts to overfit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_model(model):\n",
    "    model.compile(optimizer='rmsprop'\n",
    "                  , loss='categorical_crossentropy'\n",
    "                  , metrics=['accuracy',tf.keras.metrics.Precision(),tf.keras.metrics.Recall()])\n",
    "    \n",
    "    history = model.fit(X_train_rest\n",
    "                       , y_train_rest\n",
    "                       , epochs=NB_START_EPOCHS\n",
    "                       , batch_size=BATCH_SIZE\n",
    "                       , validation_data=(X_valid, y_valid)\n",
    "                       , verbose=0)\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.7070090174674988,\n",
       "  0.5174614787101746,\n",
       "  0.3788684904575348,\n",
       "  0.3041400909423828,\n",
       "  0.25723156332969666,\n",
       "  0.22602522373199463,\n",
       "  0.2032897025346756,\n",
       "  0.1780741959810257,\n",
       "  0.1627146452665329,\n",
       "  0.1489810198545456,\n",
       "  0.13913194835186005,\n",
       "  0.12844568490982056,\n",
       "  0.11971041560173035,\n",
       "  0.11082577705383301,\n",
       "  0.10460763424634933,\n",
       "  0.09958921372890472,\n",
       "  0.09780213981866837,\n",
       "  0.09410517662763596,\n",
       "  0.089164137840271,\n",
       "  0.08444852381944656],\n",
       " 'accuracy': [0.3995633125305176,\n",
       "  0.8253275156021118,\n",
       "  0.8668122291564941,\n",
       "  0.9017467498779297,\n",
       "  0.9366812109947205,\n",
       "  0.9344978332519531,\n",
       "  0.9410480260848999,\n",
       "  0.9454148411750793,\n",
       "  0.9563318490982056,\n",
       "  0.9541484713554382,\n",
       "  0.9563318490982056,\n",
       "  0.9563318490982056,\n",
       "  0.960698664188385,\n",
       "  0.960698664188385,\n",
       "  0.960698664188385,\n",
       "  0.960698664188385,\n",
       "  0.9628821015357971,\n",
       "  0.9628821015357971,\n",
       "  0.9628821015357971,\n",
       "  0.9628821015357971],\n",
       " 'precision': [0.39427313208580017,\n",
       "  0.8253275156021118,\n",
       "  0.8668122291564941,\n",
       "  0.9017467498779297,\n",
       "  0.9366812109947205,\n",
       "  0.9344978332519531,\n",
       "  0.9410480260848999,\n",
       "  0.9454148411750793,\n",
       "  0.9563318490982056,\n",
       "  0.9541484713554382,\n",
       "  0.9563318490982056,\n",
       "  0.9563318490982056,\n",
       "  0.960698664188385,\n",
       "  0.960698664188385,\n",
       "  0.960698664188385,\n",
       "  0.960698664188385,\n",
       "  0.9628821015357971,\n",
       "  0.9628821015357971,\n",
       "  0.9628821015357971,\n",
       "  0.9628821015357971],\n",
       " 'recall': [0.3908296823501587,\n",
       "  0.8253275156021118,\n",
       "  0.8668122291564941,\n",
       "  0.9017467498779297,\n",
       "  0.9366812109947205,\n",
       "  0.9344978332519531,\n",
       "  0.9410480260848999,\n",
       "  0.9454148411750793,\n",
       "  0.9563318490982056,\n",
       "  0.9541484713554382,\n",
       "  0.9563318490982056,\n",
       "  0.9563318490982056,\n",
       "  0.960698664188385,\n",
       "  0.960698664188385,\n",
       "  0.960698664188385,\n",
       "  0.960698664188385,\n",
       "  0.9628821015357971,\n",
       "  0.9628821015357971,\n",
       "  0.9628821015357971,\n",
       "  0.9628821015357971],\n",
       " 'val_loss': [0.5335533022880554,\n",
       "  0.43902894854545593,\n",
       "  0.3966190814971924,\n",
       "  0.36304351687431335,\n",
       "  0.36193162202835083,\n",
       "  0.3229401409626007,\n",
       "  0.33019882440567017,\n",
       "  0.3119520843029022,\n",
       "  0.3339370787143707,\n",
       "  0.302752822637558,\n",
       "  0.33394140005111694,\n",
       "  0.2985526919364929,\n",
       "  0.32714682817459106,\n",
       "  0.30503079295158386,\n",
       "  0.3339540362358093,\n",
       "  0.29546359181404114,\n",
       "  0.3473667800426483,\n",
       "  0.3011917769908905,\n",
       "  0.33582183718681335,\n",
       "  0.30534660816192627],\n",
       " 'val_accuracy': [0.9019607901573181,\n",
       "  0.9019607901573181,\n",
       "  0.9019607901573181,\n",
       "  0.9019607901573181,\n",
       "  0.9019607901573181,\n",
       "  0.8823529481887817,\n",
       "  0.9019607901573181,\n",
       "  0.9019607901573181,\n",
       "  0.9019607901573181,\n",
       "  0.9019607901573181,\n",
       "  0.9019607901573181,\n",
       "  0.9019607901573181,\n",
       "  0.8823529481887817,\n",
       "  0.9019607901573181,\n",
       "  0.9019607901573181,\n",
       "  0.9019607901573181,\n",
       "  0.9019607901573181,\n",
       "  0.9019607901573181,\n",
       "  0.9019607901573181,\n",
       "  0.9019607901573181],\n",
       " 'val_precision': [0.9019607901573181,\n",
       "  0.9019607901573181,\n",
       "  0.9019607901573181,\n",
       "  0.9019607901573181,\n",
       "  0.9019607901573181,\n",
       "  0.8823529481887817,\n",
       "  0.9019607901573181,\n",
       "  0.9019607901573181,\n",
       "  0.9019607901573181,\n",
       "  0.9019607901573181,\n",
       "  0.9019607901573181,\n",
       "  0.9019607901573181,\n",
       "  0.8823529481887817,\n",
       "  0.9019607901573181,\n",
       "  0.9019607901573181,\n",
       "  0.9019607901573181,\n",
       "  0.9019607901573181,\n",
       "  0.9019607901573181,\n",
       "  0.9019607901573181,\n",
       "  0.9019607901573181],\n",
       " 'val_recall': [0.9019607901573181,\n",
       "  0.9019607901573181,\n",
       "  0.9019607901573181,\n",
       "  0.9019607901573181,\n",
       "  0.9019607901573181,\n",
       "  0.8823529481887817,\n",
       "  0.9019607901573181,\n",
       "  0.9019607901573181,\n",
       "  0.9019607901573181,\n",
       "  0.9019607901573181,\n",
       "  0.9019607901573181,\n",
       "  0.9019607901573181,\n",
       "  0.8823529481887817,\n",
       "  0.9019607901573181,\n",
       "  0.9019607901573181,\n",
       "  0.9019607901573181,\n",
       "  0.9019607901573181,\n",
       "  0.9019607901573181,\n",
       "  0.9019607901573181,\n",
       "  0.9019607901573181]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_history = first_model(base_model)\n",
    "base_history.history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate the model performance, we will look at the training and validation loss and accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Validation\n",
    "\n",
    "lets check the model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, epoch_stop):\n",
    "    model.fit(X_train_oh\n",
    "              , y_train_oh\n",
    "              , epochs=epoch_stop\n",
    "              , batch_size=BATCH_SIZE\n",
    "              , verbose=0)\n",
    "    results = model.evaluate(X_test_oh, y_test_oh)\n",
    "    \n",
    "    return results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 1ms/step - loss: 0.8903 - accuracy: 0.8947 - precision_1: 0.8947 - recall_1: 0.8947\n",
      "[0.8902625441551208, 0.8947368264198303, 0.8947368264198303, 0.8947368264198303]\n",
      "Test accuracy of baseline model: 89.47%\n"
     ]
    }
   ],
   "source": [
    "test_results = test_model(base_model,30)\n",
    "print(test_results)\n",
    "print('Test accuracy of baseline model: {0:.2f}%'.format(test_results[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 0 1 1 1 1 1 1 1 0 0 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 0 1 0 0 1 1\n",
      " 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "y_score = base_model.predict_classes(X_test_oh)\n",
    "print(y_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.75      0.75        12\n",
      "           1       0.93      0.93      0.93        45\n",
      "\n",
      "    accuracy                           0.89        57\n",
      "   macro avg       0.84      0.84      0.84        57\n",
      "weighted avg       0.89      0.89      0.89        57\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = base_model.predict_classes(X_test_oh)\n",
    "print(y_test.ndim)\n",
    "print(classification_report(y_test_le, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9237426900584795\n",
      "0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "\n",
    "average_precision = average_precision_score(y_test_le, y_pred)\n",
    "print(average_precision)\n",
    "average_recall = recall_score(y_test_le, y_pred)\n",
    "print(average_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_arr = np.column_stack((y_test_le, y_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [0, 0],\n",
       "       [0, 0]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
